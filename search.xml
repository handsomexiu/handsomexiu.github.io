<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>langchain-吴恩达</title>
      <link href="/2023/10/18/langchain-%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
      <url>/2023/10/18/langchain-%E5%90%B4%E6%81%A9%E8%BE%BE/</url>
      
        <content type="html"><![CDATA[<p>本篇blog是关于对吴恩达老师langchain视频的学习</p><p>视频链接如下：</p><p><a href="https://www.bilibili.com/video/BV1zu4y1Z7mc/?share_source=copy_web&amp;vd_source=0ec5c2e569af093da6baa551bf60ff8e">吴恩达最新《LLM应用程序开发的LangChain》|langchain-for-llm-application-development|中英字幕</a></p><p><a href="https://www.bilibili.com/video/BV1pz4y1e7T9/?share_source=copy_web&amp;vd_source=0ec5c2e569af093da6baa551bf60ff8e">简直逆天！我居然只花了2小时就掌握了吴恩达教授讲的【LangChain+ChatGLM-6B】LLM应用开发实践！强烈推荐！！   人工智能|深度学习</a></p><p>下面这个有英文字幕，但是有些地方感觉怪怪的</p><span id="more"></span><p>[TOC]</p><p>LangChain：<a href="https://www.langchain.asia/">https://www.langchain.asia/</a></p><p><a href="https://blog.csdn.net/qq_36080693/article/details/131217876?spm=1001.2014.3001.5502">https://blog.csdn.net/qq_36080693/article/details/131217876?spm=1001.2014.3001.5502</a></p><p><a href="https://zhuanlan.zhihu.com/p/633939244">吴恩达最新Langchain课程学习笔记①丨Prompts, Models, Output parsers - 知乎 (zhihu.com)</a></p><p><strong><a href="https://zhuanlan.zhihu.com/p/643059379">精华笔记：吴恩达 x LangChain 《使用LangChain构建与数据对话的聊天机器人》（上）</a></strong></p><p><strong><a href="https://mp.weixin.qq.com/s/KrFV-fuP2MI3HQGmEM1sUA?poc_token=HF2bLGWj8faW8dJZUMSWjglg4JmPEPO6CVR3SHgd">精华笔记：吴恩达 x LangChain《基于LangChain的大语言模型应用开发》(上)</a></strong></p><h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>大语言模型应用开发</p><p>一个应用可能需要多次调用LLM并解析输出，因此需要编写大量的粘合代码。</p><p>Langchain（最初是用于构建LLM应用的开源框架）能够加速开发，使得开发过程更加的轻松</p><p><strong>Langchain专注于组合和模块化（composition and modularity）</strong></p><ul><li>拥有许多可与彼此或单独使用的个体组件（modular components）</li><li>use case：这些模块化的组合方式形成了一系列将其转化为端到端的应用的方式，且容易入门（common ways to combine components）</li></ul><p>Langchain常见的组件</p><ul><li><strong>models</strong></li><li><strong>prompts</strong>：即如何使模型实现有用和有趣的功能</li><li><strong>indexes</strong>：即将数据注入系统以与模型结合使用的方式</li><li><strong>chains</strong>：prompt+LLM+output parsing<ul><li>can be used as building blocks for longer chain</li></ul></li><li><strong>agents</strong>：agent是一种令人兴奋的端到端用例类型，它使用模型作为推理引擎。（algorithms for getting LLMs to use tools）</li></ul><p><a href="https://mp.weixin.qq.com/s/KrFV-fuP2MI3HQGmEM1sUA?poc_token=HF2bLGWj8faW8dJZUMSWjglg4JmPEPO6CVR3SHgd">精华笔记：吴恩达 x LangChain《基于LangChain的大语言模型应用开发》(上) (qq.com)</a></p><h1 id="models-prompts-and-parsers解析器"><a class="markdownIt-Anchor" href="#models-prompts-and-parsers解析器"></a> models prompts and parsers（解析器）</h1><p><a href="https://mp.weixin.qq.com/s/KrFV-fuP2MI3HQGmEM1sUA?poc_token=HF2bLGWj8faW8dJZUMSWjglg4JmPEPO6CVR3SHgd">精华笔记：吴恩达 x LangChain《基于LangChain的大语言模型应用开发》(上) (qq.com)</a></p><p>模型使指支撑其中很多部分的语言模型，</p><p>prompts指的是创建输入以传递给模型的方式，</p><p>解析器则位于相反的一端，它涉及将这些模型的输出解析为更结构化的格式，以便您可以在下游执行操作。</p><p>我们反复提示一个模型，解析输出，所以Langchain提供了一套简单的抽象概念来做这类操作<br>langchain为一些常见的操作提供了提示（prompt，如总结，回答问题，调用api）；不用自己设计prompt</p><p>langchain不仅有prompt同时还有解析器</p><ul><li><p>当你使用LLM构建一个复杂的应用程序时，你经常让LLM以某种格式生成其输出，比如使用特定的关键字；</p><ul><li>比如react中的一些关键字thought，action，observation；这个prompt可以和一个解析器结合起来以提取出被标记为这些特定关键词的文本</li></ul></li><li><p>可以指定LLM的输入；也可以让解析器正确解析 LLM的输出</p></li><li><p>提示模板可以和输出解析器结合在一起，以方便输入提示以特定格式输出，然后解析器暂停该输出将数据存储在python字典或其他一些数据结构中，使其以便下游处理</p></li></ul><h1 id="memory"><a class="markdownIt-Anchor" href="#memory"></a> memory</h1><p><a href="https://mp.weixin.qq.com/s/KrFV-fuP2MI3HQGmEM1sUA?poc_token=HF2bLGWj8faW8dJZUMSWjglg4JmPEPO6CVR3SHgd">精华笔记：吴恩达 x LangChain《基于LangChain的大语言模型应用开发》(上) (qq.com)</a></p><p>使用langchain来管理聊条或聊天机器人对话<br>当你与这些模型互动时，他们自然不记得你之前说了什么，也不记得之前对话的内容<br>me’mory</p><ul><li><p>你如何记住你以前的对话部分，并将其输入到语言模型中，以便他们可以在你与他们互动的时候有这样的对话流程</p><ul><li>多轮对话？？？？？</li><li>可以根据自己的想法去创建对话</li><li>利用langchain的memory.save_context({“input”:“hi”},{“output”:“cool”})</li></ul><p><img src="image-20231016103137378.png" alt="image-20231016103137378"></p></li><li><p>所以当你用一个大语言模型进行聊天对话时，大语言模型本身事物状态的，语言模型本身并不能记得你到目前为止的对话</p><ul><li>而每次交易，每次对API终端的调用都是独立的</li></ul></li><li><p>而聊天机器人有一段时间的内存知识因为通常有 rapid code提供了目前为止的完整对话，作为语言模型的上下文</p></li><li><p>因此内存可以明确的存储术语或目前为止的对话</p></li><li><p>但是随着对话变漫长，所需要的内存量变得非常大，而且向LLM发送大量令牌的成本也会增加</p><ul><li>这是 ConversationBufferMemory</li></ul></li></ul><p>langchain提供了几种方便的存储器来存储和积累对话</p><ul><li>ConversationBufferWindowMemory</li><li>ConversationTokenBufferMemory<ul><li>需要指定LLM，不同LLM计算（计数，counting）token的方式是不同的</li></ul></li><li>ConversationSummaryBufferMemory<ul><li>用LLM来写一个大目前为止的对话摘要，让这个成为记忆</li><li>如果没超过max_token_limit则直接存储；否则用summary</li><li>目的是为了保持信息的明确存储，且信息的显式存储量不超过我们指定的令牌数量</li></ul></li><li>如何设置上限而不是让其任意增长</li><li><img src="image-20231016111339094.png" alt="image-20231016111339094"></li></ul><p>langchain实际上也支持额外的内存类型，其中最强大的是向量数据库存储器：如果你熟悉单词嵌入和文本嵌入，矢量数据库时加上存储的就是这种 embeddings</p><ul><li>它可以用这种向量数据库检索出最相关的文本块，用向量数据库作为其memory</li></ul><p>langchain也支持实体memory</p><ul><li>这是用于当你想记住关于特定的人，特定的其他实体细节<ul><li>比如你谈到一个特定的朋友，你可以让langchain记住关于这个朋友的事实</li><li>这将是一个实体的明确方式</li></ul></li></ul><p>使用多种记忆，如上面的对话记忆，另外还可以有实体记忆来回忆个人；</p><ul><li><strong>所以这种方式你可以记住也许是对话的摘要，再加上一种明确的方式来存储寡欲对话中重要任务的重要事实</strong></li></ul><p>传统的数据库也是很常见的（SQL）因此你可以回顾整个对话以便于auditing或者进一步改进system</p><p><img src="image-20231016111327544.png" alt="image-20231016111327544"></p><h1 id="chains"><a class="markdownIt-Anchor" href="#chains"></a> Chains</h1><p>langchain种最关键的部分即chain</p><p><strong>chain通常将LLM与prompt结合在一起</strong></p><p>有了这个block，你也可以把这些block堆一起来对你的文本或者其他数据进行一系列的操作</p><p><strong>LLMChain</strong></p><ul><li>这是一个简单但是非常强大的链，它是我们将要讨论的许多链的基础</li></ul><p><strong>Sequential Chains</strong></p><ul><li><p>顺序链一个接一个地运行着一连串的链条</p></li><li><p>SimpleSequentialChain</p><ul><li><img src="image-20231016151401400.png" alt="image-20231016151401400"></li><li>这希望我们的sub chain只有一个输入和只返回一个输出</li><li>这里的子链可以是LLMChain</li><li>SimpleSequencialChain(chains=[chain1,chain2])：可以称为整体(overall) simple chain</li></ul></li><li><p>上面要求子链有一个输入和一个输出，多个输入或多个输出时</p><ul><li><img src="image-20231016151451213.png" alt="image-20231016151451213"></li><li>用常规的（regular）sequential chain</li><li>要注意出入输出匹配正确，且名称排列一定要正确</li><li>适用于更加复杂的场景</li><li>SequentialChain</li></ul></li><li><p>一个非常普通但很基本的操作是将一个输入路由到一个链上，这取决于该输入是什么</p></li></ul><p>一个很好的想象方法是如果你有多个子链其中每个子链有某种特定类型的输入，你可以有一个路由链（router chain）</p><p><img src="image-20231016154803384.png" alt="image-20231016154803384"></p><ul><li>首先决定将其传递给哪个子链，然后再将其传递给那个chain</li><li>MultiPromptChain：这是一种特定类型的链，用于在多个不同提示模板之间进行路由；这个用来汇总用的，创建总体链路<ul><li>chain = MultiPromptChain(router_chain=router_chain,<br>destination_chains=destination_chains,<br>default_chain=default_chain, verbose=True<br>)</li></ul></li><li>LLMrouterChain：使用语言模型本身来路由不同的子链</li><li>RouterOutputParse：路由器输出解析器，将LLM输出解析为可以在下游使用的字典，以确定使用哪个链以及该链的输入应该是什么。<ul><li>RouterOutputParser将LLM输出解析成一个字典，根据字典内容确定下游使用哪条链，以及链的输入应该是什么</li><li>他将帮助这个链路决定在哪些子链路之间进行路由</li></ul></li><li>除了目标链我们还需要一个默认链，当路由器无法决定使用哪个子链时就会调用此链</li></ul><h1 id="question-and-anwser-over-documents"><a class="markdownIt-Anchor" href="#question-and-anwser-over-documents"></a> Question  and Anwser over Documents</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzkyNzE3MTkyMw==&amp;mid=2247488986&amp;idx=1&amp;sn=fe19d5271b90ad6b042dbd7c38109c7e&amp;chksm=c22d41e6f55ac8f060000a1990e794aa3f4af83864297f75b99fa41be326f904f3ccf6179d21&amp;cur_album_id=2996732650201677829&amp;scene=189#wechat_redirect">精华笔记：吴恩达 x LangChain《基于LangChain的大语言模型应用开发》(下) (qq.com)</a></p><p>人类正在使用LLM构建的最常见的复杂应用之一是可以在文档之上或关于文档的问题上回答的系统</p><p>一个文本可能是从PDF文件、网页或某些公司的内部网内部文件种提取出来的，你能不能用LLM来回答关于这些文件的问题，以帮助用户活获得更深入的理解和获取他们所需要的信息</p><p>LLM可以根据从PDF文件、网页或公司内部文档中提取的文本来回答问题，这使得LLM能够与未经训练的数据结合起来，从而更灵活地适配不同应用场景。</p><ul><li>引入linkchain的一些关键组件如embedding model and vector stores</li><li>这开始将这些语言模型与他们最初未经训练的数据结合起来，这使他们在你的应用种更加灵活和适应</li></ul><p><strong>要构建一个基于文档的问答系统，需要引入 LangChain 的更多关键组件，例如嵌入（Embedding）模型和向量存储（Vector Stores）。</strong></p><p>RetrievalQA：在文件上做检索</p><p>还要文档加载器，被用来加载一些专有数据，这里用的使CSV格式，CSVLoader</p><p>最后引入向量存储，将从DocArray内存搜索矢量存储开始</p><ul><li><p>DocArray in-memory search vector store:DocArrayInMemorySearch</p></li><li><p>这是一个内存（in - memory）向量存储，而且不需要连接到任何类型的外部数据库</p><ul><li>这就是in-memory</li></ul></li><li><h4 id="接下来将导入一个索引向量存储索引创建器-vectorstoreindexcreator这里创建一个内存方式的向量存储传入上一步创建的️️加载器"><a class="markdownIt-Anchor" href="#接下来将导入一个索引向量存储索引创建器-vectorstoreindexcreator这里创建一个内存方式的向量存储传入上一步创建的️️加载器"></a> 接下来将导入一个索引，向量存储索引创建器（ VectorstoreIndexCreator）：这里创建一个内存方式的向量存储，传入上一步创建的️️加载器。**</h4><ul><li><pre class="highlight"><code class="python"><span class="keyword">from</span> langchain.indexes <span class="keyword">import</span> VectorstoreIndexCreatorindex = VectorstoreIndexCreator(  vectorstore_cls=DocArrayInMemorySearch//指定向量存储类).from_loaders([loader])//接受一个文档加载器的列表，我们这里只关心一个加载器（loader），所以这就是我们在这里传递的内容&lt;!--code￼<span class="number">0</span>--&gt;</code></pre></li></ul></li></ul><p>可以用一行代码（更容易上手）来做也可以分解成更详细的步骤来做（能够让你设置更多关于到底发生了什么的具体细节）</p><p>Stuff method</p><ul><li><img src="image-20231016184837145.png" alt="image-20231016184837145"></li><li>你只需要把所有的东西放到一个提示种，然后把它发送给语言模型，得到一个response</li><li>但并不是工作的很好<ul><li>比如文件很大的时候</li></ul></li></ul><p><img src="image-20231016185018837.png" alt="image-20231016185018837"></p><p>把所有的文件都当作独立的（可以batch操作），且需要更多的调用；</p><p><img src="image-20231016185103656.png" alt="image-20231016185103656"></p><p>速度比较慢 ，调用多</p><p><img src="image-20231016185227557.png" alt="image-20231016185227557"></p><p>这些方法可以用到其他的链种不仅仅是问答</p><p>mapreduce常用于summary</p><p><strong>不同的链由很多事情要做</strong></p><h1 id="evaluating-llm-applications"><a class="markdownIt-Anchor" href="#evaluating-llm-applications"></a> Evaluating LLM Applications</h1><p><strong>当使用LLM构建一个复杂的应用程序时，其中一个重要但是有时很棘手的步骤是——如何评估你的应用程序做的如何，他是否符合一些准确性标准</strong></p><p>这些应用程序确实由血多不同的步骤组成的链条（chain）和序列（sequence）</p><ul><li>第一个要做的事就是了解每个步骤的具体内容</li><li>一些工具可以被认为是visualizer or debuggers</li><li>但是在很多不同的数据点上获得一个更加全面的画面事非常有用的<ul><li>在很多不同的数据电商了解模型是如何做的</li></ul></li><li>哪些是我们想要评估的数据点</li></ul><p>评估有两个目的：</p><ul><li>检验LLM应用是否达到了验收标准</li><li>分析改动对于LLM应用性能的影响</li></ul><p>基本的思路就是利用语言模型本身和链本身，来辅助评估其他的语言模型、链和应用程序。</p><p><strong>langchain.debug = True</strong></p><ul><li>这种调试模式可以用来强调什么地方出了问题</li><li>拥有这些所有信息对于理解发生了什么事真的很有帮助</li></ul><p>打印更多的信息</p><p><strong>通常情况下，当一个错误的结果被返回时，它不一定是语言模型本身出问题，可能是检索出了问题</strong></p><p><strong>语言模型做评估可以充分理解语意</strong>，而不仅仅是做精确匹配比如正则化匹配</p><h1 id="agent"><a class="markdownIt-Anchor" href="#agent"></a> Agent</h1><p>有时人们会认为大语言模型是一个知识库</p><ul><li>就像它学会了记忆大量信息，也许来自于互联网</li></ul><p>但是我（吴恩达）认为，更有用的方式是将大语言模有时视为一个推理引擎</p><ul><li>这种情况下，你可以给它一些文本块或者其他信息来源</li></ul><p>agent是最强大的部分之一也比较新</p><p>将语言模型作为一个agent的推理引擎</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">agent= initialize_agent(</span><br><span class="line">    tools, </span><br><span class="line">    llm, </span><br><span class="line">    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,</span><br><span class="line">    handle_parsing_errors=<span class="literal">True</span>,</span><br><span class="line">    verbose = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ul><li>agent参数</li></ul><p>agent参数 CHAT_ZERO_SHOT_REACT_DESCRIPTION中的CHAT部分，表示这是一个专门为Chat模型优化的代理。REACT部分表示一种组织Prompt的技术，能够最大化语言模型的推理能力。</p><ul><li>handle_parsing_errors</li></ul><p>true表示当内容无法被正常解析时，会将错误内容传回语言模型，让它自行纠正。</p><p>从打印出来的中间步骤详细记录中，我们可以看到几个关键词，其表示的含义分别是：</p><table><thead><tr><th style="text-align:left">关键词</th><th style="text-align:left">表示含义</th></tr></thead><tbody><tr><td style="text-align:left">Thought</td><td style="text-align:left">LLM在思考的内容</td></tr><tr><td style="text-align:left">Action</td><td style="text-align:left">执行特定的动作</td></tr><tr><td style="text-align:left">Observation</td><td style="text-align:left">从这个动作中观察到了什么</td></tr></tbody></table><p><strong>像coplit，甚至启用代码解释器插件的ChatGPT，他们正在做的事情之一就是他们正在使用语言模型来编写代码，然后执行这些代码</strong></p><p>agent的一大好处就是可以把它连接到你自己的信息源，自己的API，自己的数据</p><h2 id="使用-python-代理工具"><a class="markdownIt-Anchor" href="#使用-python-代理工具"></a> 使用 Python 代理工具</h2><p>类似于ChatGPT的代码解释器，Python 代理工具可以让语言模型编写并执行Python代码，然后将执行的结果返回给代理，让它决定下一步的操作。</p><p>我们的任务目标是对一组客户名单按照姓氏和名字进行排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">agent = create_python_agent(</span><br><span class="line">    llm,</span><br><span class="line">    tool=PythonREPLTool(),</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>REPL基本上是一种与代码交互的方式，你可以把它看作是一个jupyter笔记本,agent可以用这个REPL执行代码，然后将其运行，然后我们会得到一些结果；</p><p>这些结果将被传回给agent，所以它可以决定下一步该增么做</p><p>在编写自定义的API时需要写一个非常详细的文档字符串，这是因为agent将用于知道什么时候应该调用工具以及应该如何调用这个工具</p><h1 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> conclusion</h1><p>多用多学！！！！！</p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 大模型 </tag>
            
            <tag> 大模型部署 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型实战(1)——langchain+LLM</title>
      <link href="/2023/10/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%98-1-%E2%80%94%E2%80%94langchain-LLM/"/>
      <url>/2023/10/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E6%88%98-1-%E2%80%94%E2%80%94langchain-LLM/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>自动驾驶相关论文阅读</title>
      <link href="/2023/10/11/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2023/10/11/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>这是关于换方向之前对自动驾驶论文的一些阅读和理解</p><p>现在看大模型了</p><span id="more"></span><p><strong>（所有论文的实现细节还得看代码）</strong></p><p>[TOC]</p><p>（还得关注一下损失函数，这个很重要）</p><p>动机感觉像是你写论文的目的，你要解决的问题，也有发现过去方法的问题；而论文的创新点往往有和过去的方法有对比。</p><p>根据网上的一些资料，论文的动机是指你为什么要做这个研究，你想要解决什么问题，你的研究有什么意义和价值。论文的创新点是指你的研究有什么不同于其他同类作品并且具备原创性的特点，是在前人的基础上乃至于高于前人的研究上得出的一种独到观点。</p><p>论文的动机和创新点之间有一定的联系，但也有区别。动机是写作论文的出发点和目标，创新点是写作论文的成果和亮点。动机可以激发你进行研究，创新点可以展示你进行研究的水平和贡献。</p><p><img src="image-20230404210125616.png" alt></p><h1 id="快速阅读轨迹预测场景上下文提取评价"><a class="markdownIt-Anchor" href="#快速阅读轨迹预测场景上下文提取评价"></a> 快速阅读（轨迹预测，场景上下文提取，评价）</h1><h2 id="1-covernet-multimodal-behavior-prediction-using-trajectory-sets-cvpr-2020"><a class="markdownIt-Anchor" href="#1-covernet-multimodal-behavior-prediction-using-trajectory-sets-cvpr-2020"></a> 1、CoverNet: Multimodal Behavior Prediction using Trajectory Sets （CVPR 2020）</h2><p><img src="image-20230505091556644.png" alt></p><p><strong>本篇文章的模型细节没有详细说明</strong></p><p>我们现在总结一下我们在使用 CoverNet 进行多模态概率轨迹预测方面的主要贡献：</p><p>• 介绍用于多模态轨迹预测的轨迹集的概念，并展示如何以固定和动态方式生成它们；</p><p>• 在 nuScenes [5] 上比较最先进的方法，nuScenes [5] 是一个公共的、真实世界的城市驾驶基准；</p><p>• 凭经验显示轨迹集分类优于多模态回归。</p><p><strong>论文将轨迹预测问题转化为对不同轨迹集合的分类问题。</strong></p><ul><li>这里的分类是利用softmax对我们事先生成的轨迹（本篇文章相当于是对control进行评分，没有直接利用模型去进行回归，而是利用模型去进行分类（评分），真实值是真实的轨迹，用的损失也是MTP）进行评分。<ul><li>我认为multipath像是一种分类+回归，只不过multipath中还有偏移回归等，以及固定的anchor。</li></ul></li><li>轨迹回归是类似于MTP那篇文章的方法，直接输出轨迹。</li></ul><p>（但这个轨迹的生成好像没有考虑到场景交互，车与车之间的交互，这些交互信息被用于评分那一块去了和MTP文章有些出入。）</p><p>本篇文章并不复杂，这里的的特征提取器和MTP那篇文章中的一样。我认为这篇文章主要是对标的是Multipath</p><p><strong>在论文TNT中有这样一段描述：</strong></p><ul><li>最近，Multi Path [ 33 ]和Cover Net [ 34 ]选择将轨迹量化为<strong>锚点</strong>，其中轨迹预测任务被改写为锚点选择和<strong>偏移回归（offset regression）</strong>。<code>锚点要么预先聚类成固定的先验集合[ 33 ]（multipath），要么基于运动学启发式[ 34 ]动态获取（covernet）。</code></li></ul><p>论文提除了两个见解：</p><ul><li>在合理的额时间范围内，可采取的不同行动相对较少。<ul><li>稀疏</li></ul></li><li>预测的轨迹应该与当前的动态状态保持一致。<ul><li>动态</li></ul></li></ul><p>论文中对fixed和dynamic做出了解释：这里也有方法</p><ul><li>fixed：如果轨迹集包含的轨迹不随代理当前动态状态或环境的变化而变化，我们认为轨迹集是固定的。<ul><li>这里和Multipath一样，是基于真实轨迹这个先验得到的，而没有考虑当前的状态。</li></ul></li><li>dynamic：如果轨迹集包含的轨迹随着代理当前动态状态的变化而变化，我们认为轨迹集是动态的。<ul><li>论文受运动学的启发，采用的是标准车辆到你管理学模型。</li><li>同时动力学模型、控制序列和当前状态通过forward integration确定轨迹 st:t+N<ul><li>我们通过在不同的控制序列上与我们的动态模型向前集成，基于当前状态 st 创建动态轨迹集 K。</li></ul></li><li>对于相同的覆盖范围，这样的动态轨迹集有可能比固定集更稀疏，因为<strong>每个控制序列映射到多个轨迹（作为当前状态的函数）</strong></li><li>论文通过预测范围内的<strong>一组不同的恒定横向和纵向加速度</strong>来参数化<strong>控制（输出空间）</strong>（这里作为anchor）。（<strong>每一个控制里面的纵向横向加速度是恒定的</strong>，也就是说再接下来的一小段时间内是不变的（然后用前向推理去计算未来的状态，根据标准车辆动力学模型）（？？？？，暂时不确定））</li><li><strong>这里的anchor相当于变成了control序列</strong></li></ul></li><li>混合：请注意，与固定轨迹的情况不同，dynamic profile的合成性质可能无法保证 100% 覆盖。（也就是说动态的控制序列没法覆盖所有情况，因此采用动静结合的方式）<ul><li>利用静态中的子采样轨迹和动态中的anchor结合起来，再去子采样（<strong>prune</strong>）</li><li>保证对空间的足够的覆盖</li></ul></li></ul><h2 id="2-智能汽车预期功能安全保障关键技术个人认为偏科普全面介绍了sotif歌歌模块的"><a class="markdownIt-Anchor" href="#2-智能汽车预期功能安全保障关键技术个人认为偏科普全面介绍了sotif歌歌模块的"></a> 2、智能汽车预期功能安全保障关键技术（个人认为偏科普，全面介绍了SOTIF歌歌模块的）</h2><p>预期功能安全（SOTIF）保障</p><p>由于性能局限、规范不足或可合理预见误用导致的预期功能安全问题层出不穷，严重阻碍了智能汽车 的快速发展。本综述聚焦<strong>智能汽车预期功能安全保障关键技术</strong>，分别从<code>系统开发、功能改进和运行 </code>3 个阶段进行了 系统的总结，最后从<code>基础理论、风险防护和更新机制</code> 3 方面进行了展望</p><ul><li>SOTIF问题：1、汽车系统复杂化，2、汽车智能化程度日益提升，3、运行环境的开放性和挑战性不断增加，4、<strong>感知和决策等功能不足</strong></li></ul><p><strong>预期功能安全旨在避免由于预期功能或其实现 的功能不足导致危害所产生的不合理风险</strong></p><p>SOTIF 研究涉及系统功能设 计改进、分析评估、验证确认和认证等多方面问题， 且随着技术发展和新技术的引入不断提出新的需求</p><p>UL 4600［4］旨在补充功能安全和SOTIF标准，提出一种面向安全目标的方法，专注于 “如何评估”全自动驾驶安全情况。</p><p>现有SOTIF研究的不足，该领域还并未形成完善的技术研究体系：1、研究总量相对较少，2、缺少对SOTIF保障关键技术系统性的研究和梳理，3、有许多高水平研究成果对于解决功能不足问题具有重要的启发和借鉴意义，但尚未被明确纳入SOTIF保障技术研究范畴。</p><p>SOTIF问题：1、车辆层对预期功能的规范不足，2、预期功能实现的不足，3、同时SOTIF危害的产生和演化依赖于特定的场景。因此，<strong>在进行SOTIF保障过程中需要综合系统自身的局限和运行场景风险以建立安全保障体系。</strong></p><p><strong>SOTIF保障目标的实现可分解为将未知转化为已知，将不安全转化为安全两个方面。</strong></p><ul><li>开发阶段 SOTIF 保障关键技术“：SOTIF 分析评估、验证确认、功能改进和发布</li><li>智能汽车功能改进关键技术：从感知定位、决策控制、合理可预见误用处理和整 车层功能改进</li><li>运行阶段SOTIF保障关键技术：短期风险防护和长期功能</li></ul><p><img src="image-20230509195929822.png" alt></p><p><img src="image-20230509195948122.png" alt></p><p>本文从 SOTIF 问题本质出发，通过对智能 汽车系统开发和运行阶段的 SOTIF 保障关键技术以 及针对系统各模块、合理可预见误用和整车层功能 改进技术的综述，梳理了 SOTIF 保障技术体系并提 出了研究展望，从而助力智能汽车 SOTIF 的技术研 究和产业落地。</p><h1 id="场景上下文提取scene-context-modelinggnn"><a class="markdownIt-Anchor" href="#场景上下文提取scene-context-modelinggnn"></a> 场景上下文提取，Scene context modeling,GNN</h1><h2 id="1-vectornetencoding-hd-maps-and-agent-dynamics-from-vectorized-representationcvpr-2020也涉及到了轨迹预测主要是表征"><a class="markdownIt-Anchor" href="#1-vectornetencoding-hd-maps-and-agent-dynamics-from-vectorized-representationcvpr-2020也涉及到了轨迹预测主要是表征"></a> 1、VectorNet：Encoding HD Maps and Agent Dynamics from Vectorized Representation(CVPR 2020)（也涉及到了轨迹预测，主要是表征）</h2><p><strong>自动驾驶的一个复杂性，且这是一个动态的多智能体的系统</strong>。</p><p>核心的兴趣是找到一个统一的表示，它将感知系统(如目标检测和跟踪)获得的动态智能体与场景上下文结合起来，（这里是场景上下文吧）通常<strong>以高清地图的形式作为先验知识提供</strong>。利用了<strong>HD map</strong>，高清地图。论文的目标是建立一个系统，学习预测车辆的意图，这些车辆被参数化为轨迹。</p><p>动机：能否直接从结构化的高清地图中学习到有意义的语境表征?同时还收自监督学习方法的影响，提出了一种随机掩码的方式来增强自己的学习能力。</p><p>方法：1、<strong>折线化向量化表示</strong>：文章将道路的特征如人行横道，交叉路口等以及车辆建模成polylines（折线）。所有这些折线然后可以表示为向量的集合。</p><p>2、<strong>层次图神经网络：hierarchical graph network VectorNet</strong>：使用了<strong>图神经网络</strong>来合并这些向量集，将每个向量视为图中的一个节点，并将节点特征设置为每个向量的起始位置和终止位置，以及其他属性如折线组id和语义标签。来自HD地图的上下文信息以及其他移动智能体的轨迹通过GNN传播到目标智能体节点。</p><p><strong>这里的图还是无向全连接图（无向完全图）</strong></p><p>分层图网络，它聚合了来自单个多段线的局部信息，然后全局地覆盖所有轨迹和地图特征。</p><p>为了学习 GNN 的竞争表示，我们观察到根据节点的空间和语义接近度来约束图的连通性很重要。因此，我们提出了一种层次图架构，其中属于具有相同语义标签的相同折线的向量被连接并嵌入到折线特征中，然后所有折线相互完全连接以交换信息。<strong>为了利用节点的空间和语义局部性，我们采用分层方法</strong>，首先在向量级别构造子图，其中属于同一折线的所有向量节点相互连接。</p><ul><li><strong>作者观察到基于节点的空间和语义邻近性来约束图的连通性是很重要的。</strong></li><li>其中，属于具有相同语义标签的同一折线的向量被连接并嵌入到折线特征中（<strong>局部图</strong>）（提取节点的相关信息）</li><li>然后，所有的多线之间完全连接以交换信息（<strong>全局图</strong>）（交互？）（高阶交互的全局图）<ul><li>这里采用的是自注意力机制，<strong>自注意力机制类似于一个全连通的图？？</strong></li></ul></li><li>我们用多层感知器实现局部图，用自注意力实现全局图[ 30 ]。我们的方法的概述如图2所示。</li></ul><p><img src="image-20230314090613854.png" alt></p><p>3、<strong>自监督学习：node completion auxiliary task.</strong>：除了行为预测目标，我们还提出了一个辅助的图补全目标。更具体地说，我们随机掩码了属于场景上下文或代理轨迹的输入节点特征，并要求模型重建被掩盖的特征。<strong>直觉是鼓励图网络更好地捕捉智能体动态和场景上下文之间的交互。</strong></p><p><img src="image-20230315085913372.png" alt></p><p>此时的轨迹还是单模态的，看论文总结最后一句话：<strong>A natural next step is to incorporate the VectorNet encoder with a multi-modal trajectory decoder (e.g. [6, 29]) to generate diverse future trajectories.</strong>（一个自然的下一步是将<strong>VectorNet编码器</strong>与多模态轨迹解码器( e.g. [ 6,29 ])相结合，以生成多样化的未来轨迹。）。下面就是TNT等论文了。</p><p><s>他的输出也是一个多模态的，而不是一个确定的值。（从损失函数：负对数高斯似然）</s></p><p><strong>为了使输入节点特征对目标agent的位置保持不变，我们将所有向量的坐标归一化到目标agent在其最后一个观测时间步的位置。</strong></p><p>（<strong>但论文中好像没有区分哪个是target智能体</strong>，难道是说有一个target，但可以预测所有的移动智能体的轨迹？）</p><p><s>也是预测目标车辆的轨迹</s>，从论文的公式来看，这个既可以用于单个智能体的轨迹生成，也可以用于多个智能体的轨迹生成</p><h3 id="想法"><a class="markdownIt-Anchor" href="#想法"></a> 想法</h3><p>我们可不可以考虑另外一种交互模式，就是agent和agent之间建模，agent与环境之间建模，然后在考虑总体</p><p><strong>vectornet 在Dense TNT被称为稀疏化编码</strong></p><p>（文章关于图是如何构建的并没有说的很清楚。这里的图可能是无向图。<strong>具体还要看看代码</strong>）</p><h2 id="2-stgcnijcai-2018"><a class="markdownIt-Anchor" href="#2-stgcnijcai-2018"></a> 2、STGCN（IJCAI 2018）</h2><p>本篇文章是用于交通流量预测方向的。</p><p><img src="image-20230426105318834.png" alt></p><p><strong>本文章是交通研究中首次应用纯卷积结构从图结构时间序列(graph-structured time series)中同时提取时空特征。</strong></p><p>由于<strong>交通流的高度非线性和复杂性</strong>，传统方法无法满足中长期预测任务的要求，<strong>往往忽略了时空依赖性</strong>。</p><p><strong>本文提出了一种新的深度学习框架- -时空图卷积网络( STGCN )来解决交通领域的时间序列预测问题。</strong></p><p>我们不使用常规的卷积和循环单元，而是<strong>将问题建模在图上，构建具有完整卷积结构的模型，从而以更少的参数获得更快的训练速度。</strong></p><p><strong>STGCN</strong></p><p><img src="image-20230426160839130.png" alt></p><ul><li><p>对于交通网络结构的特征（空间特征提取）采用的是图卷积神经网络</p><ul><li><p><strong>交通网络一般以图结构组织。将道路网用数学上的图形表示是自然合理的。然而，以往的研究忽略了交通网络的空间属性：由于交通网络被分割成多个片段或网格，网络的连通性和全局性被忽视</strong>。即使在网格上进行二维卷积，由于数据建模的妥协，也只能粗略地捕捉空间局部性。因此**，在我们的模型中，图卷积被直接用于图结构数据，以提取空间域中具有高度意义的模式和特征。**</p></li><li><p>由于直接用GCN的话计算量比较大，本文采用的应该是 <strong>切比雪夫多项式近似</strong>。将线性复杂度从</p></li><li><p><strong>过去的图信号是向量的，现在可以扩展到矩阵，也就是说图中每个节点的信号值不再是一个标量，而是一个向量，我们可以记通道数为</strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">C_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p></li></ul></li><li><p>对于时间序列上的特征提取采用的是<strong>时间门控卷积</strong></p><ul><li><p><code>尽管基于RNN的模型在时间序列分析中变得广泛，但用于流量预测的循环网络仍然存在迭代耗时、门机制复杂和对动态变化响应缓慢等问题。相反，卷积神经网络具有训练速度快、结构简单、对前几步没有依赖约束等优点。受[格林等, 2017]的启发</code>，<strong>我们在时间轴上使用全卷积结构来捕捉交通流的时间动态行为。</strong></p><p>这种特定的设计允许通过作为分层表示形成的多层卷积结构进行并行和可控的训练过程。</p></li><li><p><strong>一维因果卷积+线性门控单元</strong></p><ul><li>值得一点注意的是，这里所描述的因果卷积好像没有填充（<strong>还得看代码</strong>）</li><li>残差连接作用在堆叠时间卷积层之间</li></ul></li></ul></li><li><p>融合特征：<strong>三明治结构（sandwich）</strong>：时空时</p><ul><li><code>中间的空间层是桥接两个时间层，通过时间卷积可以实现图卷积的快速空间状态传播</code></li><li><strong>&quot;三明治&quot;结构还帮助网络充分应用瓶颈策略，通过图卷积层对通道C进行降尺度和升尺度操作，实现尺度压缩和特征压缩。<strong>此外，在每个ST - Conv块内使用</strong>层归一化</strong>以防止过拟合。</li></ul></li><li><p>模型输出：附加了一个额外的时间卷积层和一个全连接层作为输出层。</p></li></ul><p><strong>下面我们总结我们的模型STGCN的主要特征。</strong></p><ul><li>STGCN是处理结构化时间序列的通用框架。它不仅能够处理交通网络建模和预测问题，<strong>而且能够应用于更一般的时空序列学习任务。</strong></li><li>时空块结合了图卷积和门控时间卷积，能<strong>够提取最有用的空间特征</strong>，同时<strong>连贯地</strong>捕获最本质的时间特征。</li><li><strong>该模型完全由卷积结构组成，因此以更少的参数和更快的训练速度实现了对输入的并行化</strong>。更重要的是，这种经济架构使得模型能够以更高的效率处理大规模网络。</li></ul><h2 id="3-scale-net-scalable-vehicle-trajectory-prediction-network-under-random-number-of-interacting-vehicles-via-edge-enhanced-graph-convolutional-neural-networkiros2020"><a class="markdownIt-Anchor" href="#3-scale-net-scalable-vehicle-trajectory-prediction-network-under-random-number-of-interacting-vehicles-via-edge-enhanced-graph-convolutional-neural-networkiros2020"></a> 3、SCALE-Net: Scalable Vehicle Trajectory Prediction Network under Random Number of Interacting Vehicles via Edge-enhanced Graph Convolutional Neural Network（IROS，2020）</h2><p><strong>每一个时间点都预测一张EGCN，然后进入一个LSTM</strong></p><p><strong>顺序编码</strong></p><p><img src="image-20230515135120334.png" alt></p><p>该方法是针对==每个时间点（帧）==都构重新对交通场景建模进行图形化建模。</p><p>（<mark>预测除ego车辆外的周围车辆，多智能体同时预测</mark>）</p><p><strong>在随机变化的交通水平下<mark>预测周围车辆的未来轨迹</mark>是开发自动驾驶汽车最具挑战性的问题之一</strong>。</p><p><mark><strong>scalable</strong></mark>：模型可以独立于所考虑的车辆总数进行操作。</p><p>特别地，我们的模型可以刻画如下First, the edge feature matrix has to be normalized vehicle-wisely in advance.</p><ul><li><strong>Fully scalable future prediction model</strong><ul><li>SCALE - Net是一个完全可扩展的可用车辆数模型。换句话说，该模型是完全灵活的，可以处理各种驾驶情况下的随机交通水平。</li></ul></li><li><strong>Explicitly embedded the natures of interaction</strong><ul><li>所提出的框架通过利用EGCN-LSTM交互嵌入层，可以内在地模仿车辆间交互的本质。</li></ul></li></ul><p>EGCN操作有两个步骤，<mark>一个是边增强的注意机制，另一个是基于图卷积神经网络的信息更新</mark>。</p><p><img src="image-20230515135155629.png" alt></p><ul><li><strong>为了更新特定车辆的上下文，首先需要计算目标车辆周围每辆车的重要性权重</strong>。即使在实际的驾驶情境中，在制定驾驶策略时，考虑到车辆的相对状态，与其他车辆相比，可能存在更多的冲突车辆。因此，为了内在地模仿这一特性，我们提出了一种<strong>边增强注意力机制</strong>。<code>边增强注意力机制的目标是生成加权邻接矩阵，邻接矩阵定义了具有连接强度的交互对的连通性</code>。<ul><li><strong>这里是得到加权邻接矩阵</strong>。</li></ul></li><li>利用节点特征矩阵和加权邻接矩阵，通过<mark>图卷积</mark>操作，<strong>多个交互对的影响同时在整个交通场景中传播。</strong><ul><li><code>由于单个交互效应对多车辆情况的近邻聚合，使得操作不受车辆总数的影响，实现了完全可扩展的模型</code>。在提出的基于EGCN的交互嵌入架构中，隐藏矩阵由每个车辆的隐藏状态组成；</li></ul></li></ul><p>周围车辆的时间序列未来位置是由传统的基于LSTM的seq2seq编码器-解码器模型产生的，该模型接受交互嵌入的隐藏矩阵HL作为其输入基础。<strong>通过LSTM编码器对车辆间的互动进行顺序编码，可以考虑时间变化的互动。</strong></p><p>在轨迹预测器中，为了使多个车辆的状态标准化，以实现模型的通用性，<strong>每个周围的车辆都被放在自己的坐标系中。<strong>因此，在整个方案中，<strong>每辆车的坐标系的原点被放在每辆车的初始位置上</strong>。利用</strong>坐标转换操作</strong>后，节点特征矩阵的每一行都被重新定义，形成车辆坐标下的车辆状态矩阵S，其中Si是车辆i在车辆i坐标上的状态。</p><p>在提出的轨迹预测器中，使用了具有LSTM编码器-解码器结构的序列-序列（seq2seq）模型。<strong>LSTM编码器的主要功能是对交互和车辆状态的顺序信息进行编码</strong>。LSTM解码器作为每个周围车辆的未来位置生成器，考虑到驾驶场景对每个车辆明确的嵌入式交互影响。</p><p><strong>为了同时考虑个人的操纵信息和交互信息</strong>，首先，LSTM编码器的输入矢量是由S（S有一个状态）和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>H</mi><mi>i</mi><mi>L</mi></msubsup></mrow><annotation encoding="application/x-tex">H_i^L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0999949999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span>之间的<strong>连接操作</strong>建立的。最后，通过LSTM编码器-解码器模型生成车辆i的时间序列未来位置。在本文中，历史时间跨度、预测时间跨度和相邻时间步骤之间的时间间隔分别被指定为3.5秒、4秒和0.5秒。</p><p>SCALE-Net采用了EGNN这种模型， <strong>对于每个时刻</strong>，每个车为一个节点，节点状态为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>l</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mi>e</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>e</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><msub><mi>x</mi><mi>e</mi></msub></msub><mo separator="true">,</mo><msub><mi>v</mi><msub><mi>y</mi><mi>e</mi></msub></msub><mo separator="true">,</mo><msub><mi>θ</mi><mi>e</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">X_l=[x_e,y_e,v_{x_e},v_{y_e},\theta_e]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>（x坐标、y坐标、x方向速度、y方向速度和倾角）， 而节点间的边大体按照<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mi>i</mi></msub><mo>−</mo><msub><mi>X</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">E_{ij}=|X_i-X_j|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span>表示（当然还有很多细节处理问题），呈现出多维的状态。<strong>建好的图就用多层的EGNN算法计算即可。下一个时刻，图模型又会重新建造，EGNN重新运行，每次EGNN最后一层的输出交给序列模型处理。</strong></p><p><mark>其中EGCN中所提到的给不同的边注意力也是值得考虑的</mark>。给不同节点不同的关注，给不同的交互不同的交互力度</p><p><strong>如何对交通场景进行graph建模文章没有细说</strong></p><h2 id="4-lanegcn-eccv2020"><a class="markdownIt-Anchor" href="#4-lanegcn-eccv2020"></a> 4、laneGCN （ECCV2020）</h2><p>多智能体预测，多模态预测</p><p><strong>强调了车道（场景）对motion predicted预测 的重要性</strong>，<mark>显式</mark>建模车道拓扑特征（之前的栅格化一般是<strong>隐式</strong>建模）</p><p>论文提出了一种新的运动预测模型（motion forecasting model）利用<mark>一种新颖的结构化地图表示以及actor-地图交互</mark></p><p>与将矢量化地图编码为栅格图像不同，我们从原始(raw)地图数据中构**建车道线图（lane graph）**来显式地保留地图结构。</p><ul><li><strong>为了捕获车道图的复杂拓扑和长距离依赖关系</strong>，我们提出了LaneGCN，它扩展了具有多个邻接矩阵和沿车道扩张的图卷积。</li><li><strong>为了捕获actors和地图之间的复杂交互</strong>，我们开发了一个由四种类型的交互组成的融合网络，actors到车道，车道到车道，车道到actors和actors到actors（actor-to-lane, lane-to-lane, laneto-actor and actor-to-actor）。</li></ul><p><img src="image-20230517085820947.png" alt></p><p>整个模型由四块构成：</p><ul><li>how to compute actor features with <strong>ActorNet</strong></li><li>how to represent the map via <strong>MapNet</strong></li><li>how to fuse the information from both actors and the map with <strong>FusionNet</strong></li><li>finally how to predict the final motion forecasting trajectories through the <strong>Prediction Header</strong></li></ul><p><img src="image-20230517102154125.png" alt></p><p>其中laneGCN在MapNet模块中，运用了四个邻接矩阵处理了四个不同的车道间的连接方式。同时还采用了不同跳（不同的幂次方）的GCN操作，用于获取：<strong>更大的感受野和多尺度拓扑特征</strong></p><p>这里的FusionNet也比较神奇：构建了一个由4个融合模块组成的stack，以捕获actors和车道节点之间的所有信息流，即actors到车道( A2L )、车道到车道( L2L )、车道到actors( L2A )和actors到actors( A2A )。</p><ul><li>A2L为车道节点引入实时的交通信息，例如车道的堵塞或使用情况。</li><li>L2L通过在车道图上传播交通信息来更新车道节点特征。</li><li>L2A将更新后的地图特征与实时交通信息融合返回给actors。</li><li>A2A处理actors之间的交互，产生输出的actors特征，然后由预测头用于运动预测。</li></ul><p><img src="image-20230517215411529.png" alt></p><h2 id="5-lanercnniros-2021"><a class="markdownIt-Anchor" href="#5-lanercnniros-2021"></a> 5、laneRCNN（IROS 2021）</h2><p>多智能体预测，多模态预测（和LaneGCN一样）</p><p><strong>这是极具挑战性的，因为acotrs有潜在的意图，他们的轨迹受到其他acotrs、他们自己、和地图之间复杂的相互作用的控制。</strong></p><p>本文提出了一种**以图为中心（graph centric）**的运动预测模型LaneRCNN。</p><p><img src="image-20230519105857456.png" alt></p><p>本篇文章中最大的特色就是<mark>LaneRoI：a local lane graph representation per actor</mark></p><ul><li>过去的方法利用一个向量去描述与一个actor相关的所有信息。如：<code>将每个actor过去的动作和周围的地图(或其他上下文信息)编码成一个特征向量，通过将二维光栅化输入卷积神经网络( CNN )，或者直接使用循环神经网络( RNN )计算</code></li><li>但本文中<strong>用一个局部的图</strong>来表示一个actor的状态。</li></ul><p><strong>method</strong></p><ul><li><p><strong>LaneRoI representation</strong></p><ul><li>这是针对每个actor中的，laneRoI中的每个节点都是相对应的actor中的车道段节点</li><li><strong>对于场景中的每个actor i，我们首先检索该actor在预测范围 T 中可能去的所有相关车道，以及在观察到的历史范围 L 中来自的所有相关车道</strong>。（go to  and  come from）</li><li><strong>LaneRoI中车道图中的每个节点对于一段道路，还有一个嵌入来表示其几何（中心，起点坐标及弧度）与语义（是否转弯，红绿灯等）信息，还包含过去的历史轨迹信息</strong></li></ul></li><li><p><strong>Lane Encoder</strong></p><p><img src="image-20230520085503979.png" alt></p><ul><li><strong>Lane Convolution Operator</strong>：laneGCN是用来更新每个acotr的LaneRoI值，对每个actor都计算。</li><li><strong>Lane Pooling Operator</strong>：这里还不是车与车之间的交互，在看到laneroi encode时这里还是对一个actor中的轨迹点进行编码的。</li><li><strong>LaneRoI Encoder</strong>：这里包含了节点更新（用lane GCN）+轨迹特征编码（用lane pooling）</li></ul></li><li><p><strong>LaneRoI Interactor</strong>：用于actor之间的交互</p></li><li><p><strong>Map-Relative Outputs Decoding</strong></p><ul><li>这里<strong>和TNT一样并不是直接预测轨迹，而是学习一个offset</strong></li><li><strong>未来天生是多模态的，行为体可以采取许多不同但可能的未来行动。</strong></li><li>在这里，目标意味着行动者在预测视域末端的最终位置。<strong>注意，行动者大多遵循车道结构</strong>，因此他们的目标通常接近于车道段l。</li><li>对每个actor中LaneRoI中的每个节点都作为未来的endpoint，利用MLP为每个位置输出一个分数，然后输出一个偏移。（这里和目标检测的anchor其实是一致的）。<strong>就是车道被用作先验</strong></li><li>解码器解码的结果式 <strong>从轨迹proposal到真实未来位置的残差。</strong></li><li>这里和 <strong>目标检测也有点像</strong></li></ul></li></ul><p>论文中的laneRoI用的比较多</p><h2 id="6-recog-有异构图2020"><a class="markdownIt-Anchor" href="#6-recog-有异构图2020"></a> 6、ReCoG （有异构图）2020</h2><p><img src="image-20230524141536451.png" alt></p><p>这篇文章中提到的异构图和平常理解的不太一样，本质上看还是同构图。</p><p>预测目标车辆的轨迹</p><p>论文开发了 <strong>ReCoG（递归卷积和图神经网络）</strong>，这是一种通用方案，<strong>将车辆与基础设施信息的交互表示为异构图</strong>，并应用图神经网络（GNN）为轨迹预测的高级交互建模。</p><p>图中的节点包含相应的特征，其中车辆节点包含使用递归神经网络 (RNN) 编码的顺序特征，基础设施节点包含使用卷积神经网络 (CNN) 编码的空间特征。（有两种节点：轨迹和基础设施）</p><p>然后 ReCoG 通过联合考虑所有特征来预测==<strong>目标车辆的未来轨迹</strong>==。</p><p>论文采用的是<strong>encoder-decoder</strong>结构：</p><p>encoder：它由三个编码器( RNN编码器、CNN编码器、GNN编码器)和一个解码器( RNN解码器)组成。</p><ul><li><p>RNN编码器应用于单个车辆的历史状态，</p></li><li><p>CNN编码器应用于局部地图。</p></li><li><p>然后利用GNN编码器提取车辆与道路的交互特征。</p><ul><li><p>采用的是 <strong><mark>有向异构图</mark></strong></p><p><img src="image-20230526162314568.png" alt></p><ul><li>其中包含两种节点，车辆节点和地图节点。</li></ul></li><li><p>为了预测目标车辆的未来轨迹，既要考虑其相邻车辆的序列特征，又要考虑其局部地图的空间特征。（这也是构造图所需要的）</p><ul><li>如果某辆车与目标车辆的距离在 20 米以内，则该车辆被选为目标车辆的邻居。本地地图是一个以目标车辆为中心的 40×40m2 的正方形。</li></ul></li><li><p>为了将交互建模为图，不失一般性，<strong>这项工作将 v1 作为目标车辆，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">v_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 作为地图节点</strong>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>v</mi><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{  v_2,\dots,v_{N-1} \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>是邻居车辆。边集合定义为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>e</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><msub><mo stretchy="false">}</mo><mrow><mo stretchy="false">(</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>∪</mo><mo stretchy="false">{</mo><msub><mi>e</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>1</mn></mrow></msub><msub><mo stretchy="false">}</mo><mo stretchy="false">(</mo></msub><mo stretchy="false">(</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E=\{e_{i,j}\}_{(j=1,\dots,N-1)}\cup\{e_{j,1}\}_((j=1,\dots,N))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">(</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>其中 ei,j 表示从节点 i 到节点 j 的有向边。车辆的顺序特征和地图特征被放入构造的相应节点中，where features are concatenated with an indicator one-hot vector，车辆节点为[0,1]，道路节点为[1,0]。然后应用 2 层 GNN 来提取车辆和道路之间的高级交互。</p></li></ul></li><li><p>将编码后的特征送入RNN解码器，预测目标车辆的未来轨迹。</p></li></ul><p>decoder：将 RNN 解码器应用于交互特征和目标车辆的序列特征的串联（the concatenation of），以预测其未来轨迹。</p><h2 id="7-vehicle-trajectory-prediction-in-connected-environments-via-heterogeneous-context-aware-graph-convolutional-networks-异构图tits-2021"><a class="markdownIt-Anchor" href="#7-vehicle-trajectory-prediction-in-connected-environments-via-heterogeneous-context-aware-graph-convolutional-networks-异构图tits-2021"></a> 7、Vehicle Trajectory Prediction in Connected Environments via Heterogeneous Context-Aware Graph Convolutional Networks （异构图，TITS 2021）</h2><h1 id="车辆轨迹预测"><a class="markdownIt-Anchor" href="#车辆轨迹预测"></a> 车辆轨迹预测</h1><h2 id="1-desire-distant-future-prediction-in-dynamic-scenes-with-interacting-agentscvpr-2017有点难框架比较大可以再好好学学"><a class="markdownIt-Anchor" href="#1-desire-distant-future-prediction-in-dynamic-scenes-with-interacting-agentscvpr-2017有点难框架比较大可以再好好学学"></a> 1、DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents(CVPR 2017)（有点难，框架比较大，可以再好好学学）</h2><p><img src="image-20230315202411542.png" alt></p><p>旨在解决对于<strong>动态场景</strong>中<strong>多个交互智能体</strong>的未来预测任务。通过1 )解释未来预测(也就是说,给定相同的背景,未来可能会有所不同)的多模态性；2 )预见未来的潜在结果并在此基础上做出策略性预测；3 )不仅从过去的运动历史进行推理，而且从场景上下文以及智能体之间的交互进行推理，有效地预测多个场景中物体的未来位置。</p><p>**我们将场景建模为由语义元素(例如道路和人行横道)和动态参与者或智能体(例如汽车和行人)组成。**我们将未来预测建模为在未来的不同时刻确定智能体的位置，仅仅依靠对场景过去状态的观察，以基于图像特征或其他感官数据的智能体轨迹和场景上下文的形式。<strong>该问题是在最大化预测的潜在未来回报的优化框架中提出的</strong></p><p>总共有如下模块：</p><ul><li><p>该模型首先利用条件<strong>变分自编码器</strong>获得一<strong>组多样化的假设未来预测样本</strong>，并通过以下<strong>RNN评分-回归模块</strong>对其进行排序和改善</p></li><li><p>通过对<strong>未来累积回报</strong>的核算，对样本进行评分，这使得类似于 IOC 框架的更好的<strong>长期战略决策成为可能。</strong></p></li><li><p><strong>IOC</strong>：逆最优控制的简称，这将在整篇论文中进行更多的说明。</p></li><li><p><strong>RNN场景上下文融合模块</strong>联合捕获过去的运动历史、语义场景上下文（CNN来捕获）和多个智能体之间的交互。</p></li><li><p><strong>反馈机制</strong>迭代排名和完善（refine）以进一步提高预测准确性</p></li></ul><p>未来的预测可能具有内在的模糊性和不确定性，因为在过去相同的情况(例如,一辆驶向交叉口的车辆可以做出不同的转向,如图1所示)下可以解释多个可能的情景。因此，学习一个直接将{ X，I }映射到Y的确定性函数f，会使潜在的预测空间表示不足，容易过度拟合训练数据。（<strong>因此这里输出的是个多值的，而且有意思的是，这里是利用隐变量生成不同的假设（然后再对这些假设进行操作，ranking和refine，再决策），不是像social lstm中的直接输出分布的参数</strong>）（DESIRE：最大化未来长期奖励，social lstm：最大化后验（或者理解成是采样）概率）</p><p>损失函数：</p><p><img src="image-20230315184920720.png" alt></p><p><img src="image-20230315101635150.png" alt></p><p><img src="image-20230315184729392.png" alt></p><p>同时该论文对KITTI和Stanford drone dataset这两个数据集的原始数据都有处理。</p><p>gpt生成内容：论文 DESIRE：Distant Future Prediction in Dynamic Scenes with Interacting Agents12 是 Namhoon Lee、Wongun Choi、Paul Vernaza、Christopher B. Choy、Philip H.S. 于 2017 年发表的研究论文。 托尔和曼莫汉钱德拉克。 该论文提出了一种新颖的深度学习框架，<strong>用于预测动态场景中多个移动物体</strong>（例如行人、汽车和自行车）的未来位置。 本文解决了考虑未来结果的不确定性和多样性、推理代理之间的交互以及将场景上下文纳入预测模型的挑战。</p><p>该论文介绍了一个CVAE+ Deep Stochastic IOC RNN 编码器-解码器框架 DESIRE，它由四个模块组成：一个条件变分自动编码器 (CVAE) 模块，它根据过去的观察生成未来轨迹的不同样本； 一个 RNN 评分回归模块，根据样本的可能性和奖励对样本进行排名和细化； 一个 RNN 场景上下文融合模块，融合了过去的运动历史、语义场景上下文和代理之间的交互； 以及迭代排序和细化以提高预测准确性的反馈机制。</p><p>该论文在两个公开可用的数据集：KITTI 和斯坦福无人机数据集上评估了所提出的模型。 该论文表明，DESIRE 在四个评估指标上优于几种基线方法：平均位移误差 (ADE)、最终位移误差 (FDE)、best-of-N (BoN) 和 min-of-N (MoN)。 该论文还证明了 DESIRE 可以处理具有多个交互代理和不同场景上下文的复杂场景。</p><h2 id="2-intentnet-learning-to-predict-intention-from-raw-sensor-dataconference-on-robot-learning-2018"><a class="markdownIt-Anchor" href="#2-intentnet-learning-to-predict-intention-from-raw-sensor-dataconference-on-robot-learning-2018"></a> 2、IntentNet: Learning to Predict Intention from Raw Sensor Data(Conference on Robot Learning 2018)</h2><p>动机：1、为了规划安全策略，解决意图不确定性的问题。2、为了解决过去目标检测方法计算效率低（不好落地的自动驾驶车辆上），以及建模高级意图和长期预测的问题。（做到更精准的预测（准确性）+<strong>减少自动驾驶应用程序反应时间</strong>）</p><p>启发：</p><p>1、<strong>受FaF的启发</strong>，本文采用的是多任务联合（jointly）学习。</p><p>2、受<strong>人类驾驶员</strong>的启发：我们设计了一个网络，利用运动和关于道路拓扑的先验知识，其形式是包含语义元素的地图，如车道、交叉口和交通灯。<strong>人类驾驶员通过利用actor过去的动作以及关于场景的先验知识（例如车道的位置、驾驶方向）来理解意图。</strong></p><p>方法：</p><ul><li>输入参数化：包括3D点云的处理和动态地图的处理，one-stage model<ul><li>我们的单阶段模型采用两个 3D 张量作为输入：<strong>体素化</strong> BEV LiDAR 和动态地图的<strong>栅格化</strong>。</li><li>设计了两流主干网络，Backbone network</li></ul></li><li>输出参数化：以离散和连续的形式预测驾驶员的意图。<ul><li><strong>trajectory regression</strong>：对于每个检测到的车辆，我们将其轨迹参数化为一系列边界框，包括当前和未来位置。我们假设车辆是不可形变的物体。每个时间戳中的pose都是3D的包括：BEV坐标中的车辆的边界框的中心+航向。（图a）</li><li><strong>high level actions</strong>：我们将离散意图预测问题构建为具有 8 个类的多类分类：保持车道、左转、右转、左变道、右变道、停止/停止、停放和其他，其中其他可以是任何其他动作，例如如倒车。</li><li>设计了顶部的三个特定于任务的分支网络，Header network。同时还在Intention和motion regression之间加入了一个<strong>残差连接</strong>，目的是提供粗粒度和细粒度的表示。</li></ul></li></ul><p>网络设计：IntentNet 通过由两流主干网络和顶部的三个任务特定分支组成的架构，利用 LiDAR 和地图信息的后期融合。</p><ul><li><p><strong>Backbone network</strong>:我们的单阶段模型采用两个 3D 张量作为输入：<strong>体素化</strong> BEV LiDAR 和动态地图的<strong>栅格化</strong>。我们利用<strong>双流主干网络</strong>，其中两个不同的 2D CNN 分别处理每个数据流。然后将从这些子组件获得的特征图沿着深度维度<strong>连接起来</strong>并馈送到融合子网络。*</p><ul><li>我们在我们的 8x 网络中使用一个小的<strong>下采样系数</strong>，因为每辆车代表 BEV 中的一小组像素，例如，当使用 0.2 m/像素的分辨率时，一辆汽车平均占据 18 x 8 像素。</li><li><strong>为了提供准确的长期意图预测和运动预测，网络需要从过去和场景的几何细节中提取丰富的运动信息以及交通规则信息。</strong></li><li>请注意，车辆在城市场景中通常以 50 公里/小时的速度行驶，仅需 3 秒即可行驶 42 米（短时间内，轨迹比较长）。因此，<strong>我们需要我们的网络具有足够大的有效感受野</strong> [33] 来提取所需的信息。<strong>为了同时保留粗粒度和细粒度特征，我们利用了残差连接</strong> [34]。我们请读者参考图 2b，了解我们网络架构的更多细节。（意图算是一种粗粒度？？？）</li></ul><p><strong>Header network</strong>：头部网络由三个特定于任务的分支组成，它们将来自骨干网络的共享特征作为输入。</p><ul><li><p><strong>检测分支</strong>在每个<strong>特征图位置</strong>为每个anchor box输出两个分数，一个用于车辆，一个用于背景。(二分类任务，看看你是框还是背景)</p><ul><li>anchor 是一个预定义的边界框，其方向作为检测的先验。与 [4, 5, 9] 类似，我们为每个特征图位置使用多个锚点。</li></ul></li><li><p><strong>意图网络</strong>对一组高级动作执行多类分类，为<strong>每个特征图位置</strong>的 8 种可能行为分配校准概率。(<strong><s>也是对正样本(目标检测)???</s></strong>,这里只是对特征图,不是对锚框)</p><ul><li>离散的意图分数依次被馈送到嵌入卷积层中，以提供额外的特征来调节运动估计。（残差连接的那个？）</li></ul></li><li><p><strong>运动估计</strong>分支接收共享特征的连接和来自高级动作分数的嵌入，<strong>并输出每个特征图位置处每个锚框的</strong>预测轨迹。</p><ul><li>我们将加权平滑 L1 损失应用于仅与<strong>正样本关联</strong>的回归目标。</li><li><code>我有一点猜测就是意图在这其实意图的话可能起到一定的指导或者是约束作用</code></li></ul></li><li><p>这里强调了一个:<strong>每个特征图位置,有点像faster-rcnn中的RPN</strong></p><p><img src="image-20230329222741641.png" alt></p></li></ul></li></ul><p>本文有一个很有特色的想法就是<strong>将目标检测+轨迹预测+意图预测结合起来</strong>，构成了一个端到端的训练，不仅提高了精度同时还提高了计算效率。</p><p>想法：<strong>因此我们是否可以也考虑这种端到端的多任务联合学习，共同优化的模型。或许说，在多任务的共同驱动下，联合学习下，我们学到的特征，等信息更加与我们的最终目标相合。同时这种学习训练模式说不定可以对这些个任务都有提升作用，这种任务驱动。</strong></p><ul><li>因此我们接下来也可以阅读其他方向的相关文献，同时可以考虑这可以和什么任务结合起来。</li></ul><h2 id="3-multipath-multiple-probabilistic-anchor-trajectory-hypotheses-for-behavior-predictionconference-on-robot-learning-2019"><a class="markdownIt-Anchor" href="#3-multipath-multiple-probabilistic-anchor-trajectory-hypotheses-for-behavior-predictionconference-on-robot-learning-2019"></a> 3、MultiPath: Multiple Probabilistic Anchor Trajectory Hypotheses for Behavior Prediction(Conference on Robot Learning 2019)</h2><p>**在TNT的related work的描述中有这样一段话：<strong>最近，MultiPath [33] 和 CoverNet [34] 选择将轨迹量化为锚点，其中</strong>轨迹预测任务被重新表述为锚点选择和偏移回归。**锚点要么预先聚类成一个固定的先验集[33]，要么基于运动学启发式[34]动态获得。</p><p><img src="image-20230325102658410.png" alt></p><p>动机：准确预测未来的概率分布，建模未来的不确定性和多模态性。提出一个具有多样性和覆盖率的模型。同时还为了解决过去单一轨迹输出和无权重多轨迹输出的缺点。</p><p>（过去的方法要么是单一轨迹输出（单峰分布），要么是无权重的多轨迹输出，这些有很大的缺陷，本文试图提出一种具有覆盖性和多样性的多轨迹（多模态+加权）的模型）</p><p>【过去单一轨迹输出和无权重多轨迹输出的缺点：当涉及到自动驾驶车辆等实际应用时，基于样本的方法有许多缺点：(1) 安全关键系统中的非确定性，(2) 对近似误差的处理不佳（例如， . “我必须抽取多少样本才能知道行人乱穿马路的几率？”），（3）没有简单的方法来对相关查询执行概率推理，例如计算时空区域的期望（<strong>这个缺点的后两点有点抽象</strong>）</p><p>同时还解决POG（<strong>概率状态空间占用网格</strong>）存储多，不易操作，且轨迹提取不明显等缺点】</p><p>本文建模的关键视角：（包括在TNT、DenseTNT中都有体现。）</p><ul><li><strong>分层地考虑随机不确定性：</strong>（<strong>算不算是一种多任务学习，jointly优化</strong>）（<strong>进行了一定程度的解耦</strong>）<ul><li>首先，<strong>意图不确定性</strong>捕获了代理打算做什么的不确定性，并被编码为锚轨迹集上的分布。</li><li>其次，给定一个意图，<strong>控制不确定性</strong>代表我们对他们如何实现它的不确定性。control uncertainty represents our uncertainty over how they might achieve it.<ul><li><strong>文章假设控制不确定性在每个未来时间步呈正态分布</strong>（也就是说轨迹呈正态分布），参数化使得均值对应于锚状态的特定上下文偏移量，相关协方差捕获单峰任意不确定性</li></ul></li></ul></li></ul><p><strong>本文启发</strong>：受目标检测和人体姿态估计中预定义锚点的启发：<strong>我们先验地估计我们的锚点，然后再修复它们以学习我们的其余参数。</strong></p><p>方法：</p><ul><li><p>数据输入（特征处理，建模过去和场景）：将动态和静态场景上下文的历史表示为从<strong>自上而下</strong>的正交视角呈现的 3 维数据数组。前两个维度表示自上而下图像中的空间位置。<strong>深度维度中的通道包含固定数量的先前时间步长的静态和时变（动态）内容。</strong></p></li><li><p>以特征图的智能体为中心：<strong>heading-normalization（朝向归一化）</strong></p><ul><li><strong>为了方向不变</strong>，提取的特征也通过<strong>可微分的双线性扭曲</strong>旋转到<strong>以主体为中心的坐标系</strong>（<code>驾驶员视角，第一人称视角</code>）。（这里就是以主体为中心（原点））（方向不变可以直接采用左右等，不用旋转）</li></ul></li><li><p>不确定性建模：</p><ul><li><p><strong>意图不确定性建模</strong>：anchor选择，采用的时K-means。对于一些特殊的数据集。对于一些数据集，直接均匀采样轨迹空间来获取锚点。（<strong>锚点要么预先聚类成一个固定的先验集</strong>）</p></li><li><p><strong>控制不确定建模</strong>：本文假定在给定意图的情况，<strong>每个<s>路</s>点的控制不确定性是单峰的</strong>，本文用的是正态分布。</p><p><img src="image-20230326090949035.png" alt></p><p>同时锚点的重要性权重不随时间改变而改变（即其中混合权重在所有时间步长上都是固定的），因此在形式上形成了：GMM，高斯混合分布</p><p><img src="image-20230326091023341.png" alt></p><p>这应该也是选择正态分布的原因。（对于总体来看如公式（2）和对于每个时间点来看，不同的anchor或<s>路</s>点加权组合都是GMM）</p><ul><li>从总体的角度来看需要另外一个假设：给定意图的情况下，不同时间步之间相互独立。这样可以保证正态分布的乘积还是正态分布。</li><li><strong>很神奇的构建方法</strong></li></ul></li><li><p><strong>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>μ</mi><mi>t</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">\mu_t^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.096108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 表示与锚状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>t</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">a_t^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.096108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 的场景特定偏移量</strong>。其中我们同归对这个偏移量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>μ</mi><mi>t</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">\mu_t^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.096108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>进行学习，回归，来调整这个正态分布的位置。（<strong>相当于偏移回归</strong>）</p></li></ul></li></ul><p><strong>这里有3个思想沿用到了TNT中：</strong></p><p>1、在给定意图的情况下不确定性是单峰的（这里假设的每个<s>路</s>点的控制不确定性高斯分布）</p><p>2、给定anchor下，不同时间步之间的分布是互相独立的</p><p>3、分层建模总不确定性</p><h2 id="4-tnttarget-driven-trajectory-predictionconference-on-robot-learning-2020"><a class="markdownIt-Anchor" href="#4-tnttarget-driven-trajectory-predictionconference-on-robot-learning-2020"></a> 4、TNT：Target-driveN Trajectory Prediction（Conference on Robot Learning 2020）</h2><p>任务困难：预测移动智能体的未来行为对于现实世界的应用至关重要。它具有挑战性，因为<strong>主体的意图和相应的行为是未知的和内在多模态的。</strong></p><p><strong>论文的动机</strong>：是为了解决多代理轨迹预测问题中的不确定性和多样性，以及提高轨迹预测的准确性和可解释性。（下面这些可以算是解决问题）</p><ul><li>对未来预测的一个关键挑战是高度的不确定性，在很大程度上是由于不知道其他代理的意图和潜在特征。</li><li>将任务建模成隐变量的形式，一个是无法解释，难以融入专家的知识，此外，这些模型需要从潜在空间进行随机抽样，以获得运行时的隐式分布。这些特性使得它们不太适合实际部署，另一个就是可能奔溃。</li></ul><p><code>为了克服这些限制，我们观察到，对于我们的任务(例如,车辆和行人轨迹预测)，在一个适度长期未来中的不确定性可以通过对代理可能的目标的预测来捕捉。这些目标不仅基于可解释的物理实体(如位置)，而且与意图(例如换道或右转)有很好的相关性。我们猜想目标的空间可以在场景中离散化- -允许确定性模型并行地生成多样化的目标- -然后再细化以更精确。</code></p><p>论文见解：<strong>我们的关键见解是，在一个适中的时间范围内进行预测，未来的模式可以被一组目标状态有效地捕获。</strong>（现在这里的适中还是之短期预测，包括后面的假设：<strong>轨迹（从初始状态到目标）的分布是单峰的，也就是说是单意图的。</strong>）</p><p><img src="image-20230318165052923.png" alt></p><p>论文的方法：1、场景上下文建模，对于HDmap采用VectorNet；对于场景的上下文是以自顶向下的图像形式提供的，论文中采用的是ConvNet，用的是Resnet-50。</p><p>**首先将未来预测问题转化为预测离散目标状态上的分布，然后建立一个概率模型，其中轨迹估计和似然以这些目标为条件。**由此得到的框架有三个stage，端到端训练：<strong>论文将未来的不确定性分解成了两个部分：目的或意图的不确定性；控制的不确定性</strong></p><ul><li><strong>目标预测</strong>在给定场景上下文的情况下估计<strong>候选目标</strong>上的分布，选出target；（<strong>用来建模目的或意图的不确定性</strong>）（输出目标偏移+分数）</li><li><strong>目标条件运动</strong>估计预测每个目标的轨迹状态序列；（<strong>用来建模控制的不确定性，stage3也有一点，选择一些分数大的轨迹</strong>）</li><li><strong>评分和选择</strong>估计每个预测轨迹的可能性，同时考虑所有其他预测轨迹的上下文。<ul><li><em>我们通过对可能性进行排序并抑制冗余轨迹，得到最终的紧凑多样化预测集。</em>（<strong>multimode</strong>）</li></ul></li></ul><p><strong>这里有一个很有意思的想法就是离散化处理（避免一些不合理的结果）和单峰（初始到某个目标之间意图单一（概率最大的那个or似然函数最大的那个））</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">id1[N Target Candidates]</span><br><span class="line">id2[M targets]</span><br><span class="line">id3[M trajectories]</span><br><span class="line">id4[K trajectories ]</span><br><span class="line">id1--&gt;id2--&gt;id3--&gt;id4</span><br></pre></td></tr></table></figure><p><img src="image-20230318112030687.png" alt></p><p>关于坐标位置：我们将矢量坐标归一化为在<strong>最后观察到的时间步</strong>以目标agent的位置为中心（<strong>endpoint,最后一个观察点（预测的不叫观察点）</strong>）（应该mmtransformer一样，这里没有详细说明）</p><h2 id="5-densetnt-end-to-end-trajectory-prediction-from-dense-goal-setsiccv-2021"><a class="markdownIt-Anchor" href="#5-densetnt-end-to-end-trajectory-prediction-from-dense-goal-setsiccv-2021"></a> 5、DenseTNT: End-to-end Trajectory Prediction from Dense Goal Sets(ICCV 2021)</h2><p><img src="image-20230322111347868.png" alt></p><p><strong>动机</strong>：为了解决之前工作基于<strong>预定义or启发式的</strong>，<strong>稀疏的</strong>锚点的方法的缺陷，以及解决<strong>人类行为的随机性</strong>。建模真实道路上的分布</p><p><strong>Dense TNT</strong> :an anchor-free and end-to-end multi-trajectory prediction method.</p><ul><li>作为特征输入，历史轨迹处理这里用的时<strong>VectorNet</strong></li><li>Dense TNT首先从场景上下文中生成<strong>概率密集</strong>的目标候选；</li><li><strong>从目标概率出发</strong>，它进一步使用目标集预测器 (goal set predictor,这是一个online 学习) 来产生最终的轨迹目标集</li><li>最后直接从<strong>密集的候选</strong>goal中输出一组轨迹</li><li>与之前的方法相比，Dense TNT<strong>更好地建模了目标候选者</strong>，<strong>摆脱了后处理。</strong></li><li><strong>anchor-free</strong>+end -to-end（<strong>端到端的训练方式来选择目标</strong>）</li></ul><p>Dense TNT中的<strong>目标集预测是一个多标签预测问题</strong>，需要多个标签作为训练目标。</p><p><img src="image-20230322220926067.png" alt></p><p><strong>重要思想</strong></p><ul><li>dense：提供一个<strong>更细粒度局部信息</strong></li><li>除此之外还理由<strong>基于离线优化的技术</strong>为我们的模型提供了多个未来的<strong>伪标签</strong><ul><li>（端到端的训练）（利用<strong>离散模型</strong>来<code>花时间寻找最优解（全局）</code>来<strong>端到端</strong>训练一个效果相当（与离散模型相比），但是计算时间短，且跟稳定的<strong>目标集预测器</strong>）</li><li>同时也解决了NMS算法的局部最优性</li><li><strong>（离散模型就像一个优化器来为我们寻找最优的参数）</strong></li></ul></li></ul><h2 id="总结1"><a class="markdownIt-Anchor" href="#总结1"></a> ########总结1#########</h2><p>像TNT，multipth，DenseTNT，<s>IntentNet</s>等这样的算法都有一个潜在结构：未来不确定性=意图+控制。（TNT，DenseTNT，Multipath：基于goal ，tnt和multipath还可以划分为基于anchor）（这几篇论文都是在注重预测方法，对于如何去建模过去的轨迹和场景，介绍的不是很详细（multipath还稍微详细一点））</p><ul><li>也就是说我们先来估计<strong>意图的不确定性</strong>（这个地方也体现了一个<strong>multimodal</strong>），比如IntentNet估计一些确定的语义明确的意图，而TNT，multipth估计一个稀疏的无语义的意图，DenseTNT估计了一个密集的无语义的意图。</li><li>然后就是<strong>控制不确定性</strong>：TNT中有一句话描述的很好：例如执行转弯所需的细粒度运动。这里的话就相当于为意图or目标去制定细粒度的预测轨迹了。</li></ul><p><strong>还有一点是我们可以不局限于轨迹预测，行文预测这一个方向上，可以阅读阅读其他方向上的论文。像Multipath和TNT都有受到目标检测中部分方法和思想的启发。</strong></p><p>TNT中的那些个target个人认为可以理解成栅格化处理一样（类似于，或者思想上相同。那么能否利用栅格化处理了（用卷积网络），也就是说用卷积网络去处理栅格化的一些个goal（并且失活掉一些网格，<strong>稀疏化表示（？？？？，其实目标的选择就是在一个大的栅格化矩阵的稀疏化表示，大部分为零，只选择有用的）</strong>，但这样的化可能就像直接POG那样，复杂难处理，所需要的参数可能也多），不用预定义（TNT，multipath）也不用离线优化模型去训练（DenseTNT））</p><p><s><strong>TNT，DenseTNT，IntentNet，multipath都是多智能体预测，可以为每个智能体都预测轨迹，就像DESIRE</strong></s></p><h2 id="问题1"><a class="markdownIt-Anchor" href="#问题1"></a> ！！！！！！！问题1！！！！！！！！！！</h2><p><strong>关于这些论文到底是直接预测单个智能体的轨迹，每个智能体都可以用这个方法。</strong></p><p>我看了一下vectornet，应该是输出单个智能体的轨迹，因为再其论文最后有提到一点： Note that, as we need to re-normalize the vector coordinates and re-compute the VectorNet features for <strong>each target</strong>, the FLOPs increase linearly with the number of predicting targets (n in Table 4).同时再multipath中有提到一个航向归一化这个也是针对每个智能体而言的。<strong>因此论文中的模型对每个模型都可以用，但是对智能体轨迹输出</strong></p><p><strong>因此multipath，TNT，这些论文应该并不是输出对各智能体的轨迹，因该还是单个智能体的轨迹。但是是多模态的。</strong></p><p><strong>要想知道是单智能体还是多智能体，不仅得看模型的输入和输出，损失函数，还得看代码的输入和输出</strong></p><h2 id="问题2"><a class="markdownIt-Anchor" href="#问题2"></a> ！！！！！！！问题2！！！！！！！！！！</h2><p>像TNT，DenseTNT，Multipath这些个论文，<strong>他们是如何利用其余的智能体的未来的轨迹的了</strong>。因为他们都有一个条件独立性的假设，这样的话就可以基于当前的状态去预测未来的一段轨迹。因此这个地方是如何利用其余智能体未来轨迹的，我存在疑问。</p><p><strong>也就是并行计算和串行计算哪个更好</strong></p><h2 id="6-trajectron这个还有一个榜刷eccv-2020"><a class="markdownIt-Anchor" href="#6-trajectron这个还有一个榜刷eccv-2020"></a> 6、trajectron++（这个还有一个榜刷）(ECCV 2020)</h2><h2 id="7-multimodal-trajectory-predictions-for-autonomous-driving-using-deep-convolutional-networksicra-2019"><a class="markdownIt-Anchor" href="#7-multimodal-trajectory-predictions-for-autonomous-driving-using-deep-convolutional-networksicra-2019"></a> 7、Multimodal Trajectory Predictions for Autonomous Driving using Deep Convolutional Networks(ICRA 2019)</h2><p><strong>论文中有提到一个这样的概念：best human drivers.（最佳人类驾驶员。）如何考虑最佳人类驾驶员是一个问题</strong></p><p><img src="image-20230403100931069.png" alt></p><p><strong>论文提出了一个用于解决模式崩溃的损失函数：<em>MTP</em></strong></p><p><strong>multimodal+预测多个agent（actor）的轨迹</strong></p><p>动机：解决自动驾驶的一个关键部分：正确预测周围参与者的运动，同时考虑到它们固有的多模态性质。解决准确的长期交通预测所需的未来可能轨迹的潜在多模态问题。解决模式崩溃问题。</p><p>方法：</p><ul><li>栅格化输入，通过CNN处理在flatten后得到栅格化特征，然后与状态输入concat<ul><li>在这项工作中，我们将任务简化为推断第i个参与者的未来x -和y -位置，而<strong>不是完全状态估计，而剩余的状态可以通过考虑sij和未来位置估计得到</strong>。</li><li>它以一幅分辨率为0.2 m的特定行为体的300 × 300 RGB栅格图像和<strong>行为体当前状态(速度、加速度和航向变化率)作为输入</strong>，输出未来x和y位置的M个模式(每模式2H输出)及其概率(每个模式一个标量)。</li></ul></li><li>多模态优化函数：使用<strong>新颖的</strong> <strong>多轨迹预测（MTP）损失</strong>，其动机是[37]，它<strong>明确地模拟了轨迹空间的多模态。</strong><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="script">L</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>M</mi><mi>T</mi><mi>P</mi></mrow></msubsup><mo>=</mo><msubsup><mi mathvariant="script">L</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msubsup><mo>+</mo><mi>α</mi><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><msub><mi>I</mi><mrow><mi>m</mi><mo>=</mo><msup><mi>m</mi><mo>∗</mo></msup></mrow></msub><mi>L</mi><mo stretchy="false">(</mo><msub><mi>τ</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>τ</mi><mo>~</mo></mover><mrow><mi>i</mi><mi>m</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{ij}^{MTP}=\mathcal{L}_{ij}^{class}+\alpha\sum\limits_{m=1}^MI_{m=m^*}L(\tau_{ij},\tilde{\tau}_{imj})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.4954490000000003em;vertical-align:-0.9671129999999999em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5283360000000004em;"><span style="top:-2.132887em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0000050000000003em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop op-symbol small-op">∑</span></span></span><span style="top:-3.950005em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9671129999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28284em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li><li>α 是用于权衡这两种损失的超参数。*<em>换句话说，我们强制最佳匹配模式 m</em> 的概率尽可能接近 1，并将其他模式的概率推到 0。**请注意，<strong>在训练期间，位置输出仅针对获胜模式进行更新，而更新所有模式的概率输出。</strong></li><li><strong>这导致每种模式专门针对不同类别的参与者行为（例如，直行或转弯），并成功解决了模式崩溃问题。</strong></li><li>同时对于距离函数：从actor位置看到的两条轨迹的最后一点之间的角度来测量距离</li></ul></li><li>上述是单次前向计算</li><li><strong>Lane-following  model</strong>（这里介绍的不多，而且应该是独立的一块）<ul><li><strong>隐式</strong>的输出多条轨迹的方法</li><li><strong>假设知道可以遵循的可能车道和过滤不太可能车道的车道评分系统</strong>，我们添加另一个光栅化层来编码此信息并训练网络输出车道跟踪轨迹。</li><li><strong>然后，对于一个场景，我们可以生成多个光栅，其中包含要遵循的各种车道，从而有效地推断出多个轨迹</strong></li><li>这里利用生成多个光栅来推断多个轨迹。和上面的操作还不一样</li></ul></li></ul><h2 id="8-multimodal-motion-prediction-with-stacked-transformerscvpr2021"><a class="markdownIt-Anchor" href="#8-multimodal-motion-prediction-with-stacked-transformerscvpr2021"></a> 8、Multimodal Motion Prediction with Stacked Transformers(CVPR2021)</h2><p><img src="image-20230405180752159.png" alt></p><p><img src="image-20230407111702071.png" alt></p><p><img src="image-20230406174355707.png" alt></p><ul><li><p><strong>多模态预测旨在生成目标车辆的多个似是而非的轨迹，在处理运动预测中的不确定性和提高运动规划的安全性方面起着关键作用。</strong>（文章解释了什么是multimodal）</p></li><li><p><strong>the motivation behind our framework is to establish the intra-relation inside data</strong></p></li><li><p><code>社会关系应该基于个体车辆特征来构建</code>(<em>the social relation should be constructed based on individual vehicle features.</em>)（这个是模型堆叠顺序的解释）</p></li></ul><p>论文动机：1、解决如何学习用有限的训练样本去覆盖场景中给定所有的结果的问题——提出了<strong>RTS（region-based strategy）。<strong>2、学习数据的内部联系：（1）解决预定义proposal的问题，proposal-based的问题（2）同时解决feature-based的问题(很难保证多模态预测) （3）如何将多个信息通道作为输入融合到transformer中去（有效多种信息融合）——提出了</strong>mmtransformer（采用了stacked架构）</strong></p><p>方法：论文提出了一种stacked架构</p><ul><li><p>stacked transformer的结构分别由三个单独的transformer单元</p><ul><li><p>motion extractor</p></li><li><p>map aggregation</p><ul><li>这里用到了vectornet中的vector表示和子图网络提取。</li></ul></li><li><p>social constructor</p><ul><li><strong>社会构造模块对所有观察到的车辆的车辆特征进行编码，旨在模拟它们之间的相互作用。</strong></li><li>我们<strong>只利用社会构造器的解码器来更新目标车辆的proposal</strong>，而不是所有车辆。</li></ul></li><li><p><strong>当然还有位置编码</strong></p></li><li><p><strong>每个transformer都将来自前一个transformer的更新的轨迹proposal作为其解码器的输入以改进proposal</strong></p></li><li><p>从图上看，除了social constructor之外，其余两个网络的proposal好像都是输入所有agent的而只有social 的从上图constructor的decoder输入的只有目标agent的proposal。</p></li></ul></li><li><p>RTS（region-based strategy）</p><ul><li><p>我们提出了一种称为<strong>基于区域的训练策略 (RTS) 的新型训练策略</strong>，该策略根据<strong>真值端点的空间分布</strong>将轨迹proposal分组为几个空间集群，并优化框架以改善每个集群内的预测结果。</p><ul><li>我们首先<strong>旋转场景</strong>，<strong>使目标车辆的航向与+y轴对齐，并使所有坐标以目标车辆的最后一个观察点为中心</strong>。（确定坐标原点以及坐标轴方向。）</li><li>在此基础上，我们将目标车辆的样本空间划分为 M 个区域，它们之间没有任何重叠。</li><li>区域形状和区域数量的详细分析在4.3节中进行了说明，分区过程在附录中进行了说明。</li><li>之后，我们将 mmTransformer 的<strong>总共 K 个提议平均分成 M 个部分，每个部分分配给一个特定的区域。</strong>（这里的M个部分正好对应上面的M个）</li><li>因此，<strong>每个区域将拥有 N 个单独的proposal，其中 N = K/M</strong>。值得注意的是，我们工作中的预处理确保<strong>所有样本</strong>都可以共享相同的分区图。（所有样本共享分区图）</li></ul></li><li><p><strong>我们计算的是分配给真值端点（endpoint）所在区域的所有提案的损失，而不是最接近地面实况的proposal。</strong>（也就是说我们只利用选定区域的，其余的不用）通过这种方式，我们以基于区域的方式改进多模态结果，从而优化一个区域的预测而不影响任何其他区域。</p></li></ul></li><li><p>这里的实验部分也有意思，在消融实验中，考虑了区域划分的一个对比（手工还是基于约束的K-means方法，结果是手工好一点）</p></li></ul><h2 id="9-home-heatmap-output-for-future-motion-estimationitsc-2021"><a class="markdownIt-Anchor" href="#9-home-heatmap-output-for-future-motion-estimationitsc-2021"></a> 9、Home: Heatmap Output for future Motion Estimation（ITSC 2021）</h2><p><strong>Home：一个处理运动预测问题的框架，其图像输出表示智能体未来位置的概率分布。</strong></p><p><strong>为了捕捉驾驶场景的复杂性，预测模型需要考虑局部地图、被预测智能体的过去轨迹以及与其他行为体的交互。</strong></p><p>它的<strong>输出需要是多模态的</strong>，以涵盖驾驶员在直行或转弯、减速或超车之间的不同选择。提出的每个模态应该代表一个智能体在不久的将来可以采取的可能轨迹。</p><p><strong>挑战</strong>：运动预测的挑战不在于拥有与地面真实最接近的绝对轨迹，而在于避免一个可能性没有考虑到的大失败，所有模态都完全错过了未来。（<strong>这里的意思因该就是说，我们要尽可能的考虑所有所有的可能性，不漏，避免错过未来</strong>）</p><p><img src="image-20230421112840977.png" alt></p><p>论文提出了过去方法的两个问题：：1、数据没有充分利用，模态的训练不到位；2、预测空间限制为受限表示</p><p><strong>论文贡献</strong>：</p><ul><li><p>我们提出了一个由卷积神经网络 (CNN)、递归神经网络 (RNN) 和注意力模块组成的简单模型架构，<strong>带有热图输出</strong>，可以轻松高效地进行训练。</p><ul><li><p>过去信息和局部场景信息编码：</p><ul><li><p><em>map and past trajectory encoding</em></p><ul><li>这里面提到了个<strong>UGRU</strong>层</li></ul></li><li><p><em>Inter-agent attention for interaction</em></p></li><li><p><em><strong>Increased output size for longer range</strong></em>（通过多个层增加输出大小同时保持空间对应关系。）</p></li></ul></li><li><p>Heatmap out</p><ul><li><p>因为我们是监督学习：The output target is an image Y with a Gaussian centered around the ground truth position.</p><ul><li><p>这个输出目标是真值heatmap，因为我们进行有监督训练<strong>需要真值</strong>。<strong>这张heatmap是由真值终点为中心点</strong>，按照高斯分布（标准差为4pixel）生成的</p></li><li><p>采用像素级的焦距损失</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>P</mi></mfrac><munder><mo>∑</mo><mi>p</mi></munder><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>p</mi></msub><mo>−</mo><msub><mover accent="true"><mi>Y</mi><mo>^</mo></mover><mi>p</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>f</mi><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>p</mi></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>Y</mi><mo>^</mo></mover><mi>p</mi></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext> </mtext><mi>f</mi><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>p</mi></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>Y</mi><mo>^</mo></mover><mi>p</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mover accent="true"><mi>Y</mi><mo>^</mo></mover><mi>p</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi><mtext> </mtext><msub><mi>Y</mi><mi>p</mi></msub><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>Y</mi><mi>p</mi></msub><msup><mo stretchy="false">)</mo><mn>4</mn></msup><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mover accent="true"><mi>Y</mi><mo>^</mo></mover><mi>p</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>e</mi><mi>l</mi><mi>s</mi><mi>e</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">L=-\frac{1}{P}\sum_p(Y_p-\hat{Y}_p)^2f(Y_p,\hat{Y}_p)\\with\ f(Y_p,\hat{Y}_p)=\begin{cases}\log(\hat Y_p)&amp;if\ Y_p=1\\(1-Y_p)^4\log(1-\hat Y_p)&amp;else\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.707553em;vertical-align:-1.386113em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.386113em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.232878em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.232878em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li></ul></li></ul></li></ul></li><li><p>我们根据这个热图输出设计了两种采样算法，分别优化 MRk 或 minFDEk</p></li><li><p>我们强调了两个指标之间的权衡，并表明我们的采样算法允许我们使用一个简单的参数来控制这种权衡</p></li></ul><p><strong>method</strong>：</p><ul><li>我们首先用<strong>二维概率热图表示可能的未来分布</strong>，该热图给出了agent位置概率的无约束近似值。</li><li>（<strong>热图像素点级别</strong>）<ul><li>该热图表示为方形图像，它自然适用于多模式预测，其中每个像素代表目标代理的未来可能位置。它还能够在概率分布中充分描述未来的不确定性，而无需选择其模式或方式。</li><li>这个地方有点像DenseTNT</li></ul></li><li>在第二步中，我们从热图中采样有限数量的未来可能位置，并有可能在<strong>不重新训练模型的情况下</strong>选择我们想要优化的指标。<ul><li>MR优化，采用了贪婪算法（论文中没细讲）</li><li>FDE优化，受KMeans启发来优化FDE<ul><li><strong>我们使用Miss Rate优化算法的结果初始化质心</strong>，并使用迭代次数L作为参数来调整Miss Rate和FDE之间的权衡。<ul><li>当L为0时Miss Rate是最优的</li><li>L增大MR被牺牲以获得更好的FDE</li></ul></li></ul></li></ul></li><li>最后，我们根据过去的历史并以采样的最终点为条件构建完整的轨迹。</li></ul><p><strong>实验部分的一些细节</strong>：</p><ul><li>Metric中还报告了测试集的度量指标p - minFDE6和p - minADE6，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-\log(p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span>被添加到度量指标中，<strong>p是分配给最佳(最接近地面真相)预测轨迹的概率。</strong></li><li>在实现细节中说明了：<ul><li><strong>每个样本帧以目标agent为中心并与其航向对齐。</strong>（如何操作的看代码**！！！！！！！！！！**）</li><li><strong>数据增强</strong>：我们以0.1的概率丢弃每个光栅通道，并在50 %的样本中以[ -π / 4 , π / 4]的均匀随机角度旋转帧来增加训练数据。</li></ul></li></ul><p><strong>总结</strong>：</p><ul><li>文章这里提出了一种新的采样方式。我们主要的是生成热图。因此模型会对热图去进行优化。</li><li>得到热图后我们会根据设置的k，去进行采样，先进行MR的优化，用来选取初始的centroid（质心），然后再优化FDE（借助了KMeans的训练方法。）当然这两个优化会进行权衡<ul><li><code>包括heatmap到这里，其实与Dense TNT有异曲同工之妙</code></li></ul></li><li>轨迹生成部分是一个独立的模块</li><li><strong>这里既可以解决每个anchor（proposal）模态的训练不足的问题。同时也可以解决proposal不足的问题（受限问题），因为模型优化的是概率热图（heatmap）</strong></li><li><strong>这里有个很有意思的想法，的heatmap学习相当于是将模态和模型解耦开来了</strong></li></ul><p><code>但这个操作是整图级别的，计算复杂度比较高</code></p><h2 id="总结2"><a class="markdownIt-Anchor" href="#总结2"></a> ！！！！！！！！总结2！！！！！！！！</h2><p>关于坐标定位的问题。<s>暂时看来有两种：（</s><strong>都是针对最后一个观察点，预测的不叫观察点</strong>）（如果预测的第一步为1，那最后一个观察点为0）</p><p>1、以TNT，mmtransformer，vectornet为例的以<strong>最后一个观察点</strong>为坐标中心。（最后一个观察点）</p><ul><li>mmtransformer使<strong>目标车辆的航向与+y轴对齐</strong>，并使所有坐标以目标车辆的最后一个<strong>观察点</strong>为中心。</li><li>TNT没详细说明。</li><li>vectornet：为了使输入节点特征对目标agent的位置保持不变，我们将所有向量的坐标归一化到目标agent在其最后一个观测时间步的位置。</li></ul><p>2、multipath为例的航向归一化：这里应该也是最后一个观察点。然后再进行预测</p><p>3、Home中也提到了航向归一化。应该也是最后一个观察点（也就是训练样本的最后一个（不是标签））。</p><h2 id="10-gohomegraph-oriented-heatmap-output-for-future-motion-estimationicra2021"><a class="markdownIt-Anchor" href="#10-gohomegraph-oriented-heatmap-output-for-future-motion-estimationicra2021"></a> 10、GOHOME：Graph-Oriented Heatmap Output for future Motion Estimation（ICRA2021）</h2><p>我认为该论文的一个主要动机就是解决HOME的计算复杂度搞得问题。提出了两个见解：</p><ul><li><strong>实际道路和可行驶区域占用的空间要稀疏得多</strong>。就是我们不用对image的全部计算，计算关键区域。<ul><li>在大多数时间范围为3s的城市驾驶预测中，192m的图像范围(每个方向可达88m )可能是足够的，而其他数据集可能需要6或8秒的预测[ 42 ]，[ 44 ]。因此有必要增加这种输出范围。</li></ul></li><li>全卷积的计算复杂度高，我们可以采用GNN编码</li></ul><p><strong>同时强调Heatmap的作用性，同时还强调了Heatmap可以用来ensemble</strong></p><p>论文提到的两个不确定性：轨迹预测本质上面临诸多不确定性。这些不确定性可以分为两类：aleatoric and epistemic</p><p>（<strong>控制不确定和意图不确定性</strong>？？？？）</p><p>（<strong>这里可以看实验的定性分析那一块：qualitative results</strong>）</p><ul><li>Aleatoric uncertainty is the natural randomness of a process<ul><li>它是控制噪声的结果，会导致加速度、曲率、</li><li>它转化为可能的未来位置的传播，通常通过在运动估计中使用<strong>高斯预测来解决[ 1 ]，[ 2 ]</strong>。</li></ul></li><li>Epistemic uncertainty outlines some knowledge that can’t be known by the observer at prediction time（认知不确定性概括了一些在预测时刻观察者无法获知的知识）<ul><li><strong>汽车的目的地是什么</strong>，它会选择靠左超车还是留在后面?最近的方法使用基于锚点[ 3 ]、[ 4 ]、预定义学习头[ 5 ]或可用的HD - Map [ 6 ] - [ 9 ]的多模态输出来覆盖这些可能的操作的跨度。</li></ul></li></ul><p><img src="image-20230422093723079.png" alt></p><p><img src="image-20230422095542546.png" alt></p><p><strong>Method</strong>：<em>GNN+lane raster+lane rank</em>:<strong>可以提高计算效率，同时还有利于范围的缩放和提供更精细的分辨率</strong></p><p>其目标是输出一个热力图，该热力图表示未来给定时刻智能体的位置。</p><p>车道线代表道路(平均10 ~ 20米)的一个<strong>宏观断面</strong>，因为我们的**目标是在宏观层面(车道线)而不是微观层面(每米)编码连通性。**我们将每个车道编码成一个道路图，其中表示几何和连通性信息。</p><p>每个车道被定义为一系列中心线点，如果它们存在，则连接到它的前一个、后一个、左和右邻居（都是车道级的，不是像素级的。）</p><ul><li><p>Graph neural network for HD-Map input</p><ul><li>这里的智能体交互用的是self-attention</li><li>论文用的图卷积操作类似于：《Learning lane graph representations for motion forecasting》<ul><li>VectorNet [ 16 ]和TNT [ 6 ]也使用了车道线，称为折线，但它们通过全局注意力连接，而不是使用图连接。<strong>我们选择在车道线上使用一个GNN，因为我们想要一个高效和高级的表示，使信息能够轻松地通过图传播，同时仍然利用连通性。</strong></li></ul></li><li>Heatmap generation through Lane-level rasters<ul><li>lane raster generation：这里面用到了Frenet-Serret，沿车道的 Frenet-Serret 参考的离散化，并生成热图。这里的损失采用的是和</li><li>lane ranking：用于车道选择，<s>在像素级损失上增加了一个二值交叉熵</s>（<code>（但这里也没有详细说明，我总觉得这里就是一个二值交叉熵，因为我们此时还没有和heatmap）</code>）。我们用分类的分数来排序。（<strong>选择的车道用于lane raster</strong>）<ul><li><strong>由于只有车道的一小部分将实际有用的代表未来的汽车位置，我们可以计算车道级栅格只为车道的子选择，节省更多的计算。</strong></li></ul></li><li><code>然后为排名靠前的车道线生成局部热力图，并投影到全局热力图上。</code></li><li>Cartesian image connection：解决overlap问题</li></ul></li></ul></li><li><p>Sparse sampling for Miss Rate Optimization and Full trajectory generation（这个和HOME一样了）</p></li><li><p>Model ensembling：这个说明了heatmap可以进行模型集成，而且可以取得更好的效果，且没有模式崩溃。后面用实验证明了这一点。（<strong>一般来说，两种模型的差异和互补性越强，性能提升就越大。</strong>）</p></li></ul><h2 id="towards-capturing-the-temporal-dynamics-for-trajectory-prediction-a-coarse-to-fine-approachconference-on-robot-learning-2022"><a class="markdownIt-Anchor" href="#towards-capturing-the-temporal-dynamics-for-trajectory-prediction-a-coarse-to-fine-approachconference-on-robot-learning-2022"></a> #Towards Capturing the Temporal Dynamics for Trajectory Prediction: a Coarse-to-Fine Approach(Conference on Robot Learning 2022)</h2><h2 id="1-mp3-a-unified-model-to-map-perceive-predict-and-planieee-2021"><a class="markdownIt-Anchor" href="#1-mp3-a-unified-model-to-map-perceive-predict-and-planieee-2021"></a> *1 MP3: A Unified Model to Map, Perceive, Predict and Plan(IEEE 2021)</h2><h2 id="2-scene-transformer-a-unified-architecture-for-predicting-multiple-agent-trajectoriesiclr-2022"><a class="markdownIt-Anchor" href="#2-scene-transformer-a-unified-architecture-for-predicting-multiple-agent-trajectoriesiclr-2022"></a> *2 SCENE TRANSFORMER: A UNIFIED ARCHITECTURE FOR PREDICTING MULTIPLE AGENT TRAJECTORIES(ICLR 2022)</h2><h1 id="行人轨迹预测"><a class="markdownIt-Anchor" href="#行人轨迹预测"></a> 行人轨迹预测</h1><h2 id="1-social-lstmhuman-trajectory-prediction-in-crowded-spacescvpr-2016"><a class="markdownIt-Anchor" href="#1-social-lstmhuman-trajectory-prediction-in-crowded-spacescvpr-2016"></a> 1、Social LSTM：Human Trajectory Prediction in Crowded Spaces(CVPR 2016)</h2><p>将轨迹预测视为序列生成任务，预测人类目标的运动同时考虑到这种常识行为：他们服从大量(不成文的)常识性规则，遵守社会规约。例如，在考虑下一步行动时，他们尊重个人空间，让渡路权。</p><p>动机：RNN的快速发展；RNN被证明对具有密集连接的数据的任务是有效的；在拥挤场景中运动的人类会根据周围其他人的行为来调整自己的运动。这种轨迹上的偏差无法通过鼓励地观察人来预测，也不能通过简单的排斥或吸引函数来预测（传统社会力模型），这促使我们建立一个模型，该模型可以解释大邻域内其他人的行为，同时预测一个人的路径。（<strong>总的来说就是如何捕捉人类运动过程中的着用常识性行为</strong>）</p><p>我们通过一种新颖的架构来解决这个问题，该架构连接了附近序列对应的LSTM。特别地，我们引入了一个&quot; Social “池化层，它允许空间邻近序列的LSTM彼此共享隐藏状态。这种架构，我们称之为” Social-LSTM &quot;，可以自动学习在时间上重合的轨迹之间发生的典型交互。该模型利用现有的人类轨迹数据集，不需要任何额外的标注来学习人类在社交空间中观察到的常识性规则和惯例。</p><p><strong>方法</strong>：工作对多个人了联合进行了预测，对每个人的轨迹都采用的是LSTM进行预测，且权重共享。对于<strong>social pooling</strong>用来共享相邻LSTMs之间的隐藏状态，结合所有邻居信息的一种方法。希望从LSTM的隐状态中捕捉到这些时变的运动特性（个体之间是相互影响，相互调整自己的路径）。</p><p>对于误差损失模型输出的不直接是轨迹，而是输出的是二元正态分布的参数，即轨迹从中采样，利用<strong>极大似然估计</strong>的思想来构建损失函数。（这里我认为可以类比为在<strong>DESIRE</strong>中也是一种多状态的输出然后选最好的，这里分布就像是一种多概率输出，然后我们利用极大似然估计选概率最大的那个）（<strong>说明了这里的输出也是多模态的</strong>）</p><p><img src="image-20230314090713256.png" alt></p><h1 id="驾驶行为预测跟车变道等另一种多模态"><a class="markdownIt-Anchor" href="#驾驶行为预测跟车变道等另一种多模态"></a> 驾驶行为预测（跟车变道等，另一种多模态）</h1><h1 id="自监督学习"><a class="markdownIt-Anchor" href="#自监督学习"></a> 自监督学习</h1><h1 id="时空大数据挖掘"><a class="markdownIt-Anchor" href="#时空大数据挖掘"></a> 时空大数据挖掘</h1><h1 id="跟车模型car-following"><a class="markdownIt-Anchor" href="#跟车模型car-following"></a> 跟车模型，car following</h1><h1 id="换道模型-lane-changing"><a class="markdownIt-Anchor" href="#换道模型-lane-changing"></a> 换道模型 lane changing</h1><h1 id="异常检测"><a class="markdownIt-Anchor" href="#异常检测"></a> 异常检测</h1><h2 id="1-基于时空轨迹数据的异常检测"><a class="markdownIt-Anchor" href="#1-基于时空轨迹数据的异常检测"></a> 1、基于时空轨迹数据的异常检测</h2><p><img src="image-20230508210019292.png" alt></p><p>为了更好地关注学生健康发展,促进校园信息化建设,以真实校园上网数据为例,提出了</p><ul><li>一种基于<strong>多尺度阈值和密度相结合</strong>的<strong>谱聚类算法</strong>(Spectral Clustering Algorithm Based on The Combination of Multi-Scale Threshold And Density,MSTD-SC),<ul><li>谱聚类将聚类问题转换成图的切割问题</li><li>谱聚类的核心便是相似度矩阵的构造</li><li>谱聚类算法在聚类的过程中是根据相似度矩阵或者进一步导出拉普拉斯矩阵中的特征向量来对数据进行聚类划分的。</li></ul></li><li>使用基于最短时间距离子序列(Shortest Time Distance-Shortest Time Distance Subsequences,STD-STDSS)的<strong>亲和距离函数</strong>来构造初始相似度矩阵,</li><li>进一步引入协方差尺度阈值和空间尺度阈值对相似度矩阵进行０-１化处理**,以此得到更精确的样本相似度**,</li><li>接着对相似度矩阵进行<strong>特征值分解,得到新的特征向量空间,</strong></li><li>最后采用DBSCAN聚类避免了K-means算法需要人工确定聚类数目的缺陷.</li></ul><p>利用<strong>轮廓系数</strong>评估多种算法得到的实验结果,MSTDＧSC算法体现出了更好的聚类性能.</p><p><code>异常轨迹模式挖掘作为时空轨迹数据挖掘的一种,旨在发掘出与诸多移动对象行为或模型不相似甚至无共性特征的离群数据对象.如今,基于时空轨迹的异常检测已被广泛应用于城市交通管理、健康医疗监控、公共安全突发事件监测、气候监测及动物迁徙分析等领域.</code></p><h2 id="2-轨迹大数据异常检测研究进展及系统框架软件学报2017"><a class="markdownIt-Anchor" href="#2-轨迹大数据异常检测研究进展及系统框架软件学报2017"></a> 2、轨迹大数据异常检测研究进展及系统框架，软件学报2017</h2><p>面对轨迹大数据低劣的数据质量和快速的数据更新,需要利用有限的系统资源处理因时变带来的概念漂移,<strong>实时地</strong> 检测多样化的轨迹异常,分析轨迹异常间的因果联系,继而识别更大时空区域内进化的、关联的轨迹异常,这是轨迹 大数据异常检测的核心研究内容。此外,融合与位置服务应用相关的多源异质数据,剖析异常轨迹的起因以及其隐含 的异常事件,也是轨迹大数据异常检测当下亟待研究的问题。</p><p>时变进化，动态演化，概念漂移</p><p><strong>基于轨迹数据的模式发现旨在从海量轨迹集合中提取诸多移动对象的1、共性特征,与之相对应的另外一类 工作则是面向轨迹大数据发现2、异常模式</strong></p><p>异常检测技术由 3 子问题组成:**① 异常定义;② 提出异常检测的方法;③ 解释异常检测的结果。**一般来 说,可以先定义正常行为的范围,再以此为依据判定与之相异的行为是否异常。但是,受限于不同的应用领域,确 定一个通用的涵盖所有异常行为的孤立点定义是非常困难的。</p><p>异常轨迹(或称为轨迹孤立点)既可被看作<strong>不遵守某种 预期模式的事件</strong>,<strong>也可被看成是根据相似性准则表现</strong>(旅行时间、数据分布等)与其他对象的行为相异。</p><p><img src="image-20230510211521260.png" alt></p><p>但在实际应用中,很难获得一个覆盖所有异常行为类型的标签训练数据集 。因此有好多都是无监督的，或者是基于弱监督的。基于全监督的数据集搜集比较困难，不多。</p><p><img src="image-20230511171853150.png" alt></p><p>本文系统地梳理和分析了 现有轨迹异常检测技术的研究和发展现状,并以轨迹数据时空相关性、检测的异常类型、异常检测输出结果方 式、异常检测处理方式为依据,对 13 种具有代表性的轨迹异常检测方法进行了详细的对比分析,指出了现有方法的局限性。</p><p>鲁棒性强的在线轨迹异常检测方法还需要继续考虑</p><h2 id="3-基于图神经网络的动态网络异常检测算法"><a class="markdownIt-Anchor" href="#3-基于图神经网络的动态网络异常检测算法"></a> 3、基于图神经网络的动态网络异常检测算法</h2><p>不仅考虑了全图的结构特征，还考虑到了图中的节点，边，图的属性特征。综合考虑了全局和局部。同时还考虑到了变化（演化）</p><p><strong>动态网络主要有以下一些特点:1)网络结构处于不确定的变化之中，每一时刻都有新的点或边加入或删除;2)网络的属性处于不确定的变化之中，同一节点或边在不同时刻的属性特征可能不同</strong></p><p>**本文的主要贡献包括:**将图神经网络应用于动态网络异常检测，从而使网络异常检测可以同时抓住结构上的异常以及属性上的异常。提出 Dynamic-DGI 的时序网络表示学习框架，从而使模型能够脱离标记数据来学习网络变化的一般特征。在多个数据集上检测了本文的方法和对比方法。</p><p><strong>待解决的问题</strong>：</p><ul><li>如何同时结合图的结构特征和属性特征来更好地挖掘异常。图上元素除了因结构产生的异常外，其本身具有的属性也可能使其具有不同于一般元素的特性，需要找到合适的方法，结合两方面的信息来确定异常;</li><li>带有标注的动态网络异常数据很少，异常数据和正常数据的样本数非常不平衡。如何使用无监督的方式来获得动态网络的表示，并在此基础上进行异常元素的挖掘;</li><li><mark>动态网络的变化特征。动态网络的动态性通常表现为结构的变化和属性的变化，异常性也包括元素本身的异常以及变化的异常。如何将这两者同时编码进表示向量，是一个需要解决的问题。</mark></li></ul><p><code>为了将图的变化作为一个特征编码来探测图的变化上的异常，本文使用门控的循环神经网络 LSTM 来对图的变化进行建模</code>。使用 LSTM 的好处是可以解决长期依赖[14]以及梯度消失的问题，对较长的序列处理比较有利。本文使用 LSTM 将变化的信息编码，并结合 GNN 提取到的整个网络本身的属性和结构特征一起编码进表示向量，从而作为网络的表示。之后，为了进行无监督表示学习，本文扩展 Deep Graph Infomax 的无监督表示学习方法，并提出 Dynamic-DGI(dynamic deep graph infomax)的动态网络无监督表示学习框架。</p><p><strong>由此可知主要任务有 3 点:</strong>（（整图（子图）级别异常检测））</p><p><strong>(1) 找到好的向量表示来体现图的整体特征;</strong></p><p><strong>(2) 使模型能够记忆之前存在过的图的信息;</strong></p><p><strong>(3) 找到合适的算法来给每一时刻的图进行异常打分，并认为异常分数大于阈值的图为异常图。</strong></p><p>步骤：</p><ul><li>该算法首先使用图神经网络将 t 时刻的网络元素信息(节点、边)提取到特征空间</li><li>之后使用图上的无监督表示学习算法 DGI 将当前时刻 的整个网络表示成一维的向量。</li><li>在图的表示向量的基础上，使用成熟的流上的异常检测算法 RRCF 等为每一时刻的图进行打分，获取其异常分数。</li><li>为了确定异常图，可以设定一个阈值并认为分数超过阈值的图存在异常。</li><li>在 进行网络表示学习的过程中，我们使用<strong>全局表示与局部表示互信息最大化的策略</strong>来进行图的表示学习。为了使模型能够利用每一时刻的图信息，我们使用 LSTM 来获取每一时刻网络全局表示的变化信息并加以处理。图 1 展示了本文算法的总体框架。</li></ul><p><img src="image-20230512151508701.png" alt></p><p><img src="image-20230513221223464.png" alt></p><p>异常评分算法有：RRCF，streaming k-means，E-D-E（Encoder-Decoder-Encoder）</p><h1 id="驾驶评价"><a class="markdownIt-Anchor" href="#驾驶评价"></a> 驾驶评价</h1><h2 id="1-结合自然语言处理与改进层次分析法的乘用车驾驶舒适性评价"><a class="markdownIt-Anchor" href="#1-结合自然语言处理与改进层次分析法的乘用车驾驶舒适性评价"></a> 1、结合自然语言处理与改进层次分析法的乘用车驾驶舒适性评价</h2><p>动机：为了有效和准确地评价乘用车驾驶舒适性</p><p>解决问题（可归为动机中去，也可放到创新点）：</p><ul><li>对舒适性的评价往往从<strong>单一角度展开</strong>，对实际驾驶舒适性提升作用有限</li><li>影响驾驶舒适性的各因素<strong>指标权重并未量化</strong>，因此对各因素评价的简单累加并不能得到准确有效的结果。</li></ul><p>方法：</p><ul><li><p><strong>改进TF-IDE</strong>：在传统的“词频你想文件频率（<strong>TF-IDE</strong>）”中引入程度副词。</p><ul><li><p>基于上述方法对主题词进行提取，获得影响驾驶舒适性的主要因素并进行分类；</p></li><li><p>在此基础上建立<strong>递阶层次结构</strong>。</p><p><img src="image-20230321110409052.png" alt></p></li></ul></li><li><p><strong>改进AHP方法</strong>：针对传统层次分析法（AHP）的不足，以三标度取代传统的九标度以保证精确性。</p><ul><li>通过<strong>Delphi</strong>实验，构造两两比较判别矩阵后再进行处理，以计算各评价指标的权重；</li><li>并对该指标体系进行一致性检验。</li></ul></li></ul><p>实验：以C级乘用车为例子、，选取4种品牌车验证了本文方法的<strong>有效性</strong>。（<code>与厂商测评结果一致，从而证明了本方法的有效性</code>）</p><h2 id="2-基于轨迹数据的危险驾驶行为识别方法"><a class="markdownIt-Anchor" href="#2-基于轨迹数据的危险驾驶行为识别方法"></a> 2、基于轨迹数据的危险驾驶行为识别方法</h2><p>旨在创建以恶危险行为的自动驾驶识别方法和判断方法。</p><p>1、该论文的考虑了 <strong>不同车辆对驾驶行为产生的影响。（创新点）</strong></p><ul><li>分析了大车和小车的车辆轨迹特征变量分布的差异性，包括速度，加速度，碰撞时间倒数，车头时距等</li><li><strong>在不同的车辆类型下，相同轨迹数据产生的在不同的车辆类型下，相同轨迹数据产生的风险程度也不一样</strong></li><li><strong>论文关于不同类型车辆的轨迹分析那一块可以好好看一看！！！！！！</strong></li></ul><p>2、论文对MTC进行了修正，采用了MMTC，从反映时间去衡量潜在危险</p><p>论文方法：</p><ul><li><p><strong>驾驶行为特征分析</strong></p><ul><li>本文先是筛选了三个碰撞风险指标：ITTC，THW，MMTC，然后利用皮尔森相关系数进行相关性分析。（<strong>个人认为这里相当于指标冗余性检验</strong>。）（在2.2节中说明了文章选择了MMTC指标（thw和mmtc呈较大的正相关性））</li><li>然后基于不同车辆对驾驶行为进行差异性分析说明了：<strong>车辆类型对于驾驶行为具有显著影响。</strong></li><li>驾驶行为标记：K-Means+制定相关规则（<strong>这个可以认为是专家鉴定</strong>？？？）（上面的风险指标用于聚类用，用于风险综合评价分析）</li></ul></li><li><p>危险驾驶行为识别模型</p><p>这里用到了上面所标记的样本。</p><ul><li>关键特征参数提取<ul><li>用<strong>统计方法</strong>提取 <strong>轨迹变量</strong>的最大值，最小值，均值，方差，和85%分位数5个<strong>时域特征。</strong></li><li>用离散小波变换将<strong>轨迹变量的时序序列</strong>转化成频域信号，提取频域信号中的<strong>离散小波系数</strong>作为危险驾驶行为识别的关键特征参数。</li></ul></li><li>LGBM识别算法<ul><li>其中有用到<strong>SMOTE方法</strong>来消除样本不平衡的影响</li><li>优化用的是<strong>差分进化算法，DE</strong></li></ul></li><li>在性能分析过程中利用了<strong>SVM-REF</strong>来对时域和频域特征进行排序，确定最优特征参数</li></ul></li></ul><p>这篇论文我有一个疑问：<strong>就是这样来进行样本的选择是否合理，正确，全面？是不是希望得到一个模型能具有K-means+专家鉴定的能力</strong>（和DenseTNT中的离散优化选取伪标签的思路有点像，这里的聚类+专家鉴定（规则）操作相当于提供伪标签，供后面的LGBM训练）(<code>这里的模型的一个小的缺点就是用了主观的判断，在构造数据集那一块，但这里可能是需要构造数据集。如果在评价指标中加入过多的专家判断，可能不太友好，推广性可能存在一定的问题</code>)</p><h2 id="3-基于自然驾驶数据的自动驾驶汽车安全性评价方法"><a class="markdownIt-Anchor" href="#3-基于自然驾驶数据的自动驾驶汽车安全性评价方法"></a> 3、基于自然驾驶数据的自动驾驶汽车安全性评价方法</h2><p><img src="image-20230416093631004.png" alt></p><p><img src="F:%5CHexo%5Cblog%5Csource_posts%5C%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%5Cimage-20230416161601141.png" alt></p><p><strong>动机</strong>：为解决现有评价方法的不足，如基于里程的方法会面临大量的重复试验从而延长测试评价周期、基于通过性指标的方法无法面向逻辑场景层级，本文<code>综合考虑自然驾驶过程中逻辑场景参数概率分布和被测算法在被测逻辑场景中的危险区域</code>，提出一种<strong>基于自然驾驶数据</strong>的自动驾驶汽车<strong>逻辑场景层面</strong>安全性评价方法，该方法应用于场景测试体系中<strong>逻辑场景层级</strong>的安全性评价，是自动驾驶场景测评领域的探索。</p><p><strong>自动驾驶汽车的安全性评价必须面向逻辑场景的同时还需要考虑自然驾驶数据</strong></p><p>（<code>强调逻辑场景和自然驾驶数据+仿真测试</code>）（但这里的仿真测试的那个<strong>仿真试验</strong>那一块介绍的不是很详细）（看论文：《<strong>面向多维度逻辑场景的自动驾驶安全性聚类评价办法</strong>》，下面那一篇）</p><p>现在自动驾驶安全性评价存在的问题：<code>缺乏逻辑场景层面评价，缺乏考虑自然数据，主观判断在评价过程中占较大的比重。</code></p><p>方法：</p><p><strong>自动驾驶安全性的量化</strong>——场景风险指数（可以理解为这个场景中危险发生的概率）</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>=</mo><msub><mo>∫</mo><mi mathvariant="normal">Ω</mi></msub><mi>P</mi><msub><mi>V</mi><mrow><mi>c</mi><mi>o</mi><mi>l</mi><mi>l</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">R=\int_\Omega PV_{collsion}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.27195em;vertical-align:-0.9119499999999999em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.433619em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">Ω</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><ul><li>首先建立自然驾驶数据的逻辑场景构建流程，分析描述场景的参数。搭建平台采集数据，并利用高斯分布模型描述参数概率分布。</li><li>进而，离散逻辑场景参数空间获取<strong>具体测试用例</strong>，并在相关仿真平台上对被测自动驾驶算法进行仿真遍历测试，（<strong>这个具体测试用例相当于用来提供相关的场景信息</strong>）。（这个基于逻辑场景的仿真测试中的<strong>仿真试验</strong>有点没讲清楚）</li><li>通过<strong>高斯模型将测试结果中的危险场景参数聚类</strong>，获取被测算法在逻辑场景中的危险区域（参数空间中的危险区域）。就是用高斯混合模型去学习危险场景出现的概率）<ul><li>这里有个 <strong>参数对称化处理</strong></li></ul></li><li>综合考虑逻辑场景参数空间概率分布和得到的相应逻辑场景危险区域，提出基于自然驾驶数据的自动驾驶汽车安全性评价指标——<strong>场景风险指数。</strong></li></ul><p>在使用本文的方法得到的场景风险指数的基础上，可以将某类逻辑场景中的场景风险指数与该类逻辑场景在自然驾驶情况下的发生概率进行结合，从而获取 <strong>被测自动驾驶算法在多个逻辑场景下的总风险指数</strong>（<strong>加权求和？？？？？？？</strong>）</p><p><strong>中国交通事故深入研究（CIDAS）数据库</strong></p><p><strong>美国国家公路安全管理局（NHTSA）事故数据库</strong></p><p><strong>通过与上面几个（自然驾驶交通事故数据库）数据库的数据信息进行对比，可以比较自动驾驶汽车与传统汽车的安全性能，即其事故情况是否优于当前对应场景中的自然驾驶人。</strong></p><p>（这里和驾驶过程中的那种实时评价还不太一样，有区别）</p><p><strong>（这里有一个问题就是我们虽说拟合出了这个分布，但怎么说明这样得出来的指标就是真的有效的了，这个范围就是危险的了。我觉得还得利用上面个的数据集来验证一下才可以！！！！！！！！！！！！！！！！！！！！！！！！！！，难道是从图中看出来的嘛，越在中心，危险的概率越高。（看图7，8和关于文末关于通过性指标的分析））</strong></p><h2 id="4-面向多维度逻辑场景的自动驾驶安全性聚类评价办法"><a class="markdownIt-Anchor" href="#4-面向多维度逻辑场景的自动驾驶安全性聚类评价办法"></a> 4、面向多维度逻辑场景的自动驾驶安全性聚类评价办法</h2><h2 id="5-基于因子长短期记忆的驾驶人接管行为及意图识别"><a class="markdownIt-Anchor" href="#5-基于因子长短期记忆的驾驶人接管行为及意图识别"></a> 5、基于因子长短期记忆的驾驶人接管行为及意图识别</h2><p><img src="image-20230509145138013.png" alt></p><p><img src="image-20230509145211547.png" alt></p><p>（其实这里就反映了一个问题：<strong>自动驾驶是如何预警的，自动驾驶车辆如何识别紧急接管情境</strong>，<code>因此驾驶安全评价仍然是一个很重要的问题</code>）</p><p>利用所得车辆运行和视觉注意力数据，根据<strong>因子分析</strong>提取得到3个公因子，采用<strong>K-means聚类分析定性</strong>识别驾驶人接管行为及意图。（考虑了不同接管情境，不同集中程度的视觉注意力）(因子分析：降维)</p><p>将因子分析分别与支持向量机和长短期记忆神经网络进行结合，获得两个定量识别驾驶人接管行为及意图的模型。</p><p>研究结果表明，驾驶人接管行为受其纵向反应、横向反应和视觉注意力影响；<strong>聚类分析可定性描述不同类型驾驶人的接管行为及意图，并揭示潜在的驾驶安全隐患；</strong>（定性分析）</p><p><code>相比支持向量机、长短期记忆神经网络和因子支持向量机模型，因子长短期记忆模型能更有效地识别驾驶人接管意图，其精确率、召回率、F1分数和准确率4项性能指标均最优；利用因子分析进行数据降维和有效信息浓缩所得公因子有助于提高驾驶接管意图识别模型的分类性能。</code></p><p>驾驶员接管：当车辆所处情况超出ODD时，驾驶人必须及时地认为控制车辆。<strong>驾驶员接管过程是否顺利关乎自动驾驶车辆能否安全的驾驶</strong></p><p>情境意识，接管请求提前量，</p><p>影响自动驾驶接管的因素众多，<strong>结合驾驶人注意力转换和情境意识重构</strong>，将自动驾驶接管的影响因素分为：1、接管请求方式，2、非驾驶任务，3、驾驶情境，4、驾驶人的社会经济属性</p><p><strong>对于识别驾驶人接管自动驾驶车辆时的驾驶意图，适用于时间序列数据的LSTM模型的性能较为出色，且通过因子分析提炼有效信息后有助于提高LSTM模型的分类性能。</strong></p><p>当然文章也有缺陷：1、有效实验人数只有11人，样本的多样性存在一定的问题。2、样本不均衡严重，文章中制动右转的数据量很少，因此识别能力很差。</p><h2 id="总结3"><a class="markdownIt-Anchor" href="#总结3"></a> !!!总结3！！！！！！！！！！！！</h2><p>感觉现在的轨迹预测有几种形式</p><ul><li>以scale-net为主的预测ego-agent周围的车辆的轨迹<ul><li>我们假设ego或target agent是有人操作的，为了模仿人的操作（我们在驾驶过程中会预测周围车辆的轨迹，来进行自己的决策），因此scale-net假定自我车辆时<strong>controllable</strong></li></ul></li><li>以laneRCN,LaneGCN,不区分目标车辆，预测多智能体的轨迹，旨在强调：<ul><li>自动驾驶车辆需要以安全舒适的方式在动态环境中导航。这就需要<strong>预测其他智能体的未来运动，以了解场景将如何演化</strong>。</li><li>自动驾驶车辆( SDVs )为了安全运行，必须准确预测其他交通参与者的未来运动。</li><li>其实这里的意图喝scale-net中的是一致的。</li><li><code>其实这里关于多智能体之间未来是如何交互的也没有详细的设计</code>，<mark>因此如果要预测多智能体的轨迹，那么仔细考虑如何未来交互是一个研究点</mark>。<strong>同时对于未来的预测也有两种</strong>：<ul><li><strong>one-forward</strong>：像假设未来的轨迹在不同时间步之间是独立的（<strong>短时间内</strong>），因此我们可以直接one-forward计算出未来的轨迹。<ul><li>有基于离散意图的（intentnet），有直接输出轨迹的，有先输出endpoit再去生成轨迹（这里面有几个：1、基于anchor，proposal等，2、基于概率图（HOME，GOHOME））</li></ul></li><li><strong>顺序计算</strong>：一步一步的计算，计算复杂度高</li></ul></li></ul></li><li>以TNT，DenseTNT等为主的预测单个智能体的操作（mmtransformer中提到是为了节省计算），但是强调这个方法可以用于其余所有的智能体。</li></ul><h1 id="相关概念"><a class="markdownIt-Anchor" href="#相关概念"></a> 相关概念</h1><p>1、<strong>模式崩溃：</strong></p><ul><li>即解码器倾向于在不同模态下预测相似的轨迹，因为似然成本是L2误差加权和，平均预测可能是局部最小值。<ul><li><a href="https://blog.csdn.net/Yong_Qi2015/article/details/125903782">https://blog.csdn.net/Yong_Qi2015/article/details/125903782</a></li><li>在生成模型中，模式崩溃问题是针对于生成样本的多样性，即生成的样本大量重复类似（生成模型只生成其中的几种模式）<ul><li><a href="https://zhuanlan.zhihu.com/p/609308879">https://zhuanlan.zhihu.com/p/609308879</a></li><li><a href="https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/87569867">https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/87569867</a></li></ul></li></ul></li></ul><p>2、<strong>baseline和state of the art(SOTA)</strong></p><p>3、<strong>教师增强，teaching-force</strong>：用真实值代替预测值来进行训练，看<strong>TNT</strong></p><p>4、<strong>赢者通吃，winner-takes-all</strong>：只训练最接近真实情况的预测，看 《<em>Multimodal Trajectory Predictions for Autonomous Driving using Deep Convolutional Networks</em>》提出的MTP损失函数</p><p>5、<strong>情境意识</strong>：为操作员感 知 、理解其周围环境以及预测周围环境的近期状态。</p><p>6、<mark>长距离依赖性（long range dependency</mark>）</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 自动驾驶 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多模态大模型综述（1）</title>
      <link href="/2023/09/18/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0%EF%BC%881%EF%BC%89/"/>
      <url>/2023/09/18/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0%EF%BC%881%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是关于多模态大模型综述的一些介绍</p><span id="more"></span><h1 id="综述a-survey-on-multimodal-large-language-models"><a class="markdownIt-Anchor" href="#综述a-survey-on-multimodal-large-language-models"></a> 综述：A Survey on Multimodal Large Language Models</h1><h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h1><p>多模态大语言模型( Multimodal Large Language Model，MLLM )是近年来兴起的一个新的研究热点，它利用强大的大语言模型( Large Language Model，LLM )作为大脑来执行多模态任务。MLLM出人意料的突现能力（涌现的新能力），如基于图像编写故事和OCR - free数学推理，在传统方法中是罕见的，这表明了通向人工智能的潜在道路。本文旨在对MLLM的最新进展进行跟踪和总结。首先，我们给出了MLLM的提法（制定概念），并对其相关概念进行了阐述。然后，讨论了多模态指令调优( M-IT )、多模态上下文学习( M-ICL )、多模态思维链( M-CoT )和LLM辅助视觉推理( LAVR )等关键技术及其应用。最后，我们讨论现有的挑战</p><ul><li>OCR-free因该是指不许用转换成文本，直接处理数据，如这里直接处理公式，而不需要转换成文本。</li></ul><h1 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> introduction</h1><p>最近几年大语言模型得到了显著的进展。通过扩大数据规模和模型规模，这些LLMs具有了惊人的突现能力。</p><ul><li>尽管LLMs在大多数自然语言处理( Natural Language Processing，NLP )任务上表现出惊人的零/少样本推理性能，但由于它们只能理解离散文本，因此本质上对视觉&quot;瞎的&quot;。</li><li>同时大视觉基础模型在感知上发展很快，与文本的传统结合更注重<strong>模态对齐</strong>[ 11 ]和<strong>任务统一性</strong>[ 12 ]，在推理方面发展缓慢。<br>鉴于这种互补性，单峰（单一的 unimodal，单模态）LLMs和视觉模型同时向对方运行（融合），最终导致了MLLM的新领域。<br>从发展人工智能( Artificial General Intelligence，AGI )的角度来看，MLLM可能从LLM向前迈进了一步，原因如下：</li><li>( 1 ) MLLM更符合人类感知世界的方式。<strong>我们人类自然会接收到多感官的输入，这些输入往往是互补和合作的。</strong> 因此，多模态信息有望使MLLM更加智能化。</li><li>( 2 ) MLLM提供了更加友好的用户界面（接口）。得益于多模态输入的支持，用户可以更加灵活地与智能助手进行交互和交流。</li><li>( 3 ) Mllm是更全面的任务解决者。虽然LLMs通常可以执行NLP任务，但MLLMs通常可以支持更大范围的任务（多模态）<br>GPT-4 [ 2 ]因为展示了令人惊叹的例子，引发了对MLLM的研究热潮。然而，GPT - 4并没有开放多模态界面（接口），迄今为止也没有公开该模型的任何信息。<br>尽管如此，研究界为开发有能力的、开源的MLLM模型做出了许多努力；some surprising practical capabilities（实际应用能力） have been exhibited, such as writing website codes based on images [13], understanding the deep meaning of a meme [14], and OCR-free math reasoning [15].<br>我们撰写此项综述，是为了让研究者对MLLM的基本思想、主要方法和当前进展有一个大致的把握。</li><li>需要注意的是，我们主要关注视觉和语言模态，也包括涉及其他模态的工作。</li><li>具体来说，我们将现有的MLLM划分为四种类型并进行相应的总结，同时打开一个GitHub页面进行实时更新。据我们所知，这是关于MLLM的第一次调查。</li></ul><h1 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> overview</h1><p>本文将最近的代表性 MLLM 分为四种主要类型：多模态指令调整 (MIT)、多模态上下文学习 (M-ICL)、多模态思维链 (M-CoT) 和 LLM 辅助视觉推理 (LAVR，a general framework to build task-solving systems)。前三个构成了 MLLM 的基本原理，最后一个是一个以 LLM 作为核心的多模态系统。这三（难道不是四种？？，看本节的最后一句话，第四种相当于一个架构！）种技术相对独立，可以结合使用。</p><p>我们从 M-IT（第 3.1 节）的详细介绍开始，以揭示 LLM 如何从两个方面适应多模态：结构和数据。然后我们引入 M-ICL（第 3.2 节），这是一种在推理阶段常用的有效技术，以提高few shot性能（in-context learning<a href="%E7%BB%BC%E8%BF%B0%EF%BC%9AHarnessing%20the%20Power%20of%20LLMs%20in%20Practice%20%EF%BC%9AA%20Survey%20on%20ChatGPT%20and%20Beyond.md">综述：Harnessing the Power of LLMs in Practice ：A Survey on ChatGPT and Beyond</a>）。另一个重要的技术是 M-CoT (§3.3)，通常用于复杂的推理任务。之后，我们进一步总结了llm主要参与LAVR的几个角度（role，角色，LLM在LAVR中扮演的几个角色）(§3.4)，这通常涉及三种技术。最后，我们总结并给出潜在研究方向。</p><h1 id="method"><a class="markdownIt-Anchor" href="#method"></a> method</h1><h2 id="multimodal-instruction-tuning"><a class="markdownIt-Anchor" href="#multimodal-instruction-tuning"></a> Multimodal Instruction tuning</h2><p>instruction是指对任务的描述。</p><ul><li>Instruction Tuning（指令调优）是一种涉及在指令格式数据集[16]集合上微调预训练的llm的技术。通过这种方式进行调整，LLM 可以通过遵循新指令泛化（扩展）到看不见的任务，从而提高零样本性能。这种简单而有效的想法引发了后续工作在 NLP 领域的成功，例如 ChatGPT [1]、InstructGPT [17]、FLAN [16, 18] 和 OPT-IML [19]。<br><img src="image-20230918103651321.png" alt="image-20230918103651321"></li><li>有监督的微调方法通常需要许多特定任务的数据来训练特定任务的模型。（pretrain-finetune）</li><li>提示方法减少了对大规模数据的依赖，可以通过提示工程完成专门的任务。（prompt engineering）<ul><li>few-shot性能能够提高</li><li>但是zero-shot的性能相当平均。对zero-shot的效果一般</li><li>虽然小样本性能得到了提高，但零样本性能仍然相当平均[ 5 ]。</li></ul></li><li>不同的是，指令微调学习如何泛化到看不见的任务，而不是像two counterparts那样拟合特定的任务（two counterparts：前面的哪两种方法）。<ul><li>instruction tuning is highly related to multi-task prompting [20].</li></ul></li></ul><p>传统的多模态模型仍然局限于前两种tuning范式，缺乏zero shot（零样本）能力。<br>因此，最近的许多工作[ 13、21、22]探索了将LLMs中的教学调整成功扩展到多模态。<strong>为了从单模态扩展到多模态，数据和模型都需要进行相应的适应</strong>。</p><ul><li>对于数据，研究人员通常通过改编已有（现有的）的基准数据集[23 - 28]或通过self-instruction获取M-IT数据集[13,21,29]。</li><li>对于模型：常见的方法就是将多模态数据注入LLMs中，利用大模型的强力的推理能力分析其他模态的数据</li><li>相关工作或者直接将外来嵌入（其余模态的嵌入，输入的特征化）对齐到LLMs [ 21、23 ~ 25、27、28、30 ~ 32]中，或者借助专家模型将外来（其余）模态翻译成LLMs可以摄取（处理）的自然语言[ 33、34]。</li><li>通过这种方式，<strong>这些工作通过多模态指令调优将LLM转化为多模态聊天机器人</strong>[ 13、21、22、33、35]和多模态通用任务求解器[ 23、24、26]。</li></ul><p>在本节的后面部分，我们首先给出基础知识( § 3.1 . 2 )。在过渡到M - IT的定义之前，我们额外引入了M - IT之前的一个常见过程，即<strong>对齐预训练</strong>（alignment pre-training）( § 3.1.3 )。接下来，我们将剩余内容整理为图2所示：首先介绍M - IT数据是如何收集的( § 3.1.4 )，然后详细讨论MLLMs的模型适配，即不同模态之间的各种弥（bridge the gap）合方式( § 3.1.5 )。最后，我们介绍了评估指令调整MLLM的评估方法( § 3.1.6 )。<br><img src="image-20230918103851046.png" alt="image-20230918103851046"></p><h3 id="preliminaries"><a class="markdownIt-Anchor" href="#preliminaries"></a> Preliminaries</h3><p>本部分简要说明了多模态指令样本的一般结构和M - IT的一般流程。<br><img src="image-20230918103805951.png" alt="image-20230918103805951"></p><ul><li>多模态指令样本通常包括一条指令和一个输入输出对<ul><li>该指令通常是描述任务的自然语言句子，例如，“详细描述图像”。</li><li>输入可以是类似于视觉问答( VQA )任务的图像-文本对[ 46 ]，也可以是类似于图像描述任务的图像[ 47 ]。</li><li>输出是对以输入为条件的指令的回答。</li></ul></li><li>如表1所示，指令模板是灵活的，且受手工设计[ 21、31、33]的约束。值得注意的是，指令样本也可以泛化为多轮（multi-round）指令，其中多模态输入共享[ 21、30、31、43]。</li><li>在形式上，多模态指令样本可以表示为三元组形式。$$(I,M,R)$$其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo separator="true">,</mo><mi>M</mi><mo separator="true">,</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">I,M,R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>表示：instruction，the multimodal input ,the ground truth response</li><li>MLLM在给定指令和多模态输入的情况下预测一个答案$$A=f(I,M;\theta)$$</li><li>这里A表示预测的answer，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>表示模型的参数。训练目标是通常用于训练LLMs [ 21、30、32、43]的原始自回归目标（auto-regressive objective），在此基础上，MLLM被要求预测回答（response）的下一个token。目标为：$$\mathcal{L}(\theta)=-\sum\limits_{i=1}^{N}\log p(R_{i}|I,R_{&lt;i};\theta)$$其中N是真实response（回答）的回答</li></ul><h3 id="modality-alignment"><a class="markdownIt-Anchor" href="#modality-alignment"></a> modality Alignment</h3><p>在论文<a href="%E7%BB%BC%E8%BF%B0%EF%BC%9AHarnessing%20the%20Power%20of%20LLMs%20in%20Practice%20%EF%BC%9AA%20Survey%20on%20ChatGPT%20and%20Beyond.md">综述：Harnessing the Power of LLMs in Practice ：A Survey on ChatGPT and Beyond</a>中有提到<code>human alignment</code>，增加了鲁棒性<br>通常对成对数据（pair-data ）进行大规模的(相对于指令整定)预训练，<strong>以鼓励不同模态[ 25,29,35,38]之间的对齐</strong>，这在M - IT之前。对齐数据集通常为图像-文本对[ 48-56 ]或自动语音识别( Automatic Speech Recognition，ASR ) [ 57-59 ]数据集，<strong>均包含文本</strong>。更具体地说，图像-文本对以自然语言句子的形式描述图像，而ASR数据集包含语音的转录。<strong>对齐预训练的常用方法是将预训练好的模块(如视觉编码器、LLM等)冻结，并训练一个可学习的接口[ 21,37,38]。</strong></p><h3 id="数据"><a class="markdownIt-Anchor" href="#数据"></a> 数据</h3><p><strong><mark>从数据集看来，我认为这也是一种finetuning，但是这里的数据集是可以构造的，以动态的适应不同的任务</mark></strong><br>多模态指令数据的采集是M - IT的关键。收集方法大致可分为以下几类：</p><ul><li>benchmark adaptation</li><li>self-instruction</li><li>hybrid composition</li></ul><h4 id="benchmark-adaptation"><a class="markdownIt-Anchor" href="#benchmark-adaptation"></a> benchmark adaptation</h4><p>benchmark数据集是高质量数据的丰富来源。<br>大量的研究[23 - 26,28,29,32,35]直接利用了现有的基准数据集来构造指令格式的数据集。以VQA数据集的转换为例，原始样本是一个输入输出对，其中<strong>输入包括图像和自然语言问题（&lt;image&gt; {question}）</strong>，输出是基于图像的问题的文本答案。这些数据集的输入-输出对可以自然地包含指令样本的多模态输入和回答。指令，即任务的描述，<strong>可以来自手动设计，也可以来自GPT辅助下的半自动生成</strong>。具体来说，一些作品[13,23,25,26,36,37]手工制作了一个候选指令pool（池，这里还不是池化，相当于存储器），并在训练期间在池中进行采样。我们为VQA数据集提供了一个指令模板示例，如表2所示。<strong>另一些工作则手工设计一些种子指令，并使用这些指令提示GPT生成更多的种子指令[24,31,33]。</strong><br><img src="image-20230918103925124.png" alt="image-20230918103925124"><br>但是由于现有VQA和caption数据集的答案通常很简洁，直接使用这些数据集进行指令调优可能会限制MLLM的输出长度。解决这个问题有两种常见的策略：</p><ul><li>第一个是修改instruction，直接告诉LLM我们要简短、单句。例如，ChatBridge[29]明确声明short和brief用于简答数据，以及a snetence和single sentence用于caption数据。类似地，InstructBLIP[23]将short 和brief插入到公共数据集的指令模板中，这些公共数据集的回答更倾向于简短的。<ul><li>既然无法变长，那我就显示的直接修改instruction，添加short，brief的内容，这样显示的学习，可以让模型直接学习short与response（答案）的关系，避免的一些隐式的学习所造成的影响。</li></ul></li><li>第二种方法是延长现有答案的长度[36]。例如，M3IT[36]提出通过用原始问题、答案和上下文提示ChatGPT来改写原始答案。</li></ul><h4 id="self-instruction"><a class="markdownIt-Anchor" href="#self-instruction"></a> Self-instruction</h4><p>尽管现有的基准数据集可以提供丰富的数据源，但它们通常不能很好地满足现实场景中的人类需求，例如<strong>多轮对话（multiple round）</strong>。为了解决这个问题，一些作品通过自我指导（self-instruction）来收集样本[60]，这引导（booststrap）llm使用一些手工注释的样本来生成遵循文本指令（textual instruction-following）的数据。<strong>具体来说，一些遵循指令（instruction-following）的样本是手工制作的种子（seed）样本，然后提示ChatGPT/GPT-4以种子样本为指导生成更多的指令样本。</strong>(和benchmark中的最后面的一样都是GPT-Aid，GPT辅助生成)<s>（<code>这个和上面的区别在哪，benchmark那，这里应该和benchmark那的，这里的更加针对任务，一些benchmark无法满足的特定任务</code>）</s> LLaVA[21]通过将图像翻译成带有caption和边界框的文本，并提示GPT-4在种子示例的上下文中生成新数据，将该方法扩展到多模态领域。通过这种方式，构建了一个M-IT数据集，称为llava - instruction -150k。根据这一思路，随后的作品如MiniGPT-4[13]、ChatBridge[29]、GPT4Tools[34]和DetGPT[38]开发了不同的M-IT数据集，以满足不同的需求。<br>（<code>这里可以看一下table 3</code>）<br><s>- instruction样本和instruction-following样本是指什么<br>- instruction-following样本因该是基于instruction构造的，需要生成出来的instruction满足要求。</s></p><ul><li>instruction-following 样本是指遵循instruction的样本（从input到output）<ul><li>对于这里所说的可能是根据自己设计的一些指令，然后已经注释好的样本作为seed，输入到GPT4中作为上下文，再这个环境下，再根据对图片的编码：解析成文本text（）内容和位置，然后再相应的instructions，输入到GPT4中去，得到的response与输入和instructions构成新的样本：instruction-following。</li><li><strong>query：查询，询问</strong></li></ul></li></ul><h4 id="hybrid-composition"><a class="markdownIt-Anchor" href="#hybrid-composition"></a> Hybrid Composition</h4><p>Apart from the M-IT data, languageonly user-assistant conversation data can also be used to improve conversational proficiencies and instruction-following abilities [22, 31, 32, 35].（除去上面的MIT数据，纯文本的数据也可以用于提高对话的熟练度和模型遵循指令的能力。）<br><strong>Multi Instruct [ 26</strong> ]探讨了融合单模态和多模态数据的不同训练策略，包括混合指令调优(混合两种数据并随机打乱)、顺序指令调优(文本数据紧接着是多模态数据)和基于Adapter的顺序指令调优。实证结果表明，在多模态数据上，混合指令调优至少不比单独调优差。</p><h4 id="思考"><a class="markdownIt-Anchor" href="#思考"></a> 思考</h4><p>如何构造instruct-follow 数据或prompt数据集还得继续思考</p><h3 id="modality-bridging"><a class="markdownIt-Anchor" href="#modality-bridging"></a> Modality Bridging</h3><p>由于LLMs只能感知文本，因此弥合自然语言和其他模态之间的鸿沟是必要的。然而，以端到端的方式训练一个大型的多模态模型是很昂贵的。而且，这样做会带来灾难性遗忘的风险[ 61 ]。</p><ul><li>因此，一种更实用的方法是在预训练的视觉编码器和LLM之间引入一个可学习的接口。（Learnable Interface）<ul><li>可学习的接口负责在<strong>冻结预训练模型的参数</strong>时连接不同的模态。(<code>交替式训练？？</code>)</li><li>挑战在于如何高效地将视觉内容翻译成LLM能够理解的文本。<ul><li>A common and feasible solution is to leverage <strong>a group of learnable query tokens</strong> to extract information in a query-based manner [62], which first has been implemented in Flamingo [63] and BLIP-2 [64], and subsequently inherited by a variety of work [23,25,42].</li><li>Furthermore, some methods use a <strong>projection-based</strong> （基于投影）interface to close the modality gap [21, 30, 38, 43].</li><li>adapter：也有一些工作探索了一种参数有效的调优方式。LLaMA- Adapter [ 28、35]在训练时在Transformer中引入了一个轻量级的适配器模块。La VIN [ 32 ]设计了一个混合模态适配器来动态决定多模态嵌入的权重。</li></ul></li></ul></li><li>另一种方法是借助专家模型将图像翻译成语言，然后将语言发送给LLM。（expert model）<ul><li>除了learnable interface，使用专家模型，如图像描述模型，也是弥合模态鸿沟的可行方法[ 35 ]。</li><li>与之不同的是，专家模型背后的思想是在没有训练的情况下将多模态输入转换为语言。<ul><li>这样，语言学习者就可以通过转换后的语言间接地理解多模态。</li><li>例如，videochat-Text [ 33 ]使用预训练的视觉模型来提取动作等视觉信息，并使用语音识别模型来丰富描述。</li><li>尽管使用专家模型是直接的，但它可能不像采用Learnable interface那样灵活。多（其余）模态（foreign modalities）转换为文本通常会造成信息损失。正如videochat- Text [ 33 ]指出的那样，将视频转化为文本描述会扭曲时空关系。</li></ul></li></ul></li></ul><h3 id="evaluation-评估"><a class="markdownIt-Anchor" href="#evaluation-评估"></a> Evaluation 评估</h3><p>评价M - IT后模型性能的指标有很多，根据问题类型（genres）可以大致分为两类，包括closed-set和open- set。<br><strong>Closed-set</strong></p><ul><li>封闭式问题指的是一种可能的答案选项已预先确定并限制在一个有限集合内的问题。评估通常在benchmark-adapted数据集上进行。<ul><li>在这种情况下，response自然可以通过benchmark指标来判断 [21, 23, 25, 26, 28, 29, 32, 35]。</li><li>The evaluation settings are typically zero-shot [23,26,29,36] or finetuning [21,23,25,28,32,35–37].<ul><li>The first setting often selects a wide range of datasets covering different general tasks and splits them into <code>held-in and held-out </code>datasets. After tuning on the former, <strong>zero-shot</strong> performance is evaluated on the latter with unseen datasets or even unseen tasks. 会尽可能涵盖更广泛的一般任务</li><li>the second setting is often observed in the evaluation of domain-specific downstream tasks.(<code>finetuning</code>)主要做的是特定领域下的学习</li></ul></li><li>上述评估方法通常仅限于小范围的选定任务或数据集，缺乏全面的定量比较。<ul><li>为此，一些人努力开发专为 MLLM 设计的新基准 [39, 40, 72]。<ul><li>例如，Fu 等人[73] 构建了一个综合评估基准 MME，其中包括总共 14 项感知和认知任务。MME 中的所有指令-答案对都是人工设计的，以避免数据泄露。</li><li>LAMM-Benchmark [39] 的提出是为了在各种二维/三维视觉任务中对 MLLM 进行定量评估。</li><li>Video-ChatGPT [40] 为基于视频的会话模型提出了一个定量评估框架，其中包含两类评估，即基于视频的生成性能评估和 zeroshot 问答评估。</li></ul></li></ul></li></ul></li><li><strong>Open-set</strong><ul><li>与封闭式问题相比，开放式问题的回答可以更加灵活，<strong>MLLM 通常在其中扮演聊天机器人的角色</strong>。<strong>由于聊天内容可以是任意的</strong>，因此与封闭式输出相比，判断起来更加棘手。</li><li>标准可分为人工评分、GPT 评分和案例研究。<ul><li>manual：人工评分需要人工对生成的回答进行评估。这种方法通常涉及手工设计的问题，旨在评估特定的维度。<ul><li>例如mPLUG-Owl [22]收集了一个与视觉相关的评估集合，用于评估自然图像理解、图表和流程图理解等能力。类似地，GPT4Tools [34]构建了两个集合，分别用于微调和zero-shot性能评估，并从思想、行动、论点和整体方面评估回答。</li></ul></li><li>GPT：由于人工评估耗费大量人力，一些研究人员探索了使用 GPT 进行评分，即 GPT 评分。<ul><li>这种方法通常用于评估多模态对话的性能。<ul><li>LLaVA [21]提议通过GPT-4对回答进行评分，评估其在帮助性和准确性等方面的表现。具体而言，从COCO [48]验证集中随机选择30个图像，每个图像都有一个简短的问题、一个详细的问题和一个复杂的推理问题，通过在GPT-4上进行自我训练，产生由MLLM和GPT-4生成的答案，并将它们发送给GPT-4进行比较。</li></ul></li><li>基于 GPT-4 的评分的一个主要问题是，目前其多模态界面尚未公开。因此，GPT-4 只能根据与图像相关的文本内容（如标题或边界框坐标）生成响应，而无法访问图像[37]。因此，在这种情况下，将 GPT-4 设置为性能上限可能是有问题的。</li><li>另一种方法是通过案例研究比较MLLM的不同能力。例如，mPLUG-Owl使用一个与视觉相关的笑话理解案例来与GPT-4 [2]和MM-REACT [14]进行比较。类似地，Video-LLaMA [42]提供了一些案例，展示了音频-视觉共感知和常识概念识别等能力。</li></ul></li></ul></li></ul></li><li><strong>other</strong><ul><li>还有一些方法侧重于 MLLM 的特定方面。例如，MultiInstruct [26] 提出了一种称为灵敏度的指标，用于评估模型对不同指令的鲁棒性。</li><li><strong><mark>Li 等人[44] 深入研究了对象幻觉问题，并提出了一种查询方法 POPE 来评估这方面的性能。</mark></strong></li><li><mark><code>Zhao 等人[45]考虑了安全问题，并提出评估 MLLM 对对抗性攻击的鲁棒性。</code></mark></li></ul></li></ul><h2 id="multimodal-in-context-learning"><a class="markdownIt-Anchor" href="#multimodal-in-context-learning"></a> Multimodal In-Context learning</h2><p>ICL是LLMs重要的新（emergent 涌现）能力之一。<br>ICL具有两个优点：</p><ul><li>（1）与传统的监督学习范式不同，传统的监督学习范式是从大量数据中学习隐含的模式，ICL的关键在于从类比（analogy）中学习[74]。<ul><li>具体的，在ICL的设置中，具体来说，在 ICL 环境中，LLMs从几个例子和一个可选指令中学习，并推断出新的问题，从而以少样本的方式解决复杂且未知的任务[14, 75, 76]。</li></ul></li><li>（2）ICL通常以无需训练的方式[74]实施，在推理阶段可以灵活地集成到不同的框架中。<ul><li>与 ICL 密切相关的一项技术是指令调整（instruction tuning）（见第 3.1 节），经验表明它能增强 ICL 的能力[16]。</li></ul></li></ul><p>在 MLLM 的背景下，ICL 被扩展到更多模态，从而产生了多模态 ICL（M-ICL）。基于（<strong>§3.1.2</strong>）中的设置，在推理时，M-ICL 可以通过在原始样本中添加演示集（即上下文样本集，a demonstration set，如a set of in-context samples ）来实现。在这种情况下，可以扩展模板，如表 3 所示。需要注意的是，我们列出了两个上下文中的示例以作说明，但示例的数量和排序可以灵活调整。事实上，模型通常对演示的安排很敏感[74, 77]。<br><img src="%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0%EF%BC%881%EF%BC%89%5Cimage-20230918104022770.png" alt="image-20230918104022770"><br>在多模态应用方面，M-ICL主要用于两个场景：</p><ul><li>解决各种视觉推理任务 [14, 27, 63, 78, 79]<ul><li>前者通常涉及从一些（a-few）特定任务的例子中学习，然后归纳出新的但类似的问题。</li><li>通过指令和演示所提供的信息，LLM能够了解任务在做什么，输出模板是什么，并最终生成预期的答案。（上下文学习）（和M-IT紧密结合）</li></ul></li><li>教导LLM使用外部工具[75, 76, 80]。<ul><li>工具使用的示例通常是纯文本的，而且更加精细（细粒度）。它们通常由一连串可按顺序执行的步骤组成，以完成任务。因此，第二种情况与 CoT 密切相关（见第 3.3 节）。</li></ul></li></ul><h2 id="multimodal-chain-of-thought"><a class="markdownIt-Anchor" href="#multimodal-chain-of-thought"></a> Multimodal Chain of thought</h2><p>正如开创性（pioneer，先前的）的工作[7]所指出的那样，思维链是“一系列中间推理步骤”，已经被证明在复杂推理任务中是有效的[7, 87, 88]。思维链的主要思想是提示LLM不仅输出最终答案，还输出导致答案的推理过程，类似于人类的认知过程</p><p>受自然语言处理领域的成功启发，已经提出了多个工作来将单模态思维链扩展到多模态思维链（M-CoT）。我们在图3中总结了这些工作。首先，类似于M-IT中的情况（参见第3.1节），需要填补模态差距（gap，bridge）（第3.3.1节）。然后，我们引入了不同的范式来获得M-CoT能力（第3.3.2节）。最后，我们描述了M-CoT的更具体方面，包括链的配置（第3.3.3节）和链的形式（第3.3.4节）。<br><img src="image-20230918104106070.png" alt="image-20230918104106070"></p><h2 id="modality-bridging-2"><a class="markdownIt-Anchor" href="#modality-bridging-2"></a> Modality bridging</h2><p>要将 NLP 的成功经验应用于多模态，首先要解决的问题就是模态桥接。实现这一目标的方法大致有两种：融合特征或将视觉输入转化为文本描述。与第 3.1.5 节中的情况类似，我们将它们分别归类为可学习接口和专家模型，并依次进行讨论。</p><ul><li><strong>可学习接口</strong>这种方法涉及采用可学习接口将视觉嵌入映射到词嵌入空间。然后，将映射后的嵌入作为prompt发送给LLM，与其他语言一起引发M-CoT推理。例如，CoT-PT [81]将多个Meta-Net链接起来进行prompt微调，以模拟推理链，其中每个Meta-Net将视觉特征嵌入到与提示（prompt）相关的特定步骤偏置中（<code>where each Meta-Net embeds visual features into a step-specific bias to the prompt，其中，每个Meta - Net将视觉特征嵌入到对提示的特定步骤的偏见中</code>）。Multimodal-CoT [82]采用了一个两阶段的框架，具有共享的基于Transformer的结构[89]，其中视觉和文本特征通过交叉注意力进行交互。</li><li><strong>专家模型</strong>：引入一个专家模型将视觉输入转换为文本描述是一种可行的模态连接方法。例如，ScienceQA [65]采用图像字幕模型，并将图像字幕和原始语言输入的拼接传递给LLM。尽管简单直接，这种方法在字幕过程中可能会造成信息丢失[33, 82]</li></ul><h2 id="learning-paradigms"><a class="markdownIt-Anchor" href="#learning-paradigms"></a> Learning paradigms</h2><p>学习范式也是一个值得研究的方面。获得M - CoT能力的途径大致有三种</p><ul><li>finetuning</li><li>training-free few/zero shot</li><li>三种方式对样本量的要求是依次递减的</li></ul><p><strong>finetuning</strong>：直观上，<strong>微调方法往往涉及到对特定数据集进行M - CoT学习。</strong> 例如，Science QA [ 65 ]构建了一个带有讲座和解释的科学问答数据集，该数据集可以作为学习CoT推理的来源，并在该数据集上进行微调。多模态CoT [ 82 ]也使用了Science QA基准，但<strong>以两步方式</strong>生成输出，即理据(推理步骤链)和基于理据的最终答案。CoT-PT [ 81 ]通过结合即时调整和特定步骤的视觉偏向来学习一个隐式的推理链。<br><strong>few/zero-shot</strong>：小样本/零样本学习在计算效率上更高效。</p><ul><li>它们之间的主要区别在于，小样本学习通常需要手工制作一些（a few（这里可以理解成少量的））语境（in-context）样本，以便模型能够更容易地一步一步地学习推理。</li><li>零样本学习不需要任何具体的CoT学习实例。（将指令instruction作为prompt）<ul><li>在这种情况下，通过提示设计的指令（如“让我们逐帧思考”或“这两个关键帧之间发生了什么”）（In this case, by prompting designed instructions like “Let’s think frame by frame” or “What happened between these two keyframes”）[85, 86]，模型学习利用嵌入的知识和推理能力，无需明确的指导。类似地，一些工作[14, 83]使用任务和工具使用的描述作为提示（prompt），<strong>将复杂任务分解为子任务</strong>。<br><strong>Chain Configuration（链配置）</strong><br>链的配置是推理的一个重要方面，可以分为自适应和预定义形式（<code>链式配置是推理的一个重要方面，可分为自适应配置和预定义配置。</code>）。自适应配置要求LLM自行决定何时停止推理链[14, 65, 75, 76, 82, 83]，而预定义配置使用预定义的长度停止链[81, 84–86]。<br><strong>Generation Patterns 生成模式</strong><br>链是如何构建的是一个值得研究的问题。我们将当前的工作总结为：</li></ul></li><li>基于填充的模式（an infillingbased pattern）：具体来说，基于填充的模式要求通过前后上下文（前后步骤）之间的推理步骤推断来填补逻辑间隙[85, 86]。</li><li>基于预测的模式（a predicting-based pattern）：基于预测的模式要求根据指令和以前的推理历史[14, 65, 75, 76, 82, 83]来扩展推理链。</li><li><strong>这两种类型的模式都要求生成的步骤应保持一致和正确</strong></li></ul><h2 id="llm-aided-visual-reasoningllm辅助视觉推理"><a class="markdownIt-Anchor" href="#llm-aided-visual-reasoningllm辅助视觉推理"></a> LLM-Aided Visual reasoning（LLM辅助视觉推理）</h2><h3 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h3><p>受工具增强型LLMs成功的启发[ 95-98 ]，一些研究探讨了调用外部工具[ 14、34、75、76]或视觉基础模型[ 14,83,84,91,92,99]进行视觉推理任务的可能性。这些工作以LLMs作为不同角色的帮助者，构建了任务特定（<strong><mark>task-specific</mark></strong>）的[ 84、90、93 ]或通用的（<strong><mark>general-purpose</mark></strong>）[ 14,75,76,80,83]视觉推理系统。</p><p>与传统的视觉推理模型[100–102]相比，这些工作具有几个优点：</p><ul><li><strong>较强的泛化能力。</strong> 利用从大规模预训练中学习到的丰富的开放世界知识，这些系统可以很容易地泛化到未见过的对象或概念，并具有显著的零/小样本性能[ 75、76、90、91、93、94]。</li><li><strong>Emergent abilities</strong> ：借助于LLMs强大的推理能力和丰富的知识，这些系统能够完成复杂的任务。例如，给定一幅图像，MM-REACT [ 14 ]可以解释表面下的含义，例如解释meme为何是有趣的。</li><li><strong>Better interactivity and control 更好的互动性和控制性</strong><ul><li>更好的交互性和控制性。传统模型通常允许一组有限的控制机制，并且往往需要昂贵的精简（组织好的，curated）数据集[ 103、104 ]。</li><li>相比之下，基于LLM的系统具有在用户友好界面中进行精细控制的能力(例如点击和自然语言查询)[ 84 ]。<br>本节的以下部分按照图4中的显示顺序组织：首先介绍在构建LLM辅助视觉推理系统时采用的不同训练范式（第3.4.2节）。随后，我们深入探讨LLM在这些系统中扮演的主要角色（第3.4.3节）。最后，我们以各种类型的性能评估总结我们的讨论。<br><img src="image-20230918104142519.png" alt="image-20230918104142519"></li></ul></li></ul><h3 id="training-paradigms"><a class="markdownIt-Anchor" href="#training-paradigms"></a> Training Paradigms</h3><p>根据训练范式的不同，LLM辅助的视觉推理系统可以分为training-free和微调finetuning两类。<br><strong>training-free</strong></p><ul><li>在预训练的LLMs中存储了丰富的先验知识，一种直观而简单的方法是冻结预训练模型，直接促使LLMs满足各种需求。根据设定，推理系统可以进一步分为少样本模型和零样本模型。<ul><li>少样本模型（few-shot）[ 14、75、76、80 ]需要一些手工设计的语境（in-context）样本(<strong>见§ 3.2</strong> )来指导LLMs生成程序（programs）或执行步骤序列。这些程序或执行步骤作为相应基础模型或外部工具/模块的指令。</li><li>零样本模型则更进一步，直接利用LLM的语言学/语义学知识或推理能力。例如，PointCLIP V2 [ 93 ]促使GPT - 3生成具有3D相关语义的描述，以便更好地与相应的图像对齐。在CAT [ 84 ]中，LLMs被指导根据用户查询对字幕进行精化。<br><strong>Finetuning</strong></li></ul></li><li>为了激活工具使用方面的规划能力并提高系统的指令跟随（<strong>instruction-following</strong>）能力，GPT4Tools [ 34 ]引入了指令调整方法(<strong>参见§ 3.1</strong> )。收集了一个新的工具相关指令数据集，并使用该数据集对模型进行微调。</li></ul><h3 id="functions"><a class="markdownIt-Anchor" href="#functions"></a> Functions</h3><p>为了进一步考察LLM在LLM辅助的视觉推理系统中究竟扮演何种角色，现有的相关工作分为三类</p><ul><li>LLM as a Controller</li><li>LLM as a Decision Maker</li><li>LLM as a Semantics Refiner<br>前两个角色，即控制者和决策者，与CoT有关(见§ 3.3 )。它经常被使用，因为复杂的任务需要分解成中间更简单的步骤。单轮任务中Controller 更常见，多轮任务中Decision Maker更常见。<br><strong>LLM as a Controller</strong></li><li>在这种情况下，LLMs充当中央控制器<ul><li>将一个复杂的任务分解为更简单的子任务/步骤<ul><li>第一步通常是利用LLMs的CoT能力来完成的。第二步将这些任务分配给合适的工具/模块。具体来说，llm被明确提示输出任务规划[80]，或者更直接地输出要调用的模块[34,75,76]。例如，VISPROG[76]提示GPT-3输出一个可视化程序，其中每个程序行调用一个模块来执行一个子任务。此外，LLMs还需要为模块输入输出参数名。为了处理这些复杂的需求，一些手工制作的语境(见§ 3.1 )例子被用作参考[ 75、76、80 ]。这与推理链的优化(见§3.3)密切相关，或者更具体地说，是least-to-most prompting[105]技术。通过这种方式，复杂问题被分解成子问题依次解决。<br><strong>LLM as a Decision Maker</strong></li></ul></li></ul></li><li>在这种情况下，复杂任务以多轮的方式进行求解，往往以迭代的方式进行[ 91 ]。决策者通常履行以下职责：( 1 )总结当前上下文和历史信息，判断当前步骤可获得的信息是否足以回答问题或完成任务；( 2 )整理和归纳答案，以用户友好的方式呈现。<br><strong>LLM as a Semantics Refiner</strong></li><li>当LLM作为语义提炼者时，研究人员主要利用他们丰富的语言学和语义学知识。具体来说，LLM经常被要求将信息整合到连贯流畅的自然语言句子中[94]，或者根据不同的特定需求生成文本[84,90,93]</li></ul><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><p>有两种方法可以评估LLM-Aided视觉推理系统的性能，即基准度量[75,76,90,91,93,94]和手动评估[34,76,92]。手动人工评估一般都是需要对模型的某些特殊方面进行评估，例如生成结果的丰富性、准确性，或者模型生成的某种思想等。（<code>有点像M-IT中的那一块</code>）</p><h1 id="challenges-and-future-directions"><a class="markdownIt-Anchor" href="#challenges-and-future-directions"></a> Challenges and Future Directions</h1><p>MLLM的发展还处于初级阶段，仍有很大的改进空间，现总结如下：</p><ul><li>目前的多层感知机在感知能力上仍然有限，导致视觉信息获取不完全或错误。这可能是由于信息容量和计算负担之间的折中。更具体地说，Q-Former [ 64 ]仅使用32个可学习的标记（tokens）来表示一幅图像，这可能会导致信息丢失。尽管如此，增大token大小势必会给输入长度通常有限的LLMs带来较大的计算负担。一种潜在的方法是引入像SAM [ 8 ]这样的大型视觉基础模型来更有效地压缩视觉信息[ 21、29 ]。</li><li>MLLM的推理链条可能是脆弱的。例如，Fu等[ 73 ]发现，在一个数学计算案例中，MLLM虽然计算出了正确的结果，但由于推理的断裂，仍然给出了错误的答案。这表明单模态LLM的推理能力可能不等于LLM接收到视觉信息后的推理能力。如何改进多模态推理是一个值得研究的课题。</li><li>MLLMs的指令跟随能力需要提升。M - IT之后，尽管有明确的指令&quot;请回答是或否&quot; [ 73 ]，但仍有部分MLLM无法生成预期的答案( ‘是’或’否’)。这表明，指令调优可能需要覆盖更多的任务以提高泛化性</li><li>object<strong>幻觉</strong>问题是广泛存在的[ 13、44]，这在很大程度上影响了MLLMs的可靠性。这可能是由于对齐预训练不足造成的[ 13 ]。因此，<strong>一种可能的解决方案是在视觉和文本模态之间进行更细粒度的对齐</strong>。<code>细粒度是指图像的局部特征，可以通过SAM [ 21、29 ]获取，以及相应的局部文本描述。</code></li><li>需要Parameter-efficient training。现有的两种模态桥接方式，即可学习接口和专家模型，都是为减少计算负担而进行的初步探索。更有效的训练方法可以在有限的计算资源下释放更多的功能。</li></ul><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>在本文中，我们对现有的MLLM文献进行了调查，并对其主要方向进行了概述，包括三种常见的技术( M - IT、M - ICL、MCoT)和构建任务解决系统的通用框架( LAVR )。此外，我们还强调了当前有待填补的研究空白，并指出了一些有前景的研究方向。我们希望此次调查能够让读者对当前MLLM的进展有一个清晰的认识，并激发更多的工作。</p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型综述（1）</title>
      <link href="/2023/09/18/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0%EF%BC%881%EF%BC%89/"/>
      <url>/2023/09/18/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0%EF%BC%881%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>this blog is for survey of LLMs (Large language Models)</p><span id="more"></span><h1 id="综述harnessing-the-power-of-llms-in-practice-a-survey-on-chatgpt-and-beyond"><a class="markdownIt-Anchor" href="#综述harnessing-the-power-of-llms-in-practice-a-survey-on-chatgpt-and-beyond"></a> 综述：Harnessing the Power of LLMs in Practice ：A Survey on ChatGPT and Beyond</h1><p><a href="https://mp.weixin.qq.com/s/wxgP42EI1ypcLKPsVqdH5A">https://mp.weixin.qq.com/s/wxgP42EI1ypcLKPsVqdH5A</a><br><a href="http://arthurchiao.art/blog/llm-practical-guide-zh/">http://arthurchiao.art/blog/llm-practical-guide-zh/</a></p><h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> abstract</h1><p>本文是一份<mark>大语言模型（LLMs）实用指南</mark>， 目的是帮助从业者和用户更好地完成他们的==自然语言处理（NLP）==相关任务 —— NLP 是 LLM 的典型使用场景（下游）。本文将从模型、数据和下游任务的角度讨论和分析 LLM 的选型和使用</p><ul><li>首先简要介绍 <mark>GPT 风格和 BERT 风格</mark>的大语言模型；</li><li>然后讨论<mark>预训练</mark>数据、<mark>训练</mark>数据和<mark>测试</mark>数据对模型选型的影响；</li><li>然后详细讨论大语言模型<mark>适合和不适合</mark>哪些自然语言处理任务（use and non-use cases）。</li></ul><p>此外，我们还探讨了大模型的 spurious biases，以及工程角度的<mark>效率、成本和延迟</mark>等重要因素， 以便从业者对实际部署大模型有一个全面了解。</p><h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>我们从<mark>模型、数据和下游任务</mark> 的角度对LLMs（large language model）的使用进行讨论和见解。</p><ul><li>首先，我们对当前 GPT 和 BERT 风格的LLMs进行介绍和简要总结。</li><li>然后，我们讨论<strong>预训练数据</strong>、训练数据和测试数据的影响。</li><li>最重要的是，我们详细讨论了大语言模型在各种自然语言处理任务中的使用和不使用案例，例如知识密集型任务、传统自然语言理解任务、自然语言生成任务、涌现能力和注意事项用于特定任务。我们提出了各种用例和非用例（use cases and non-use cases）来说明LLMs在现实场景中的实际应用和局限性。我们还尝试了解数据的重要性以及与每个 NLP 任务相关的具体挑战。此外，我们还探讨了虚假偏差对LLMs的影响，并深入研究了其他基本考虑因素，例如效率、成本和延迟，以确保全面了解在实践中部署LLMs。本综合指南旨在为研究人员和从业者提供与LLMs合作的宝贵见解和最佳实践，从而使这些模型能够在广泛的 NLP 任务中成功实施。定期更新的LLMs实用指南资源精选列表可在 <a href="https://github.com/Mooler0410/LLMsPracticalGuide">https://github.com/Mooler0410/LLMsPracticalGuide</a> 找到。</li></ul><p>近年来，大语言模型的快速发展对自然语言处理领域产生了革命性的影响 [12, 128, 131]。 这些强大的模型在各种 NLP 任务 —— 从<mark>自然语言理解</mark><strong>（NLU）到</strong><mark>生成式任务</mark><strong>（generation tasks）—— 中都展现出了巨大的潜力，甚至为</strong><mark>通用人工智能</mark>**（AGI）铺平了道路。<br>然而，有效且高效地利用这些模型需要实际了解它们的功能和局限性，以及 NLP 中涉及的数据和任务。</p><h1 id="本文目的"><a class="markdownIt-Anchor" href="#本文目的"></a> 本文目的</h1><p>作为一份给大模型从业者和用户的指南，本文主要关注<mark>下游 NLP 任务中如何使用 LLM</mark>。例如，</p><ul><li>为什么选择或不选择某些 LLM；</li><li>如何根据模型大小、计算要求和特定领域预训练模型的可用性等等因素，选择最合适的 LLM。</li><li>为从业人员和最终用户提供所需的实用知识，帮助他们成功利用 LLM 的强大功能完成自己的 NLP 任务<br>工作：</li><li>首先，我们的工作通过讨论最重要的模型（如 GPT 式和 BERT 式架构）简要介绍了 LLM。</li><li>然后，我们从数据角度深入探讨影响模型性能的关键因素，包括预训练数据、训练/调整数据和测试数据。</li><li>最后，也是最重要的一点，我们深入探讨了各种具体的 NLP 任务，深入分析（offering insights into）了 LLM 在知识密集型任务、传统 NLU 任务和生成任务中的适用性，以及这些模型所具备的新兴能力和挑战性的现实世界场景。</li><li>我们提供了详细的示例，以突出 LLM 在实际应用中的成功案例和局限性。<br>为了分析大型语言模型的能力，我们将它们与微调模型进行了比较。目前，关于大型语言模型和微调模型还没有公认的定义。考虑到实用性，我们在文章中提出了它们的定义：</li><li>LLM 是在大量数据集上预先训练的庞大语言模型，无需针对特定任务的数据进行调整；<ul><li>但这并不意味着大模型不可以微调，大模型也可以微调，提高对于任务的性能（few-shot那一块）。但是大模型提出来是在一个大的数据集上训练的，能处理的任务更加的广泛。更加的通用，泛化能力强。</li></ul></li><li>fine-tuned模型通常是较小的语言模型，它们也经过预训练，然后在较小的、针对特定任务的数据集上进一步调整，以优化其在该任务上的性能。<ul><li>针对特定的数据集，有点像“领域专家”<br>本文总结了以下 LLM 实用指南：</li></ul></li><li><strong><mark>自然语言理解</mark></strong>：在数据分布不均或训练数据极少场景下，LLM 卓越的泛化能力（generalization ability）；</li><li><strong><mark>自然语言生成</mark></strong>：利用 LLM 的能力，为各种应用程序创建连贯、上下文相关的高质量文本；</li><li><strong><mark>知识密集型任务</mark></strong>：利用 LLM 中存储的大量知识，解决一些需要特定领域专业知识或世界常识（general world knowledge）的任务；</li><li><strong><mark>推理能力</mark></strong>：了解和利用 LLM 的推理能力，提升基于上下文的决策能力和解决问题能力。</li></ul><h1 id="模型实用指南practical-guide-for-models"><a class="markdownIt-Anchor" href="#模型实用指南practical-guide-for-models"></a> 模型实用指南（PRACTICAL GUIDE FOR MODELS）</h1><p>本节简要介绍当前业界最先进的 LLM。 这些模型在训练策略、模型架构和使用场景上有所不同。为了更清晰地理解 LLM 的发展， 本文将它们分为两种类型：</p><ol><li><strong><mark>encoder-decoder or encoder-only</mark></strong></li><li><strong><mark>decoder-only</mark></strong><br><img src="image-20230918103207953.png" alt="image-20230918103207953"><br>几点发现：</li><li><strong><mark>decoder-only 模型逐渐成为 LLM 的主要发展趋势</mark></strong>。<ul><li>LLM 早期阶段，encoder-only 和 encoder-decoder 模型更受欢迎；</li><li>随着 2021 年 GPT-3 的横空出世，decoder-only 模型完成了一次漂亮的翻身仗；</li><li>在 BERT 带来的最初爆炸性增长之后，encoder-only 模型逐渐开始失宠；</li></ul></li><li><strong><mark>OpenAI 在 LLM 领域始终保持领先地位</mark></strong>。其他公司和机构正在努力追赶。 这种领导地位可能归因于 OpenAI 对其技术路线的坚守，即使最初大家并不看好这条路线；</li><li><strong><mark>Meta 对开源 LLM 做出了重大贡献</mark></strong>，并促进了 LLM 的研究。 在考虑对开源社区尤其是 LLM 相关的贡献时，Meta 是最慷慨的商业公司之一，Meta 开发的所有 LLM 都是开源的；</li><li><strong><mark>LLM 表现出闭源的趋势</mark></strong>。<ul><li>LLM 早期阶段（2020 年之前），大多数模型都是开源的；</li><li><strong>随着 GPT-3 的推出，公司越来越倾向于闭源他们的模型</strong>，如 PaLM、LaMDA 和 GPT-4:</li><li>因此，学术研究人员进行 LLM 训练实验变得更加困难，<strong>基于 API 的研究可能成为学术界的主要方法</strong>；</li></ul></li><li><strong><mark>encoder-decoder 模型仍然还有前途</mark></strong>。<ul><li>业界仍然在这个方向积极探索，且大部分都是开源的；</li><li>Google 对开源 encoder-decoder 架构做出了重大贡献，虽然 decoder-only 模型的灵活性和多功能性使得 Google 对这个方向的坚持似乎前途有些暗淡。<br><img src="image-20230918103144917.png" alt="image-20230918103144917"></li></ul></li></ol><h2 id="bert-style-language-models-encoder-decoder-or-encoder-only"><a class="markdownIt-Anchor" href="#bert-style-language-models-encoder-decoder-or-encoder-only"></a> BERT-style Language Models: Encoder-Decoder or Encoder-only</h2><p>自然语言数据易于获取。为了更好地利用超级数据集，人们已经提出了很多<mark>无监督训练</mark>范式（unsupervised training paradigms）， 这也促进了自然语言的<mark>无监督学习</mark>（unsupervised learning）。<br>这其中，一种常见的方式是在<mark>给定上下文的情况下，预测句子中掩掉（masked）的单词</mark>。 这种训练范式被称为遮掩语言模型（<strong><mark>Masked Language Model，MLM</mark></strong>）<br>（AE ：Autoencoder Language Models）</p><ul><li>模型能深入理解单词之间以及单词与上下文的关系，</li><li>使用 <strong><mark>Transformer 架构</mark></strong> 等技术在大量文本语料库上进行训练。<br>典型模型包括</li><li>BERT [28]</li><li>RoBERTa [65]</li><li>T5 [84]。<br>这种模型在许多 NLP 任务（如情感分析和 named entity 识别）中取得了 state-of-the-art 的结果， 已经成为自然语言处理领域的重要工具。</li></ul><p>尽管语言模型通常在架构上是任务不可知的（<strong><mark>task-agnostic</mark></strong>）， 但都需要在特定下游任务的数据集上进行微调。</p><h2 id="gpt-style-language-models-decoder-only"><a class="markdownIt-Anchor" href="#gpt-style-language-models-decoder-only"></a> GPT-style Language Models: Decoder-only</h2><p>研究人员发现，扩展语言模型的参数规模（<strong><mark>scaling up</mark></strong>） 能显著提高少样本（few-shot）甚至零样本（zero-shot）性能[16]。 少样本和零样本最成功的模型是<mark>自回归语言模型</mark> （Autoregressive Language Models，ALM），</p><ul><li>这些模型的训练方式：<strong><mark>给出前面的单词，生成这句话的下一个单词</mark></strong>。</li><li>这些模型已被广泛用于文本生成和问题回答等 NLP 任务。<br>典型的自回归语言模型包括，</li><li>GPT-3 [16]</li><li>OPT [126]</li><li>PaLM [22]</li><li>BLOOM [92]<br>这其中，GPT-3 是一个划时代的模型，它首次通过<mark>提示</mark>（prompting）和<mark>上下文学习</mark>（in-context learning） 展示了少样本/零样本也能取得不错的性能，展现了自回归语言模型的优越性。<br>还有一些模型针对特定任务进行了优化，如</li><li>CodeX [2]：代码生成</li><li>BloombergGPT [117] ：金融领域<br>最近的突破是 <strong><mark>ChatGPT</mark></strong>，它专门针对对话任务优化了 GPT-3，从而在各种实际应用中 互动性、连贯性，以及更好的上下文理解能力。<br>更加适用于生成类型的任务</li></ul><p>ChatGPT：总结：</p><ul><li>BERT适用于需要深度理解上下文的任务，它主要用于双向任务的分类和理解。</li><li>GPT适用于生成任务，它主要用于自然语言生成，如文本生成、对话生成和文本摘要等。</li><li>对于某些任务，BERT和GPT可以相互补充和结合使用，以获得更好的性能，例如，BERT可以用于理解上下文，然后GPT可以用于生成自然语言响应。</li></ul><h3 id="问答系统和对话生成人机对话"><a class="markdownIt-Anchor" href="#问答系统和对话生成人机对话"></a> 问答系统和对话生成，人机对话</h3><p>对话生成（Dialog Generation）和问答系统（Question Answering System）都属于自然语言处理领域，但它们在任务和功能上有明显的区别：</p><ol><li><strong>任务目标</strong>：<ul><li><strong>对话生成</strong>：对话生成系统的主要目标是生成自然流畅的对话文本，模拟人与人之间的对话交流。这包括生成对话中的问题、回答和对话内容，通常是一个连续性的文本流。对话生成系统通常用于构建聊天机器人、虚拟助手、客服代理等。</li><li><strong>问答系统</strong>：问答系统的主要目标是回答特定问题的文本，根据用户提出的问题从给定的数据或知识库中提取或生成正确的答案。问答系统通常依赖于文档检索、自然语言理解和信息提取技术，以提供准确的答案。</li></ul></li><li><strong>输入与输出</strong>：<ul><li><strong>对话生成</strong>：对话生成系统通常接受一系列对话轮次（例如，用户问题和系统回应）作为输入，并生成连续的文本响应作为输出，可以是一句话或多句话的对话。</li><li><strong>问答系统</strong>：问答系统接受用户提出的问题（通常是单个问题）作为输入，并生成一个准确的答案作为输出。答案通常是短文本或短语。</li></ul></li><li><strong>数据源</strong>：<ul><li><strong>对话生成</strong>：对话生成系统通常不需要特定的数据源，可以是基于事先定义的规则、预训练模型或从实际对话中学习的数据。</li><li><strong>问答系统</strong>：问答系统需要一个特定的数据源，通常是包含问题和答案的知识库、文档集合或数据库。系统需要从这些数据源中检索信息以回答用户问题。</li></ul></li><li><strong>应用领域</strong>：<ul><li><strong>对话生成</strong>：对话生成主要应用于创建具有自然语言交互能力的应用程序，如聊天机器人、虚拟助手、社交媒体机器人等。</li><li><strong>问答系统</strong>：问答系统通常应用于信息检索、知识库查询、自动问答、搜索引擎、智能搜索等需要准确回答用户问题的领域。<br>虽然对话生成和问答系统有不同的任务和用途，但它们也可以在某些情况下结合使用。例如，一个问答系统可以用于从知识库中提取答案，然后将答案转化为自然语言并与用户进行对话以提供更友好的用户体验。因此，这两种技术通常可以相互补充，根据具体需求进行选择和整合。</li></ul></li></ol><h4 id="思考"><a class="markdownIt-Anchor" href="#思考"></a> 思考</h4><p>1、感觉任务的要求是偏问答系统和检索<br>2、如何构造数据集</p><h1 id="数据实用指南"><a class="markdownIt-Anchor" href="#数据实用指南"></a> 数据：实用指南</h1><p>在本节中，我们将讨论数据在为下游任务选择合适模型时的关键作用。数据对模型有效性的影响始于预训练阶段，并一直持续到训练和推理阶段。<br>注意：</p><ol><li>LLMs generalize better than fine-tuned models in downstream tasks facing out-of-distribution data, such as adversarial examples and domain shifts.</li><li>LLMs are preferable to fine-tuned models when working with limited annotated data, and both can be reasonable choices when abundant annotated data is available, depending on specific task requirements.</li><li>It’s advisable to choose models pre-trained on fields of data that are similar to downstream tasks.</li></ol><h2 id="pretraining-data"><a class="markdownIt-Anchor" href="#pretraining-data"></a> Pretraining data</h2><p>预训练数据在大语言模型的开发中起着关键作用。</p><ol><li>作为 <strong><mark>LLM 超能力</mark></strong>（remarkable capabilities）[5，47] <strong><mark>的基础</mark></strong>， 预训练数据的质量、数量和多样性显著影响 LLM 的性能[124]。 常用的预训练数据包括<mark>多种文本数据</mark>，例如书籍、文章和网站。 数据经过精心挑选，以确保全面代表人类知识、语言差别和文化观点。<ol><li>#思考<ol><li><strong><mark>对于自身的任务也需要数据集能够充分的体现任务的要求，要问答/查询的内容。</mark></strong></li></ol></li></ol></li><li>预训练数据的重要性在于它能为语言模型提供丰富的单词知识、语法、句法和语义理解，以及识别上下文和生成连贯反应的能力。 预训练数据的<mark>多样性</mark>也对模型性能起着至关重要的作用，LLM 的性能高度依赖于<mark>预训练数据的组成</mark>。<strong>LLM 的选择在很大程度上取决于预训练数据的成分</strong>。 例如，<ul><li>PaLM [22] 和 BLOOM [92] <mark>多语言任务</mark>（multilingual tasks）和<mark>机器翻译</mark>方面表现出色，因为它们有丰富的多语言预训练数据；</li><li><strong>PaLM 还很擅长<mark>问答任务</mark>，因为预训练数据中包含大量社交媒体对话和书籍语料库 [22]；</strong></li><li>GPT-3.5（code-davinci-002）预训练数据集中集成代码数据，因此<mark>代码执行和代码补全</mark> 能力很强。<br>简而言之，在针对 NLP 任务做 LLM 选型时，建议选择那些<mark>在类似数据领域上进行过预训练</mark>的模型。</li></ul></li></ol><h2 id="finetuning-data"><a class="markdownIt-Anchor" href="#finetuning-data"></a> Finetuning data</h2><p>如果已经有了通用大模型，接下来想部署到线上环境提供服务，那根据手头 <strong><mark>标注数据（annotated data）的多少</mark></strong>，</p><ul><li>零（zero）</li><li>少（few）</li><li>丰富（abundant）<br>可以在部署之前先对大模型进行<mark>配置调整或模型微调</mark>。</li></ul><h3 id="zero-annotated-data-通用大模型-zero-shot-配置"><a class="markdownIt-Anchor" href="#zero-annotated-data-通用大模型-zero-shot-配置"></a> Zero annotated data ：通用大模型 + zero-shot 配置</h3><p>这种情况即没有标注数据，那就没有微调的可能了；在配置方面，将 LLM 设置为 <strong><mark><code>zero-shot</code></mark></strong> 是最合适的。LLM 的 zero-shot methods [120] 已经比之前更好。此外，这种场景由于<mark>模型参数保持不变</mark>remain unaltered）， 也<mark>不存在参数更新过程</mark>（parameter update process）， 因此可以避免灾难性遗忘（catastrophic forgetting）[49]。</p><ul><li>“灾难性遗忘”（Catastrophic Forgetting）是指神经网络在学习新任务时忘记了之前学习的任务的现象。这是神经网络训练中一个常见的问题，特别是在迁移学习（Transfer Learning）或连续学习（Continual Learning）的情况下。当神经网络被训练用于多个任务时，它有时会非常快速地忘记以前学习的任务，从而在新任务上表现得更好。</li><li>灾难性遗忘通常是由于神经网络的权重更新机制造成的。当神经网络学习新任务时，它会调整权重以适应新的数据和目标。然而，这些权重的调整可能导致之前学习的任务的权重被覆盖或忘记，从而降低了在以后执行这些任务时的性能</li></ul><h3 id="few-annotated-data通用大模型-few-shot-in-context-learning"><a class="markdownIt-Anchor" href="#few-annotated-data通用大模型-few-shot-in-context-learning"></a> Few annotated data：通用大模型 + few-shot in-context learning</h3><p>这种情况下，可以将手头<mark>少量的 few-shot examples 直接通过 prompt 输入到 LLM 中</mark>， 这被称为上下文学习==（in-context learning）==， 这些数据可以有效地指导 LLM 针对具体任务进行优化（generalize to the task）。（<strong><mark>prompt engineering</mark></strong>）</p><ul><li>[16] 中指出，one-shot 和 few-shot 性能取得了显著的提高，甚至可以与 SOTA fine-tuned open-domain 模型的性能相当。</li><li>通过 scaling[16]，LLMs 的 zero/few-shot 能力可以进一步提高。</li><li>还有人提出了一些 few-shot 学习方法来增强微调模型，例如 meta-learning[56]或 transfer learning[88]。但是，由于微调模型的规模较小且容易过拟合，性能可能不如使用 LLMs。</li></ul><h3 id="abundant-annotated-data丰富的标注数据通用大模型微调模型"><a class="markdownIt-Anchor" href="#abundant-annotated-data丰富的标注数据通用大模型微调模型"></a> Abundant annotated data：丰富的标注数据：通用大模型/微调模型</h3><p>如果有大量特定任务的注释数据，就可以考虑微调模型和 LLM。在大多数情况下，微调模型可以很好地适应数据。在这种情况下，选择使用微调模型还是 LLM 取决于特定任务，也取决于许多因素，包括所需的性能、计算资源和部署限制。</p><ul><li>大多数情况下，对模型进行微调（fine-tuning the model）可以很好地适应数据；</li><li>通用模型的一个优势是可用于满足一些约束条件，例如隐私 [99]。</li></ul><p>总之，这种情况下使用微调模型还是 LLM 就看具体任务以及所需的性能、计算资源和部署约束等因素了。</p><h3 id="小结通用模型-vs-微调模型的选型"><a class="markdownIt-Anchor" href="#小结通用模型-vs-微调模型的选型"></a> 小结：通用模型 vs. 微调模型的选型</h3><p>简而言之</p><ul><li>不管标注数据有多有少，通用大模型都是可以用的；</li><li>有丰富的 annotated data 时可以考虑使用微调模型。</li></ul><h2 id="test-datauser-data"><a class="markdownIt-Anchor" href="#test-datauser-data"></a> Test data/user data</h2><p>在部署 LLM 用于实际任务时，经常面临测试/用户数据与训练数据之间分布差异导致的性能问题。 这些差异可能涉及到</p><ul><li>domain shifts [132]</li><li>out-of-distribution variations [31]</li><li>adversarial examples [82]<br>它们极大<mark>降低了微调模型</mark>在实际应用中的<mark>有效性</mark>。 原因是<mark>微调模型都是基于特定数据分布拟合的</mark>，generalize to OOD data 的能力较差。</li></ul><p>另一方面，通用模型在这种情况表现得相当好，因为它们没有明确的拟合过程。 此外，最近的<mark>人类反馈强化学习</mark>（Reinforcement Learning from Human Feedback， <mark><code>RLHF</code></mark>）进一步增强了 LLM 的泛化能力[77]。例如，</p><ul><li>InstructGPT 展示了在 a wide range of tasks (各种任务)的多种指令中的熟练理解能力，甚至偶尔还能理解混合语言指令，尽管这样的指令很少。</li><li>ChatGPT 在大多数 adversarial and out-of-distribution (OOD) 分类和翻译任务上表现出一致的优势 [109]。 <strong>它在理解对话相关的文本方面的优越性，使得它在 DDXPlus 数据集 [101]上表现出色，这是一个设计用于 OOD 评估的医学诊断数据集。</strong></li></ul><h1 id="practical-guide-for-nlp-tasks任务实用指南"><a class="markdownIt-Anchor" href="#practical-guide-for-nlp-tasks任务实用指南"></a> PRACTICAL GUIDE FOR NLP tasks:任务实用指南</h1><p>In this section, we discuss in detail <strong>the use cases and no use cases</strong> for LLMs in various downstream NLP tasks and the corresponding model abilities. And in Figure 2, we summarize all discussions into a decision flow. It can be a guide for a quick decision while facing a task.<br><strong>很多时候，“大模型很好！”这个断言后紧跟着的问题就是“大模型怎么用，什么时候用？”，面对一个具体任务时，我们是应该选择微调、还是不假思索的上手大模型</strong>？这篇论文总结出了一个实用的“决策流”，根据“是否需要模仿人类”，“是否要求推理能力”，“是否是多任务”等一系列问题帮我们判断是否要去使用大模型。<br><img src="image-20230918103052162.png" alt="image-20230918103052162"></p><h2 id="traditional-nlunatural-language-modeltasks"><a class="markdownIt-Anchor" href="#traditional-nlunatural-language-modeltasks"></a> traditional NLU（natural language model）tasks</h2><p>传统的 NLU 任务是 NLP 中的一些基本任务，包括文本分类、命名实体识别（NER）、entailment prediction等。其中许多任务旨在作为大型人工智能系统（<code>这里和大模型不一样，这里更像是多个任务多个模型的组合</code>）的中间步骤，例如用于构建知识图谱的 NER。<br>在传统的 NLU 任务中，微调模型通常是比 LLM 更好的选择，当需要很强的泛化能力的时候LLM能够提供帮助。</p><h3 id="no-use-case"><a class="markdownIt-Anchor" href="#no-use-case"></a> No use case.</h3><ul><li>在大多数自然语言理解任务中，如 GLUE[106] 和 SuperGLUE[105] 中的任务，<strong>如果这些任务有丰富的注释良好的数据，并且测试集上包含极少的分布外示例（OOD）</strong>，那么微调模型仍然有更好的性能。对于不同的任务和数据集，小型微调模型与 LLM 之间的差距是不同的。</li><li><strong>文本分类</strong>：在文本分类中，LLMs 普遍逊色于微调模型；</li><li><strong>情感分析</strong>：在 IMDB 与 SST 任务上大模型与微调模型表现相仿，而在如毒性监测任务中，几乎所有的大模型都差于微调模型；<ul><li>对于另一项标志性文本分类任务–毒性检测，差距则要大得多。所有 LLM 在这项任务上都表现不佳，在 CivilComments [13] 上，即使是最好的 LLM 也只比随机猜测 [59] 好。另一方面，大多数流行的微调模型可以获得更好的性能[33]，而 Perspective API 3 仍然是检测毒性的最佳模型之一。该应用程序接口由一个基于多语言 BERT 的模型和从该模型中提炼出的几个较小的单语言 CNN 提供支持，该模型是根据公开可用的毒性数据和几个较小的单语言 CNN 调整的。这<strong>可能是由于毒性是由语言表达中的细微差别定义的，而大型语言模型无法仅根据所提供的输入准确理解这项任务。</strong></li></ul></li><li><strong>自然语言推理</strong>：在 RTE 与 SNLI 上，微调模型优于 LLMs，在 CB 等数据中，LLMs与微调模型相仿；</li><li><strong>问答</strong>：在 SQuADv2、QuAC 和许多其他数据集上，微调模型具有更好的性能，而在 CoQA 上，LLMs 表现与微调模型性能相仿；</li><li><strong>信息检索</strong>：LLMs 尚未在信息检索领域广泛应用，信息检索的任务特征使得没有自然的方式为大模型建模信息检索任务；</li><li><strong>命名实体识别</strong>：在命名实体识别中，大模型仍然大幅度逊色于微调模型，在 CoNLL03 上微调模型的性能几乎是大模型的两倍，但是命名实体识别作为一个经典的 NLP 中间任务，很有可能会被大模型取代。<ul><li>这段文本讨论了一些低级别中间任务，这些任务不是为了常规用户而是为了高级任务而设计的，例如命名实体识别（NER）和依赖解析。作者指出，目前的语言模型（LLMs）在这些任务上的表现不足，因为LLMs的当前评估主要集中在实际应用任务上。根据可用的评估结果，对于NER任务，LLMs仍然面临挑战，而经过微调的模型性能大约是LLMs的两倍。作者认为这些中间任务可能会很快消失，因为LLMs可以在不依赖这些中间任务的情况下完成高级任务（例如，依赖解析用于编码任务；NER用于某些文本生成任务）。<br>简而言之，这段文本指出LLMs在一些特定任务上的表现不够理想，但随着LLMs的发展，它们可能会取代这些任务，因此这些任务可能会变得不再重要。</li></ul></li></ul><p>总之，对于大多数传统自然语言理解的任务，微调模型的效果更好(就在benchmark的数据集上的表现和计算成本)。LLM模型通常是fine-tuned model的10/100倍大小；<strong>One possible cause for the inferior performance of LLMs on certain tasks can be the design of instructions/prompts</strong>.将 IR 和句子标记等任务的输入转换为few/zero-shot形式并非易事。另一方面，微调模型的能力上限尚未达到，一些方法如 FLAN-tuning [67] 可以进一步提高 NLU 任务的性能。另一个有趣的发现是，在 NLU 任务上，经过微调，masked language models（如 T5[85]）比相同规模的大多数自回归语言模型更好，而最近的一些结果表明，这一差距可以通过以下方式弥补：scaling[22]。</p><h3 id="use-cases"><a class="markdownIt-Anchor" href="#use-cases"></a> Use cases</h3><ul><li>代表性任务之一是杂项文本分类(miscellaneous text classification)[59]。与情感分析等经典的特定领域文本分类任务相比，杂项文本分类处理各种主题和类别，这些主题和类别之间可能没有明确或牢固的关系。<ul><li>它更接近现实世界的案例，并且很难格式化以使用微调模型。</li></ul></li><li>另一个是对抗性自然语言推理（ANLI）[74]。这是一个困难的数据集，由三轮（R1、R2 和 R3）对抗性挖掘的自然语言推理问题组成。<ul><li>LLM 在 ANLI 上表现出了卓越的性能，尤其是在 R3 和 R2 上。这两个例子都表明，在传统的 NLP 任务中，LLM 对分布外(OOD)和稀疏注释的数据(zero-shot，few-shot)具有出色的泛化能力，超过了微调模型的能力</li></ul></li></ul><p>同时，在一些小众的领域，如 Miscellaneous Text Classification，Adversarial NLI 等任务中 ，LLMs 由于更强的泛化能力因而具有更好的性能，<strong>但是在目前而言，对于有成熟标注的数据而言，微调模型可能仍然是对传统任务的最优解</strong></p><h2 id="generation-tasks"><a class="markdownIt-Anchor" href="#generation-tasks"></a> Generation tasks</h2><p><strong>自然语言生成大致包括两大类任务，其目标是创建连贯、有意义且与上下文相适应(切合语境)的符号序列</strong>。</p><ul><li>第一类任务侧重于将输入文本转换为新的符号序列，例如段落摘要和机器翻译等任务。</li><li>第二类是 &quot;开放式 &quot;生成，目的是从头开始生成文本或符号，以准确匹配输入描述，例如编写电子邮件、撰写新闻文章、创作虚构故事和编写代码。<br>由于具有很强的生成能力和创造力，LLM 在大多数生成任务中都表现出优势。</li></ul><h3 id="use-cases-2"><a class="markdownIt-Anchor" href="#use-cases-2"></a> Use cases</h3><p>生成任务要求模型全面了解输入内容或要求，并具有一定的创造性。这是LLM所擅长的。</p><ul><li><strong>文本摘要</strong>：对于文本摘要而言，如果使用传统的如 ROUGE 等的自动评估指标，LLMs 并没有表现出明显的优势，但是如果引入人工评估结果，LLMs 的表现则会大幅优于微调模型。这其实表明当前这些自动评估指标有时候并不能完整准确的反应文本生成的效果；</li><li><strong>机器翻译</strong>：对于机器翻译这样一个拥有成熟商业软件的任务而言，LLMs 的表现一般略逊于商业翻译工具，但在一些冷门语言的翻译中，LLMs 有时表现出了更好的效果，譬如在罗马尼亚语翻译英语的任务中，LLMs 在零样本和少样本的情况下击败了微调模型的 SOTA；<ul><li>在机器翻译（MT）中，尽管考虑到 BLEU[78] 等一些自动指标，LLM 的平均性能略逊于一些商业翻译工具[45]，但 LLM 可以胜任翻译工作。LLM 尤其擅长将一些低资源语言文本翻译成英语文本，例如在 WMT’16 的罗马尼亚语-英语翻译[11]中，zero-shot或few-shot LLM 的表现优于 SOTA 微调模型[22]。<strong>这主要是由于英语资源构成了预训练数据的主要部分（这里需要和下面的任务区分）</strong>。BLOOM [92] 在更多的多语言数据上进行了预训练，因此在富资源和低资源翻译中都能获得更好的翻译质量。另一个有趣的发现是，BLOOM 在罗曼语之间实现了良好的翻译质量，即使是来自加利西亚语的翻译也是如此，而加利西亚语并不包含在预训练数据中。一个合理的解释是，来自同一语言组中某些语言的文本可以帮助 LLMs 从相似性中学到更多。如果能在预训练数据中加入更多的多语言文本，翻译能力可能会进一步提高。<ul><li><code>但是在no use case的案列中，英语翻译成少有的语言的时候就会有fine-tuned model效果略优于LLMs，可能是由于其余的翻译样本之间无法互补，而且没有学习到细节</code></li></ul></li><li>这样其实还是再强调在少样本或者零样本上，LLMs更加的合适</li></ul></li><li><strong>开放式生成</strong>：在开放式生成方面，显示是大模型最擅长的工作，LLMs 生成的新闻文章几乎与人类编写的真实新闻无法区分，在代码生成、代码纠错等领域 LLMs 都表现了令人惊讶的性能。</li></ul><h3 id="no-use-case-2"><a class="markdownIt-Anchor" href="#no-use-case-2"></a> No use case.</h3><p>微调模型，如 DeltaLM+Zcode [118]，在大多数资源丰富的翻译和资源极少的翻译任务中仍然表现最佳。</p><ul><li>在资源丰富的机器翻译中，微调模型的性能略优于 LLM [22, 92]。而在资源极其匮乏的机器翻译中，如英语-哈萨克语翻译，微调模型的表现明显优于 LLM。<code>这里和机器翻译那一块有点冲突</code><ul><li>可能是fine-tuned model的精细化控制导致的<ul><li>在某些情况下，小型微调模型可以更好地进行精细控制，因为它们可能更容易调整以适应任务特定的需求。</li></ul></li></ul></li></ul><h2 id="knowledge-intensive-tasks"><a class="markdownIt-Anchor" href="#knowledge-intensive-tasks"></a> Knowledge-intensive tasks</h2><p><strong>知识密集型 NLP 任务指的是一类非常依赖背景知识、特定领域专业知识或一般现实世界知识的任务。</strong> 这些任务超越了简单的模式识别或语法分析，<strong>需要对我们的现实世界拥有“常识”并能正确的使用</strong>。它们高度依赖于对<strong>特定实体、事件和现实世界</strong><code>常识</code>的<mark>记忆和适当(正确)利用</mark>。</p><ul><li>LLMs拥有丰富的现实世界知识，在知识密集型任务中表现出色。</li><li>当知识要求与学习到的知识不匹配时，或者面对只需要上下文知识的任务时，LLMs 就会陷入困境。<ul><li>个人感觉大模型只有预训练，没有微调，模型可能对任务的匹配不高</li></ul></li></ul><h3 id="use-cases-3"><a class="markdownIt-Anchor" href="#use-cases-3"></a> use cases</h3><p>一般来说，有了数十亿个训练词库和参数，LLM 比微调模型拥有更多的真实世界知识</p><ul><li><strong>闭卷问答</strong>：在 Closed-book Question-Answering 任务中，要求模型在没有外部信息的情况下回答事实性的问题，在许多数据集如 NaturalQuestions、WebQuestions、TriviaQA 上 LLMs 都表现了更好的性能，尤其在 TriviaQA 中，零样本的 LLMs 都展现了优于微调模型的性能表现；</li><li><strong>大规模多任务语言理解</strong>：大规模多任务语言理解（MMLU）包含 57 个不同主题的多项选择题，也要求模型具备一般性的知识，在这一任务中最令人印象深刻的当属 GPT-4，在 MMLU 中获得了 86.5% 的正确率。</li><li>此外，Big-bench[96]中的一些任务旨在探测 LLM 并推断其未来能力（probe LLMs and extrapolate their future capabilities），这些任务严重依赖于对现实世界知识的记忆。在这类任务中，一些 LLM 的表现优于人类的平均水平，甚至与人类的最佳表现不相上下。例如，“印度教知识”（Hindu_knowledge）任务要求模型提供有关印度教神话的事实；“元素周期”（Periodic Elements）任务要求模型具有从元素周期表中预测元素名称的能力；“物理”（Physics）任务则通过要求模型提供解决给定物理问题所需的公式来测试模型的物理知识。</li></ul><h3 id="no-use-cases"><a class="markdownIt-Anchor" href="#no-use-cases"></a> No use cases</h3><p>值得注意的是，<strong>在知识密集型任务中，大模型并不是百试百灵，有些时候，大模型对现实世界的知识可能是无用甚至错误的，这样“不一致”的知识有时会使大模型的表现比随机猜测还差</strong>。如重定义数学任务（Redefine Math）中要求模型在原含义和从重新定义的含义中做出选择，这需要的能力与大规模语言模型的学习到的知识恰恰相反，因此，LLMs 的表现甚至不如随机猜测。<br>There are some other tasks requiring knowledge different from that learned by LLMs. The required knowledge is not that learned by LLMs about the real world. In such tasks, LLMs are not notably superior.</p><ul><li>有些任务只要求模型捕捉上下文中的自含知识。输入的上下文知识足以让模型做出预测。对于这些任务，小型微调模型可以很好地完成。机器阅读理解（MRC）就是这样一项任务。MRC 任务提供几个段落，要求模型根据这些段落预测问题的答案。我们在上一节讨论了 MRC，因为它也是一项传统的 NLU 任务</li><li>另一种情况是，LLMs 中有关现实世界的知识对任务毫无用处，甚至所需的知识与现实世界相反。因此，LLM 无法很好地完成此类任务。在某些情况下，不一致的知识甚至会使 LLM 比随机猜测更糟糕。例如，在 Big-Bench 中，Mnist ascii 任务要求模型说出 ASCII 艺术所代表的数字。这项任务所要求的能力与现实世界的知识毫无关系。此外，在 &quot;逆缩放现象 &quot;竞赛[70]中，&quot;重新定义数学 &quot;任务重新定义了一个常用符号，并要求模型在原始含义和重新定义后的含义之间做出选择。该任务的要求与 LLMs 的知识形成鲜明对比，因此 LLMs 的表现甚至不如随机猜测。</li></ul><p>作为 LLM 中真实世界知识的替代方案，允许访问额外的知识，因此模型可以通过<strong>检索增强</strong>（retrieval augmentation）获得任务所需的足够知识。检索增强的基本思想是在预测之前增加一个额外的信息检索步骤，即从大型语料库中检索与任务相关的一些有用文本。然后，模型将根据输入上下文和检索到的文本进行预测。有了检索到的附加信息，closed-book任务就可以变成 &quot;open-book &quot;任务。在这种情况下，微调模型在规模较小的情况下也能发挥很好的作用，因为所需的知识可以通过检索获得。例如，在有额外语料库的 NaturalQuestions [52] 中，检索增强模型 [44, 48] 比其他任何方法都要好得多。</p><ul><li>这句话的意思是，在大型语言模型（LLMs，如GPT系列）中，为了完成某项任务，不仅可以利用模型自身的训练知识，还可以通过访问外部知识来获取足够的信息。这外部知识通常以检索的方式被引入到模型中，以增强模型在特定任务上的性能。</li></ul><h2 id="abilities-regarding-scaling"><a class="markdownIt-Anchor" href="#abilities-regarding-scaling"></a> Abilities Regarding scaling</h2><p>除了推理之外，随着模型规模的增长，<strong>模型还会浮现一些 Emergent Ability，譬如符合操作、逻辑推导、概念理解等等</strong>。<strong>但是还有类有趣的现象称为“U形现象”，指随着 LLMs 规模的增加，模型性能出现先增加后又开始下降的现象</strong>，典型的代表就是前文提到的重定义数学的问题，这类现象呼唤着对大模型原理更加深入与细致的研究。</p><p>LLM 的扩展（如参数、训练计算等）可以极大地增强预训练语言模型的能力。随着模型规模的扩大，模型在一系列任务中的能力通常会增强。（<strong><mark>智能涌现？？</mark></strong>）</p><ul><li>从某些指标可以看出，<strong>性能与模型规模呈幂律关系</strong>。例如，用于衡量语言建模性能的交叉熵损失（cross-entropy loss）会随着模型规模的指数增长而线性下降，这也被称为 <strong>“扩展法则”[41, 47]</strong>。对于某些关键能力，如推理能力，模型规模的扩大使这些能力逐渐从非常低的状态转变为可用状态，甚至接近人类的能力。在本节中，我们将从 LLM 的能力和行为以及扩展的角度概述 LLM 的使用情况。<br><strong>注意：</strong></li><li>1）随着模型规模的指数级增长，LLM 在算术推理和常识推理等推理能力方面变得尤为突出。</li><li>(2）随着 LLM 规模的扩大，<strong>新出现的能力</strong>成为使用的偶然性，如文字处理能力和逻辑能力。</li><li>(3) 在许多情况下，由于对大型语言模型的能力如何随着规模的扩大而发生变化的了解有限，其性能并不会随着规模的扩大而稳步提高。</li></ul><h3 id="use-case-with-reasoning"><a class="markdownIt-Anchor" href="#use-case-with-reasoning"></a> Use Case with reasoning</h3><p>推理涉及对信息的理解、推断和决策，是人类智力的重要方面之一。对于 NLP 来说，这也是一项挑战。现有的许多推理任务可分为常识推理和算术推理。</p><ul><li><strong>算术推理</strong>：不夸张的说，GPT-4 的算术与推理判断的能力超过了以往的任何模型，在 GSM8k、SVAMP 和 AQuA 上大模型都具有突破性的能力，值得指出的是，通过思维链（CoT）的提示方式，可以显著的增强 LLMs 的计算能力；<ul><li>测试算术推理的任务对人类来说微不足道，旨在挑战将自然语言转化为数学符号和多步骤推理的能力。</li></ul></li><li><strong>常识推理</strong>：常识推理要求大模型记忆事实信息并进行多步推理，在大多数数据集中，LLMs 都保持了对微调模型的优势地位，特别在 ARC-C （三-九年级科学考试困难题）中，GPT-4 的表现接近 100%（96.3%）。</li></ul><h3 id="use-cases-with-emergent-abilities"><a class="markdownIt-Anchor" href="#use-cases-with-emergent-abilities"></a> Use Cases with Emergent Abilities</h3><p>模型的扩展还赋予模型一些前所未有的、超越幂律规则的神奇能力。<br>These abilities are called <strong>“emergent ability”.</strong>  As defined in [113], emergent abilities of LLMs are abilities that are not present in smaller-scale models but are present in large-scale models。</p><ul><li>这意味着这种能力无法通过推断较小规模模型的性能改进来预测，而且一旦规模超过一定范围，模型就会在某些任务上突然获得良好性能。</li><li>新出现的能力通常是不可预测和出人意料的，导致任务随机或意外出现</li></ul><p>处理单词操作是一种典型的新兴能力。它指的是学习符号操作的能力，如反向单词[16]（颠倒的单词），在这种情况下，给模型一个反向拼写的单词，模型必须输出原来的单词。例如GPT-3[16]显示了单词排序和单词解词任务的新兴能力。PaLM [22] 在 ASCII 单词识别 4 和 hyperbaton 5 任务中表现出突现能力。语言模型的逻辑能力往往会随着模型规模的扩大而出现，如逻辑推理、逻辑序列和逻辑网格谜题。此外，其他任务，如高级编码（如自动调试、代码行描述）和概念理解（如新概念、简单图灵概念），也是大型语言模型具有新兴能力的用例。</p><h3 id="no-use-cases-and-understanding"><a class="markdownIt-Anchor" href="#no-use-cases-and-understanding"></a> No-Use Cases and Understanding.</h3><p>虽然如上所述，在大多数情况下，较大的模型会带来更好的性能，但仍有许多例外情况，在选择合适的模型时应加以考虑。（这里的模型更偏向于模型大小）</p><ul><li>在某些任务中，随着 LLM 规模的增大，其性能开始下降，例如：Redefine-math：测试当常用符号被重新定义为其他含义时，语言模型是否能够处理这些符号；Intothe-unknown：要求模型选择哪条信息有助于回答问题；Memo-trap：要求 LM 以类似名言的方式写出一个短语，但结尾却不同6。这也被称为<strong>反向缩放现象（Inverse Scaling Phenomenon）</strong>。</li><li>在 LLM 的缩放中观察到的另一个有趣现象叫做 <strong>U 型现象</strong> [114]。顾名思义，这种现象指的是随着 LLM 规模的增加，它们在某些任务上的性能最初会有所提高，但随后开始下降，最终才会再次提高，例如在以下任务上：（Hindsight-neglect）：测试语言模型是否能够根据预期值来评估一个赌注是否值得下；否定质量保证（NegationQA）：这项任务采用现有的多项选择数据集，并否定每道题的一部分，以观察语言模型是否对否定敏感；引语重复（Quote-repetition）：要求模型重复(复述)提示中给出的句子，并用少量的例子来帮助它识别任务。</li><li><strong>因此，应注意性能下降的风险，如果任务与我们刚才讨论的任务类似，则应仔细考虑是否使用庞大的 LLM。</strong></li></ul><p><strong>更深入地了解 LLM 中的涌现能力、反尺度现象和 U 型现象（inverse scaling phenomenon and U-shape phenomenon），对于推进该领域的研究至关重要。</strong> 从某种意义上说，<mark>U 型现象表明，小尺度模型和大尺度模型的预测具有不同的内在机制</mark>。从这个角度看，U 型现象可以看作是反尺度现象的一种转化，是由于足够大的模型的一些突现能力造成的[114]。GPT-4[76]在某些情况下表现出反比例现象的逆转，例如在一项名为 &quot;Hindsight Neglect &quot;的任务中。如<strong>何解释 LLMs 在缩放过程中的这些行为仍是一个未决问题</strong>。人们提出了几种假设。对于突发性能力，</p><ul><li>一种解释是一项任务可能有多个关键步骤，在 LLM 大到足以处理每个步骤之前，它无法处理这项任务；</li><li>另一种解释则侧重于评估指标的粒度[113]。对于反比例放现象和 U 形现象，解释主要集中在1、模型过度依赖先验信息而非输入prompt，2、有效但误导性的少量实例，以及3、在困难任务中分散注意力的较易任务等方面 [114]（模型更加关注简单任务，对困难任务的注意力不多）。<ul><li><strong>模型对其先前信息的过度依赖</strong>：这表示模型在处理任务时过于依赖其在预训练阶段学到的通用知识，而不是充分关注任务输入提示。这可能导致模型在特定任务上的表现不佳，<code>因为它太过专注于以前的知识，而不是任务的具体要求</code>。</li><li><strong>有效但具有误导性的few-shot示例</strong>：这指的是一些示例或训练样本，它们看似有效，但实际上可能会误导模型。<code>这些示例可能会导致模型学到不准确或不合理的规律，从而影响其在实际任务上的性能</code>。</li><li><strong>分散注意力的更简单任务在困难任务中</strong>：这意味着模型可能会在面对困难任务时分散注意力，更多地关注那些相对容易的任务。<code>这可能导致模型在困难任务上的表现不佳，因为它没有足够的专注力或资源来解决那些更具挑战性的任务。</code></li></ul></li></ul><h2 id="miscellaneous-tasks杂项任务多任务"><a class="markdownIt-Anchor" href="#miscellaneous-tasks杂项任务多任务"></a> Miscellaneous tasks:杂项任务（多任务？）</h2><p><strong>注意</strong>：</p><ul><li>对于与大型预训练语言模型（LLMs）的预训练目标和数据差距较大的任务，Fine-tuned模型或专用模型仍然有它们的用武之地。（对LLMs不适用的任务）</li><li>LLM 在模仿人类、数据注释和生成方面表现出色。它们还可用于 NLP 任务的质量评估，并具有可解释性等优势。</li></ul><h3 id="no-use-case多模态数据集多模态输出是一个难点"><a class="markdownIt-Anchor" href="#no-use-case多模态数据集多模态输出是一个难点"></a> No use case.(多模态数据集，多模态输出是一个难点)</h3><p>由于目标和训练数据的不同，LLM 在完成某些任务时通常会遇到困难。<br>尽管 LLM 在各种自然语言处理任务中取得了显著的成功，但它们在回归任务中的表现却不那么令人印象深刻。例如，ChatGPT 在评估句子相似性的回归任务 GLUE STS-B 数据集上的表现就不如经过微调的 RoBERTa [130]。<strong>回归任务通常涉及预测连续值而不是离散标签</strong>，这给 LLM 带来了独特的挑战。<strong>LLM 性能不佳的一个主要原因是语言建模目标与回归任务目标之间的内在差异</strong>。==LLM 的设计目的是预测序列中的下一个单词或生成连贯的文本，其预训练的重点是捕捉语言模式和关系。==因此，它们的内部表示可能并不适合对连续的数字输出建模。此外，<strong>LLM 主要针对文本数据进行训练，侧重于捕捉自然语言处理的复杂性。</strong> <code>因此，LLM 在多模态数据（涉及处理文本、图像、音频、视频、动作和机器人等多种数据类型）上的表现在很大程度上仍有待探索</code>。而经过微调的多模态模型，如 BEiT[110] 和 PaLI [19]，仍然在视觉问题解答（VQA）和图像字幕等许多任务中占主导地位。尽管如此，最近推出的 GPT-4 [76] 已经在<strong>多模态融合</strong>方面迈出了一步，但对其能力仍缺乏详细的评估。</p><h3 id="use-case"><a class="markdownIt-Anchor" href="#use-case"></a> use case</h3><ul><li><strong>LLM 非常善于模仿人类、充当聊天机器人并执行各种任务</strong>。由 LLM 驱动的 ChatGPT 在与人类的多次对话中表现出的一致性、可靠性、信息量和鲁棒性令人惊讶。人类反馈程序在获得这些能力方面发挥了重要作用（RLHF：人类反馈强化学习）</li><li><strong>LLM 既可以充当优秀的注释者，也可以生成数据，用于数据扩增</strong>，例如[27, 29, 99, 121, 122]。在某些任务中，一些 LLM 与人类注释者的效果不相上下[37]。而从 GPT3.5 中收集的文本（text-davinci-003）已被用作训练其他语言模型的类人教学示范[100]。</li><li><strong>LLM 也可用于某些 NLG 任务的质量评估，如摘要和翻译。</strong> 在摘要任务中，GPT-4 作为一种评价器比其他方法实现了更高的人机相关性（higher correlation with humans），而且幅度很大[64]。其他一些基于 LLM 的评价器[34, 50, 64, 108]也在更多的 NLG 任务中显示出良好的人机对齐性，尤其是与传统的自动指标相比。但 LLM 评估器可能偏向于 LLM 生成的文本 [64]。</li><li>此外，正如我们在上文所讨论的，LLM 的某些能力除了能提高性能外，还能带来其他好处，例如可解释性。LLM 的 CoT（chain-of-thought） 推理能力可以显示 LLM 是如何得出预测结果的，这在实例层面上是一种很好的解释，同时还能提高性能。</li></ul><h2 id="real-world-tasks很重要"><a class="markdownIt-Anchor" href="#real-world-tasks很重要"></a> Real world “tasks”！！！！！！！！！！！！！！！！（很重要）</h2><p>在本节的最后一部分，我们将讨论 LLM 和微调模型在现实世界 &quot;任务 &quot;中的应用。我们对 &quot;任务 &quot;一词的使用比较宽泛，因为现实世界中的场景往往缺乏像学术界那样格式化的定义。许多对模型的请求甚至不能被视为 NLP 任务。模型在现实世界中面临的挑战来自三个方面</p><ul><li>`举例来说，请求模型播放音乐、控制物联网设备、执行图像识别任务等，都是不属于传统的NLP任务，因为它们需要涉及到不同类型的数据和领域知识，而不仅仅是文本数据。<ul><li><code>这句话的主要观点是，模型面临各种各样的请求，其中一些请求超出了NLP的范围，可能需要更广泛的能力，包括对多模态数据的处理、硬件控制等等，而不仅仅是纯粹的文本理解和生成。因此，要满足这些不同类型的请求，模型可能需要更多的功能和适应能力</code></li></ul></li><li><strong>嘈杂（噪声）/非结构化输入</strong>：现实世界的输入来自现实世界的非专家。他们对如何与模型交互知之甚少，甚至无法流畅地使用文本。因此，真实世界的输入数据可能很杂乱，包含错别字、口语和混合语言，这与用于预训练或微调的格式良好的数据不同。</li><li><strong>Tasks not formalized by academia:学术界暂未确定的任务</strong>：在现实世界中，学术界通常对任务定义不明确，并且比学术环境中的任务更加多样化。<mark>用户经常提出不完全属于预定义类别的查询或请求，有时单个查询中有多个任务。</mark></li><li><strong>Following users’instructions.</strong>：用户的请求可能包含多个隐式意图（例如对输出格式的特定要求），或者如果没有后续问题，他们期望的预测可能不清楚。<strong><mark>模型需要理解用户意图并提供与这些意图一致的输出。</mark></strong><br><strong>本质上，现实世界中的这些挑战来自于用户的请求与为特定任务设计的任何 NLP 数据集的分布存在显着偏差。公共 NLP 数据集并不反映模型的使用方式 [77]。</strong><br><mark>LLMs are better suited to handle real-world scenarios compared to fine-tuned models. However, evaluating the effectiveness of models in the real world is still an open problem.</mark></li></ul><p><strong>处理这种真实世界的场景需要应对模糊性、理解上下文和处理噪声输入。</strong></p><ul><li>与微调模型相比，LLMs 在这方面的能力更强，因为它们是在包含各种写作风格、语言和领域的不同数据集上训练出来的。</li><li>此外，LLMs 还具有很强的生成开放域响应的能力（open-domain responses），因此非常适合这些场景。<ul><li><strong>开放领域响应（Open-Domain Responses）</strong> 是指一种自然语言处理和人工智能领域的概念，指的是计算机系统或AI模型在回答问题、提供信息或进行对话时，不受特定领域、主题或上下文的限制。换句话说，这种响应是广泛适用于各种不同话题和问题的，而不仅仅限于某一特定领域或主题。——聊天机器人</li><li>与开放领域响应相对应的是<strong>封闭领域响应（Closed-Domain Responses）</strong>，后者限制了模型的响应范围，通常用于特定领域或任务，例如在医疗保健领域回答医学问题，或在金融领域回答金融相关问题。</li></ul></li><li>另一方面，微调模型通常是为特定的、定义明确的任务定制的，可能难以适应新的或意想不到的用户请求。它们在很大程度上依赖于明确的目标和完善的训练数据，这些数据指定了模型应该学习遵循的指令类型。由于微调模型更专注于特定的分布和结构化数据，因此在处理嘈杂的输入时可能会比较吃力。<strong>微调模型通常需要一个辅助系统来处理非结构化上下文、确定可能的意图，并相应地完善模型的响应。</strong></li></ul><p>此外，一些机制，如指令调整（instruction tuning）[91, 112]和人类对齐调整（human alignment tuning）[77]，进一步提高了 LLM 的能力，使其更好地理解和遵循用户指令。<strong>这些方法在保持连贯性和一致性的同时，提高了模型生成有益、无害和诚实响应的能力</strong>[77, 91, 112]。<code>虽然这两种方法都能使 LLM 更好地泛化到未见过的任务和指令中</code>，但我们注意到，人类标注者更喜欢为人类对齐(human alignment)而调整的模型[77]，而不喜欢用来自公共 NLP 任务（如 FLAN [112] 和 T0 [91]）的指令调整的模型。<code>原因可能与微调模型劣势的原因类似：公共 NLP 任务/数据集是为方便自动评估而设计的，它们只能涵盖真实世界使用的一小部分</code>（在自然语言生成文本摘要那一块内容提到了这一点）。</p><p><strong>涉及真实世界场景时，主要问题之一是如何评估模型是否优秀</strong>。由于没有任何正式的任务或衡量标准，<mark>对模型有效性的评估只能依靠人工标注者的反馈</mark>。考虑到人工评估的复杂性和成本，目前还没有对微调模型和 LLM 进行大规模、系统化的比较。不过，LLM（如 chatGPT）的巨大成功和普及在一定程度上证实了 LLM 的优越性。</p><h1 id="其余考虑"><a class="markdownIt-Anchor" href="#其余考虑"></a> 其余考虑</h1><p>尽管 LLM 适用于各种下游任务，但还有一些其他因素需要考虑，如<strong>效率和可信度</strong>。我们对效率的讨论包括 LLM 的训练成本、推理延迟和参数效率调整策略。同时，<mark>我们对可信度的研究包括鲁棒性与校准、公平性与偏差、潜在的虚假相关性以及 LLMs 的安全性挑战。</mark><br>Remark ：</p><ol><li>Light, local, fine-tuned models should be considered rather than LLMs, especially for those who are sensitive to the cost or have strict latency requirements. Parameter-Efficient tuning（参数高效微调） can be a viable option for model deployment and delivery.</li><li>The zero-shot approach of LLMs prohibits the <strong>learning of shortcuts from task-specific datasets</strong> , which is prevalent in fine-tuned models. Nevertheless, LLMs still demonstrate a degree of shortcut learning issues.<ol><li>大模型主打一个泛化，通用，不希望学习一些特定的联系，导致在输出的时候因为某种联系造成不良的影响。</li></ol></li><li>Safety concerns associated with LLMs should be given utmost importance as the potentially harmful or biased outputs, and hallucinations from LLMs can result in severe consequences. Some methods such as human feedback have shown promise in mitigating these problems.<ol><li>与 LLM 相关的安全问题应得到高度重视，因为 LLM <strong>可能产生的有害或偏差输出以及幻觉会导致严重后果</strong>。一些方法（如人工反馈）已显示出缓解这些问题的前景。</li></ol></li></ol><h2 id="efficiency"><a class="markdownIt-Anchor" href="#efficiency"></a> Efficiency</h2><p>实际部署除了要考虑模型准确性，<strong><mark>性能、成本和延迟</mark></strong> 都是重要考虑因素，。<br>实践中，从业者必须考虑<mark>效率和效果</mark> （efficiency with effectiveness）之间的平衡。</p><h3 id="成本"><a class="markdownIt-Anchor" href="#成本"></a> 成本</h3><p>训练，能耗，数据及大小，Flops（计算成本），硬件要求。<br>如果要使用API接口的话，价格上也是比较昂贵的，（也可能导致恶意攻击）。</p><ul><li>GPT-3.5-turbo 通用聊天服务的收费标准为 $0.002 per 1k token；</li><li>对于需要定制模型的用户，训练成本为每 $ 0.003 per 1k token，使用成本为 $0.12 per 1k token [4]；<br>因此，对于无法承担如此大成本的用户，如小型初创企业、个人用户等，小型微调模型是更好、更合理的选择。</li></ul><h3 id="latency延迟"><a class="markdownIt-Anchor" href="#latency延迟"></a> Latency：延迟</h3><p>延迟是实际部署 LLM 需要考虑的关键因素。</p><ul><li><strong>Inference time</strong>：是衡量延迟的常用指标，它高度依赖于<mark>模型大小、架构和 token 大小</mark></li><li>由于LLM通常过于庞大，无法在单个用户的机器上运行，企业通过API提供LLM服务。<strong>API的延迟</strong>可以根据用户的位置而变化，OpenAI API服务对单个请求的平均延迟可以从几百毫秒到几秒不等。</li><li>对于无法接受高延迟的情况，大型 LLM 可能不适用。例如，在许多信息检索应用中，<code>可扩展性至关重要</code>。<ul><li><strong><mark>搜索引擎</mark></strong> 需要非常高效的推理，否则就没有意义。</li><li><strong><mark><code>InstructGPT</code></mark></strong> davinci v2（175B*）的理想<mark>去噪推理时间</mark>（idealized denoised inference time） （i.e. a query-passage pair to be scored）<strong><mark><code>0.21s/request</code></mark></strong>，这对于网络搜索引擎来说太慢了。</li></ul></li></ul><h3 id="parameter-efficient-tuning"><a class="markdownIt-Anchor" href="#parameter-efficient-tuning"></a> Parameter-Efficient tuning</h3><p>在实际应用中，我们可以在一些特定的数据集上对模型进行调优。<strong>参数高效调优</strong>( Parameter-Efficient Tuning，PET )是一种有效的技术，<strong>可以在冻结预训练LLMs的大部分参数的同时调整模型参数(或额外的参数)的小部分。</strong> <mark>PEFT的主要目标是在保持原有模型性能的前提下，大幅降低计算和存储成本</mark>。</p><ul><li>常用的PET技术有LoRA [ 42 ]、Prefix Tuning [ 58 ]、P - Tuning [ 62、63 ]等。作为一个例子，LoRA（Low-Rank Adaptation :低秩自适应）方法保持了预训练模型的权重，并将低秩矩阵融入到Transformer架构的每一层。这种方法极大地减少了后续任务需要训练的参数数量，从而提高了整体效率。</li><li><strong>All these PFT methods can be helpful either for fine-tuning a model to a specific task or tuning LLMs to meet special requirements like human alignment.</strong></li></ul><p>大模型必然是未来很长一段时间我们工作生活的一部分，而对于这样一个与我们生活高度同频互动的“大家伙”，<strong>除了性能、效率、成本等问题外，大规模语言模型的安全问题几乎是大模型所面对的所有挑战之中的重中之重</strong>，<mark>机器幻觉</mark>是大模型目前还没有极佳解决方案的主要问题，大模型输出的有偏差或有害的幻觉将会对使用者造成严重后果。同时，随着 LLMs 的“公信度”越来越高，用户可能会过度依赖 LLMs 并相信它们能够提供准确的信息，这点可以预见的趋势增加了大模型的安全风险。</p><p>除了误导性信息外，<strong>由于 LLMs 生成文本的高质量和低成本，LLMs 有可能被利用为进行仇恨、歧视、暴力、造谣等攻击的工具，LLMs 也有可能被攻击以未恶意攻击者提供非法信息或者窃取隐私</strong>，据报道，三星员工使用 ChatGPT 处理工作时意外泄漏了最新程序的源代码属性、与硬件有关的内部会议记录等绝密数据。</p><h2 id="trustworthiness可信赖我认为这里更像是模型的效果"><a class="markdownIt-Anchor" href="#trustworthiness可信赖我认为这里更像是模型的效果"></a> Trustworthiness：可信赖（我认为这里更像是模型的效果）！！！！！！！</h2><p><strong><mark>考虑到LLMs现在涉及医疗、金融和法律等敏感领域，确保它们是可信的并且能够产生可靠的输出至关重要。</mark></strong></p><h3 id="robustness-and-calibration"><a class="markdownIt-Anchor" href="#robustness-and-calibration"></a> Robustness and Calibration.</h3><p><strong>LLMs的准确性和鲁棒性被证明具有很强的相关性</strong>[ 59 ]。场景上精度较高的模型也具有较好的鲁棒性。然而，在额外的应用特定任务数据上进行调整后，零样本的鲁棒性变差[ 116 ]。这可能是由于过拟合导致的，由于模型的复杂度极高，且来自下游任务的训练样本有限，导致泛化性较差[ 43 ]。类似地，人们观察到，由于<strong>过参数化</strong>[ 51 ]，<strong>微调模型会导致显著的误校准（miscalibrations）</strong>。</p><ul><li>因此，当稳健性和校准是关键考虑因素时，微调模型可能不是最佳选择。</li><li>然而，<strong>人类对齐</strong>已经被发现是增强模型鲁棒性的潜在解决方案</li><li>另一方面，实现模型的最优校准取决于所使用的场景和适应过程。</li></ul><p>鲁棒性还一个就是得应对噪声的攻击</p><h3 id="fairness-and-bias"><a class="markdownIt-Anchor" href="#fairness-and-bias"></a> Fairness and Bias.</h3><p><strong>LLMs已被证明表现出不同的对待（处理,待遇）和影响</strong>，使社会偏见长期存在，并可能导致歧视[ 10、17]。<strong>为了保证所有用户的公平和公正</strong>，在NLP模型的开发和部署中解决这些问题是至关重要的。<code>人口统计学群体之间的表现差异可以作为公平问题的指标</code>。LLMs特别容易受到公平问题的影响，因为在方言、宗教、性别和种族等人口统计学类别中观察到了显著的表现差异[ 59 ]。然而，研究表明，<strong>与人类指令对齐的模型可以提高LLM的性能，而与它们的大小无关</strong>，其中InstructGPT模型( davinci v2 )表现出比其他LLM更小的性能差异[ 23 ]。</p><h3 id="spurious-biases虚假偏见"><a class="markdownIt-Anchor" href="#spurious-biases虚假偏见"></a> Spurious Biases.（虚假偏见）</h3><p>在预训练和微调范式下的各种自然语言理解任务中都观察到了捷径学习问题（shortcut learning problem），其中模型在预测[ 31、35、98]时<strong>严重依赖于微调数据中输入和标签之间的虚假相关性</strong>。</p><ul><li>例如，在阅读理解任务中，微调模型往往关注问题与原文之间单词的词汇匹配，忽略了预期的阅读理解任务本身[ 53 ]。</li><li>相比之下，大型语言模型LLMs并不直接在微调数据集上训练，这使得它们学习微调数据集中存在的捷径特征的可能性较小，从而增强了模型的泛化能力。</li><li>然而，LLMs并不是万无一失的，在in-context学习过程中可能会表现出一些捷径学习<ul><li>例如，最近的初步研究已经开始调查基于prompt的方法在大规模语言模型[ 111、129 ]中的鲁棒性。一项这样的研究评估了GPT - 3在文本分类和信息提取任务上的小样本学习性能[ 129 ]，<code>并揭示了被检查的LLMs容易受到大多数标签偏差和位置偏差的影响，他们倾向于根据答案在训练数据中的频率或位置来预测答案。</code><ul><li>此外，这些LLMs表现出共同的token偏见，偏爱在其预训练语料中普遍存在的答案。最近的研究表明，这种位置偏差可以通过选择适当的prompt 来减轻[ 68 ]。总的来说，虽然LLMs显著降低了微调模型中普遍存在的捷径学习问题，但它们仍然存在</li></ul></li></ul></li></ul><h2 id="safety-challenges"><a class="markdownIt-Anchor" href="#safety-challenges"></a> Safety challenges！！！！！！！！！！！！</h2><p>LLMs在推理、知识保持和编码等许多领域都表现出了极强的能力。随着它们变得更加强大和像人一样，<strong>它们以重要方式影响人们的观点和行为的潜力也越来越大</strong>。因此，一些新的安全挑战应该考虑到我们的社会，并在最近的工作[ 75、76 ]中引起了许多关注</p><h3 id="hallucinations幻觉幻视我觉得这里有一些trustworthiness中robustness-and-calibration问题了可能有点交叉"><a class="markdownIt-Anchor" href="#hallucinations幻觉幻视我觉得这里有一些trustworthiness中robustness-and-calibration问题了可能有点交叉"></a> Hallucinations(幻觉，幻视)！！！！！！！！！！！！！！（我觉得这里有一些Trustworthiness中Robustness and Calibration问题了，可能有点交叉）</h3><p><mark>LLMs可能产生&quot;幻觉&quot;，或产生荒谬或不真实的内容，在各种应用中会对信息的质量和可靠性产生显著的负面影响。</mark>（<strong>生成看似合理、实际错误的文本</strong>）<br><strong>随着LLMs变得越来越有说服力和可信性，用户可能会过度依赖它们，并相信它们能在他们熟悉的领域提供准确的信息。</strong></p><ul><li>如果模型产生的内容完全是虚假的或误导性的，<strong>导致基于该信息做出不正确的决定或行动，这可能特别危险</strong>。这些结果可能在许多领域产生严重后果，如医疗、金融或公共政策，其中信息的准确性和可靠性至关重要。为了缓解这些问题，来自人类反馈的强化学习( RLHF )被广泛使用，[ 75,77]和LLMs本身已经集成到循环中[ 75 ]。<ul><li>上次看见一个用知识图谱解决大模型幻视的问题</li></ul></li></ul><h3 id="harmful-content有害内容"><a class="markdownIt-Anchor" href="#harmful-content有害内容"></a> Harmful content.（有害内容）</h3><p>由于LLMs生成的文本具有较高的连贯性、质量和可读性，LLMs中的有害内容会造成重大危害，包括仇恨言论、歧视、煽动暴力、虚假叙述，甚至社会工程学攻击。为检测和纠正这些内容而实施的保障措施可以是缓解[ 97 ]。这些LLM还可以通过提供所需的非法信息而具有双重用途潜力，导致武器扩散[ 75 ]甚至恐怖袭击计划等风险。确保负责任地使用这些LLM，并采取保障措施防止伤害是至关重要的。此外，在现有的工作中，来自人类的反馈对于消除有害输出起着重要的作用。</p><h3 id="privacy"><a class="markdownIt-Anchor" href="#privacy"></a> Privacy</h3><p>LLMs可能面临严重的安全问题。例如，用户隐私问题。据报道，三星公司的员工在无意间泄露顶级机密数据时，使用ChatGPT处理他们的工作，包括新程序本身的源代码、与硬件相关的内部会议纪要等。意大利数据保护机构宣布，ChatGPT的开发者OpenAI非法收集个人用户数据，导致意大利成为第一个因隐私问题而禁止ChatGPT的政府[ 1 ]。</p><h1 id="总结大模型的挑战与未来"><a class="markdownIt-Anchor" href="#总结大模型的挑战与未来"></a> 总结——大模型的挑战与未来</h1><p>近年来，随着大型语言模型的发展，自然语言处理领域发生了革命性的变化。有效地使用LLMs需要了解它们的能力，以及各种NLP任务的局限性。本工作为LLMs在下游NLP任务中的应用提供了实践指导。我们首先讨论GPT式和BERT式架构等显著模型及其性能影响因素。然后，我们探讨了将LLMs用于下游任务，包括知识密集型任务、NLU和NLG任务，并提供了成功和局限性的具体实例。该实践指南为LLMs提供了见解，并为在NLP任务中使用LLMs提供了最佳实践。我们希望它能使研究人员和实践者发挥他们的潜力，推动创新。</p><p>接下来，我们对LLMs的未来挑战进行了展望：</p><ul><li><strong>实践验证</strong>：在真实数据集上对所提出的模型进行评估。<ul><li>而现有的深度学习模型主要在标准的学术数据集上进行评估，如ImageNet，这些数据集是深度学习发展的里程碑。然而，<strong>标准学术数据集的局限性并不能准确反映真实世界的表现。</strong> 随着模型的发展，在反映现实世界需求的更多样、更复杂和更现实的数据上评估它们至关重要。在真实世界的&quot;数据集&quot;上评估模型，除了学术上的，将提供更严格的测试它们的能力，以及更好地了解它们在现实世界应用中的有效性。这确保了模型能够应对现实世界的挑战并提供实际的解决方案。</li></ul></li><li><strong>模型对齐</strong>：<ul><li><strong>确保日益强大和自动的模型与人类的价值和优先事项保持一致是至关重要的。</strong> 必须制定方法，以确保这些模型按照预期的行为进行，并且不会对不理想的结果进行优化。从模型开发过程开始就集成对齐技术是至关重要的。<strong>模型的透明性和可解释性也是评估和确保一致性的重要因素。</strong> 此外，当我们展望未来时，一个更加艰巨的挑战也随之而来：对齐超人系统（aligning superhuman systems）。虽然这项任务目前超出了我们的需求，但重要的是要考虑和准备对齐这种先进系统的潜在影响，因为它们可能会呈现独特的复杂性和伦理问题[ 8、15 ]。</li></ul></li><li><strong>安全隐患</strong>：Safety Alignment：安全对齐<ul><li>虽然讨论人工智能存在的风险很重要，但需要进行具体的研究，以确保高级人工智能的安全发展。这包括可解释性技术、可扩展的监督和治理技术以及模型属性的形式化验证技术。安全不应仅仅被视为模型建立过程中的一个附加部分，而应被视为模型建立过程中不可或缺的一部分。</li></ul></li><li><strong>Performance Prediction with Scaling</strong><ul><li>很难预测随着模型规模和复杂度的急剧增加，模型性能会发生怎样的变化。在扩大规模或开发新的架构后，开发更好地预测模型性能的方法将有助于更有效地利用资源和加快进展。一些可能性包括：训练一个较小的&quot;种子&quot;模型并外推其生长，模拟尺度增加或模型调整的影响，以及在不同尺度下对模型的迭代进行基准测试<strong>以构建缩放规律</strong>。这些可以在模型构建之前提供对模型性能的洞察。（超参数的学习一样？？？，如果将模型规模看成一个超参数的话）</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAT</title>
      <link href="/2023/09/07/GAT/"/>
      <url>/2023/09/07/GAT/</url>
      
        <content type="html"><![CDATA[<p>这是关于GAT的一些介绍，注意力机制在图神经网络中的应用；inductive learning；局部信息的聚合</p><span id="more"></span><p><mark>相较于GCN，GAT更加的注重局部环境</mark></p><h1 id="图注意力层"><a class="markdownIt-Anchor" href="#图注意力层"></a> 图注意力层</h1><p>注意力机制的三要素：query,source,attention value。可以设置如下</p><ul><li>Query :设置成当前中心节点的特征向量</li><li>Source设置为所有邻居的特征向量</li><li>attention value：设置为中心节点经过聚合操作后的新的特征向量<br>设图中任意节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在第l层所对应的特征向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup></msup></mrow><annotation encoding="application/x-tex">h_{i}\in R^{d^{(l)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">d^{(l)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>表示节点特征的长度；经过一个以注意力机制为核心的聚合操作之后，输出的是每个节点的新特征向量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>∈</mo><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></msup></mrow><annotation encoding="application/x-tex">h_{i}&#x27;\in R^{d^{(l+1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.010556em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">d^{(l+1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>表示输出的特征向量的长度。这个聚合操作叫做：图注意力层（GAL）！</li></ul><p><img src="GAT%5CPasted%20image%2020230907155121.png" alt><br>假设中心节点为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，我们假设邻居节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">v_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的权重系数为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><mi>W</mi><msub><mi>h</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij}=a(Wh_i,W_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi>R</mi><mrow><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>×</mo><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">W\in R^{d^{(l+1)}\times d^{(l)})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>是该层节点特征变换的权重参数。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>是相关度计算，只要满足<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></msup><mo>×</mo><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup></msup><mo>→</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">R^{d^{(l+1)}}\times R^{d^{(l)}} \rightarrow R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1230299999999998em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span></p><p>论文采用一个单层全连接层来处理：其中权重参数：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∈</mo><msup><mi>R</mi><mrow><mn>2</mn><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow></msup></mrow><annotation encoding="application/x-tex">a\in R^{2d^{(l+1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>Leaky ReLU</mtext><mo stretchy="false">(</mo><msup><mi>a</mi><mi>T</mi></msup><mo stretchy="false">[</mo><mi>W</mi><msub><mi>h</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>W</mi><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij}=\text{Leaky ReLU}(a^T[Wh_i||Wh_j])</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.177439em;vertical-align:-0.286108em;"></span><span class="mord text"><span class="mord">Leaky ReLU</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mclose">)</span></span></span></span></span></p><p>其实我认为这里有点问题，从计算（代码）来看更因该像这样<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>Leaky ReLU</mtext><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>W</mi><msub><mi>h</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>W</mi><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">]</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij}=\text{Leaky ReLU}([Wh_i||Wh_j]a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord text"><span class="mord">Leaky ReLU</span></span><span class="mopen">(</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>，中间是拼接操作。代码采用采用了一种很神奇的方式：没有使用拼接技术将两个矩阵拼接起来，而是采用了——广播机制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_prepare_attentional_mechanism_input</span>(<span class="params">self, Wh</span>):</span><br><span class="line">    <span class="comment"># Wh.shape (N, out_feature)</span></span><br><span class="line">    <span class="comment"># self.a.shape (2 * out_feature, 1)</span></span><br><span class="line">    <span class="comment"># Wh1&amp;2.shape (N, 1)</span></span><br><span class="line">    <span class="comment"># e.shape (N, N)#这样就构成了一个相似度矩阵</span></span><br><span class="line">    Wh1 = torch.matmul(Wh, self.a[:self.out_features, :])</span><br><span class="line">    Wh2 = torch.matmul(Wh, self.a[self.out_features:, :])</span><br><span class="line">    <span class="comment"># broadcast add</span></span><br><span class="line">    e = Wh1 + Wh2.T<span class="comment"># N×1+1×N</span></span><br><span class="line">    <span class="comment">#通过广播机制得到一个相似度矩阵</span></span><br><span class="line">    <span class="comment">#这里和拼接和在和a相乘在进行扩展的原理是一样的，只不过这里利用广播机制来进行计算。</span></span><br><span class="line">    <span class="comment"># 而且这里的计算量更小由4O^2变成了2O^2</span></span><br><span class="line">    <span class="keyword">return</span> self.leakyrelu(e)</span><br></pre></td></tr></table></figure><p>代码原链接：<a href="https://github.com/Diego999/pyGAT">https://github.com/Diego999/pyGAT</a></p><p>采用了广播机制减少了计算量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><msup><mi>O</mi><mn>2</mn></msup><mo>→</mo><mn>2</mn><msup><mi>O</mi><mn>2</mn></msup><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">(</mo><mtext>out_features</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">4O^2\rightarrow 2O^2,O(\text{out\_features})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1241079999999999em;vertical-align:-0.31em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord text"><span class="mord">out_features</span></span><span class="mclose">)</span></span></span></span></p><p>最后的权重系数：对e进行归一化处理：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mover accent="true"><mi>N</mi><mo>~</mo></mover><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_{ij}=softmax_j(e_{ij})=\frac{\exp(e_{ij})}{\sum\limits_{v_{k}\in \tilde{N}(v_{i})}\exp(e_{ik})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.448138em;vertical-align:-2.021138em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7500050000000001em;"><span style="top:-1.9398620000000002em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.3023300000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0000050000000003em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop op-symbol small-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.335138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.021138em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>这样就保证了所有邻居的权重系数的和为1.完成权重系数的计算对节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>进行更新：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mover accent="true"><mi>N</mi><mo>~</mo></mover><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></munder><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>W</mi><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_i&#x27;=\sigma(\sum\limits_{v_{k}\in \tilde{N}(v_{i})}\alpha_{ij}Wh_{j})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.048892em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8018919999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.685143em;vertical-align:-1.635138em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.689862em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.3023300000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.635138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>当然也可以采用多头注意力机制：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mi>σ</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msub><mi>v</mi><mi>j</mi></msub><mo>∈</mo><msub><mover accent="true"><mi>N</mi><mo>~</mo></mover><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mi>I</mi></msub><mo stretchy="false">)</mo></mrow></msub></mrow></munder><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><msub><mi>h</mi><mi>j</mi></msub></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t&#x27;=||_{k=1}^K\sigma(\sum\limits_{v_j\in\tilde N_{(v_I)}}\alpha_{ij}^{(k)}W^{(k)h_j})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.048892em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8018919999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.813048em;vertical-align:-1.763043em;"></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.689862em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span><span style="top:-3.3023300000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.03588em;margin-right:0.1em;"><span class="pstrut" style="height:2.6833299999999998em;"></span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.33853em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4327214285714286em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.763043em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231360000000004em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9379999999999998em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><img src="GAT%5CPasted%20image%2020230907164456.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGAE</title>
      <link href="/2023/09/07/VGAE/"/>
      <url>/2023/09/07/VGAE/</url>
      
        <content type="html"><![CDATA[<p>本篇文章是关于VGAE的介绍，VGAE是变分自编码器再图神经网络上的应用</p><span id="more"></span><ul><li>图变分自编码器</li><li>就是将变分自编码器用到了图上</li><li>是一种无监督学习</li><li>目的是重构误差最小</li><li>损失函数的设计和VAE的一致，考虑的是极大似然估计</li></ul><p>论文考虑的是无向无权重图，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">G</mi><mo>=</mo><mrow><mi mathvariant="script">V</mi><mo separator="true">,</mo><mi mathvariant="script">E</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}={\mathcal{V},\mathcal{E}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78055em;vertical-align:-0.09722em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.0593em;">G</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08944em;">E</span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">N=\mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span></span></span></span>表示节点数量。这里的邻接矩阵A有点不一样的是，这里考虑到了自连接也就是A的对角线不为1，为0。（<code>这里为什么要考虑自连接了</code>）</p><p>对于VAE中采用的是神经网络来拟合隐变量的方差和均值——这里隐变量的数量和样本（节点）数量是一致的。<br>对于VGAE而言论文利用了两层图卷积网络来拟合均值和方差。</p><p>推断模型</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>q</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext>    </mtext><mi>q</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>μ</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">(</mo><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(Z|X,A)=\prod_{i=1}^{N}q(z_i|X,A),with\ \ \ \ q(z_i|X,A)=\mathcal{N}(z_i|\mu_i,diag(\sigma_i^2))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>G</mi><mi>C</mi><msub><mi>N</mi><mi>μ</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mu=GCN_{\mu}(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>表示均值向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span></span></span></span>的矩阵。同理论文对方差的拟合用的是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>σ</mi><mo>=</mo><mi>G</mi><mi>C</mi><msub><mi>N</mi><mi>σ</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log \sigma=GCN_{\sigma}(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>C</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">GCN(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>的公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mi>C</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>R</mi><mi>E</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>X</mi><msub><mi>W</mi><mn>0</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">GCN(X,A)=\hat ARELU(\hat AXW_0)W_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.19677em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>其中对于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo>^</mo></mover><mo>=</mo><msup><mi>D</mi><mrow><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mi>A</mi><msup><mi>D</mi><mrow><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">\hat A=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9540200000000001em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span>对称归一化邻接矩阵。</p><p>生成模型：是由潜在变量的内积给出来的</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>z</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext>   </mtext><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>z</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(A|Z)=\prod_{i=1}^N\prod_{j=1}^{N}P(A_{ij}|z_i,z_j),with \ \ \ P(A_{ij}|z_i,z_j)=\sigma(z_i^Tz_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.2421130000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.177439em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>学习目标</p><ul><li><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>Z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>−</mo><mi>K</mi><mi>L</mi><mo stretchy="false">[</mo><mi>q</mi><mo stretchy="false">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}=\mathbb{E}_{q(Z|X,A)}[\log p(A|Z)]-KL[q(Z|X,A)||p(Z)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">Z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">A</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p></li></ul><p>Non-probabilistic graph auto-encoder (GAE) model(这里因该是一般的GAE的形式)</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>A</mi><mo>^</mo></mover><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>Z</mi><msup><mi>Z</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext>   </mtext><mi>Z</mi><mo>=</mo><mi>G</mi><mi>C</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat A=\sigma(ZZ^{T}),with\ \ \ Z=GCN(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span></span></p><h1 id="一些参考"><a class="markdownIt-Anchor" href="#一些参考"></a> 一些参考</h1><p><a href="https://zhuanlan.zhihu.com/p/64485020"> 一文理解变分自编码器（VAE）</a></p><p><a href="https://zhuanlan.zhihu.com/p/78340397">VGAE（Variational graph auto-encoders）论文详解</a></p><p><a href="https://zhuanlan.zhihu.com/p/91900950">深度学习中常见的互信息的变分上下界(详细推导)</a></p><p><a href="https://blog.csdn.net/lj2048/article/details/105846421">【GNN五大类 VGAE】（变分图自编码器）：Variational Graph Auto-Encoders</a><br><a href="https://blog.csdn.net/oldmao_2001/article/details/118729806">第六周.02.VGAE带读+代码实操</a></p><p><a href="https://blog.csdn.net/oldmao_2001/article/details/120468742">CS224W摘要09.Theory of Graph Neural Networks</a></p><p><a href="https://zhuanlan.zhihu.com/p/348498294">机器学习方法—优雅的模型（一）：变分自编码器（VAE）</a></p><h1 id="code"><a class="markdownIt-Anchor" href="#code"></a> code</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">class VGAE(nn.Module):#最终Z的维度是(N,hidden2_dim),其中N表示节点数</span><br><span class="line">def __init__(self, adj):#唯一的参数是邻接矩阵</span><br><span class="line">super(VGAE,self).__init__()</span><br><span class="line">self.base_gcn = GraphConvSparse(args.input_dim, args.hidden1_dim, adj)#第一个权重是共享的</span><br><span class="line">self.gcn_mean = GraphConvSparse(args.hidden1_dim, args.hidden2_dim, adj, activation=lambda x:x)#用于求均值 μ</span><br><span class="line">self.gcn_logstddev = GraphConvSparse(args.hidden1_dim, args.hidden2_dim, adj, activation=lambda x:x)#用于log σ</span><br><span class="line"></span><br><span class="line">def encode(self, X):</span><br><span class="line">hidden = self.base_gcn(X)</span><br><span class="line">self.mean = self.gcn_mean(hidden)</span><br><span class="line">self.logstd = self.gcn_logstddev(hidden)</span><br><span class="line">gaussian_noise = torch.randn(X.size(0), args.hidden2_dim)</span><br><span class="line">sampled_z = gaussian_noise*torch.exp(self.logstd) + self.mean#这里是重参数技巧Z=μ+σ*ε</span><br><span class="line">return sampled_z</span><br><span class="line"></span><br><span class="line">def forward(self, X):#X是特征矩阵</span><br><span class="line">Z = self.encode(X)#在这里调用了encode，然后当使用VGAE时会自动调用forward，因此会顺便调用encode这个函数</span><br><span class="line">A_pred = dot_product_decode(Z)#这里是最后的点成，即生成模型</span><br><span class="line">return A_pred</span><br><span class="line"></span><br><span class="line">class GraphConvSparse(nn.Module):</span><br><span class="line">def __init__(self, input_dim, output_dim, adj, activation = F.relu, **kwargs):</span><br><span class="line">super(GraphConvSparse, self).__init__(**kwargs)</span><br><span class="line">self.weight = glorot_init(input_dim, output_dim)</span><br><span class="line">self.adj = adj</span><br><span class="line">self.activation = activation</span><br><span class="line"></span><br><span class="line">def forward(self, inputs):</span><br><span class="line">x = inputs</span><br><span class="line"># print(self.weight.dtype)</span><br><span class="line">x = torch.mm(x,self.weight)#torch.mm是矩阵乘法</span><br><span class="line">x = torch.mm(self.adj, x)</span><br><span class="line">outputs = self.activation(x)</span><br><span class="line">return outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dot_product_decode(Z):#这里是sigmoid函数乘法</span><br><span class="line">A_pred = torch.sigmoid(torch.matmul(Z,Z.t()))#torch.matmul是矩阵乘法</span><br><span class="line">return A_pred</span><br><span class="line"></span><br><span class="line">def glorot_init(input_dim, output_dim):#用于参数的初始化</span><br><span class="line">init_range = np.sqrt(6.0/(input_dim + output_dim))</span><br><span class="line">initial = torch.rand(input_dim, output_dim)*2*init_range - init_range#这里有广播机制</span><br><span class="line">return nn.Parameter(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>插入图片</title>
      <link href="/2023/09/03/%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/"/>
      <url>/2023/09/03/%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/</url>
      
        <content type="html"><![CDATA[<p>插入图片的方法：<a href="https://zhuanlan.zhihu.com/p/542101567">https://zhuanlan.zhihu.com/p/542101567</a></p><p>注意：使用：</p><span id="more"></span><p><img src="image-20230902165946533.png" alt></p><p>而不是</p><p><img src="%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%5Cimage-20230902165946533.png" alt>（此时这里的图片不会显示)</p><p>也就是说路径要用 /这个，要是路径用了\会导致结果不会显示</p><p>而且图片要插入到笔记同名的且文件夹中（会自动创建）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">用：![](插入图片/image-20230902165946533.png)，/</span><br><span class="line">不用：![](插入图片\image-20230902165946533.png)，\</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>QCNext何为下一代？——关于QCNext模型的介绍以及关于“下一代”的讨论</title>
      <link href="/2023/09/02/QCNext%E4%BD%95%E4%B8%BA%E4%B8%8B%E4%B8%80%E4%BB%A3%EF%BC%9F%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8EQCNext%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E5%85%B3%E4%BA%8E%E2%80%9C%E4%B8%8B%E4%B8%80%E4%BB%A3%E2%80%9D%E7%9A%84%E8%AE%A8%E8%AE%BA/"/>
      <url>/2023/09/02/QCNext%E4%BD%95%E4%B8%BA%E4%B8%8B%E4%B8%80%E4%BB%A3%EF%BC%9F%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8EQCNext%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E5%85%B3%E4%BA%8E%E2%80%9C%E4%B8%8B%E4%B8%80%E4%BB%A3%E2%80%9D%E7%9A%84%E8%AE%A8%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p>QCNxet的论文《QCNeXt: A Next-Generation Framework For Joint Multi-Agent Trajectory Prediction》。文章主要是对“下一代”进行讨论.</p><span id="more"></span><h1 id="qcnexta-next-generation-framework-for-joint-multi-agent-trajectory-prediction"><a class="markdownIt-Anchor" href="#qcnexta-next-generation-framework-for-joint-multi-agent-trajectory-prediction"></a> “<strong>QCNext：A Next-Generation Framework For Joint Multi-Agent Trajectory Prediction</strong>”</h1><p>论文中所提到的“下一代”是指 QCNet 的下一代。（其实就是在QCNet上的解释）</p><p>论文中提到了两个词语：“marginal distribution”和“joint distribution”，我们结合轨迹预测这个问题域进行解释：我们首先假设有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>个智能体，未来的时间步为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>。</p><ul><li><p>“marginal distribution”——边缘分布：模型在进行多只能预测的通过解码器直接输出需要预测的N个之智能体体的轨迹，并没有考虑智能体在未来时间步内的交互。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>每个智能体都独立的服从一个分布（边缘分布）</mtext><mspace linebreak="newline"></mspace><msub><mi>X</mi><mn>1</mn></msub><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>N</mi></msub><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mtext>对于轨迹的预测就分别从这</mtext><mi>N</mi><mtext>个分布中对轨迹进行采样</mtext><mi>T</mi><mtext>条轨迹。</mtext><mspace linebreak="newline"></mspace><mtext>每条轨迹都是独立的没有联系</mtext></mrow><annotation encoding="application/x-tex">\text{每个智能体都独立的服从一个分布（边缘分布）}\\X_1\sim P(X_1),X_2\sim P(X_2),\dots,X_N\sim P(X_N)\\对于轨迹的预测就分别从这N个分布中对轨迹进行采样T条轨迹。\\每条轨迹都是独立的没有联系</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">每个智能体都独立的服从一个分布（边缘分布）</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">于</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">预</span><span class="mord cjk_fallback">测</span><span class="mord cjk_fallback">就</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">别</span><span class="mord cjk_fallback">从</span><span class="mord cjk_fallback">这</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">布</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">进</span><span class="mord cjk_fallback">行</span><span class="mord cjk_fallback">采</span><span class="mord cjk_fallback">样</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord cjk_fallback">条</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">。</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">条</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">都</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">独</span><span class="mord cjk_fallback">立</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">没</span><span class="mord cjk_fallback">有</span><span class="mord cjk_fallback">联</span><span class="mord cjk_fallback">系</span></span></span></span></span></p></li><li><p>“joint distribution”——联合分布：模型显示的考虑了智能体未来的交互，因此是联合分布。相较于边缘分布的相互独立的提取轨迹。这里更像是一个场景一个场景的进行预测：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>显示的考虑智能体之间的交互，智能体未来轨迹的分布是一个联合分布</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mtext>对于轨迹的预测就统一的抽取</mtext><mi>T</mi><mtext>次样本，每次都涉及到</mtext><mi>N</mi><mtext>个智能体之间轨迹点。</mtext><mspace linebreak="newline"></mspace><mtext>这里更像是一个一个场景的提取</mtext></mrow><annotation encoding="application/x-tex">显示的考虑智能体之间的交互，智能体未来轨迹的分布是一个联合分布\\(X_1,X_2,\dots,X_N)\sim P(X_1,X_2,\dots,X_N)\\对于轨迹的预测就统一的抽取T次样本，每次都涉及到N个智能体之间轨迹点。\\这里更像是一个一个场景的提取</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">显</span><span class="mord cjk_fallback">示</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">考</span><span class="mord cjk_fallback">虑</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">之</span><span class="mord cjk_fallback">间</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">交</span><span class="mord cjk_fallback">互</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">未</span><span class="mord cjk_fallback">来</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">布</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">联</span><span class="mord cjk_fallback">合</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">布</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">于</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">预</span><span class="mord cjk_fallback">测</span><span class="mord cjk_fallback">就</span><span class="mord cjk_fallback">统</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">抽</span><span class="mord cjk_fallback">取</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord cjk_fallback">次</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">次</span><span class="mord cjk_fallback">都</span><span class="mord cjk_fallback">涉</span><span class="mord cjk_fallback">及</span><span class="mord cjk_fallback">到</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">之</span><span class="mord cjk_fallback">间</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">点</span><span class="mord cjk_fallback">。</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">这</span><span class="mord cjk_fallback">里</span><span class="mord cjk_fallback">更</span><span class="mord cjk_fallback">像</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">场</span><span class="mord cjk_fallback">景</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">提</span><span class="mord cjk_fallback">取</span></span></span></span></span></p></li></ul><h2 id="编码器"><a class="markdownIt-Anchor" href="#编码器"></a> 编码器</h2><p>论文的场景编码器与 QCNet 中使用的相同，它是一种基于分解注意力的 Transformer，可以捕获时间依赖性、智能体映射交互和社交交互。编码器的整体架构</p><p><img src="image-20230902165946533.png" alt></p><p>论文采用 QCNet 中以query为中心的范例来对场景元素进行编码。这种编码范式背后的哲学是相对时空，它指导论文为模型配备空间维度的旋转平移不变性和时间维度的平移不变性。在该范式中，为每个场景元素建立局部时空坐标系，包括车道、人行横道、车辆、行人等。然后将这些场景元素编码在其局部坐标系中以产生不变的表示，场景元素之间的关系为Transformers 在相对时空位置嵌入的帮助下捕获。具体来说，在执行 QKV 注意力之前，注意力层中的键/值元素与相对于查询元素的时空位置嵌入相连接。在地图-地图注意力以及一系列时间注意力、智能体-地图注意力和社会注意力之后，场景编码器产生形状 [M, D] 的地图编码和形状 [A, T, D] 的智能体编码，其中 M 、 A 、 T 、 D 分别是地图多边形、建模智能体、历史时间步和隐藏单元的数量。这些编码稍后将用作解码器中的场景上下文</p><h2 id="解码器"><a class="markdownIt-Anchor" href="#解码器"></a> 解码器</h2><p>论文的解码流程遵循 QCNet 解码器的设计选择，其中循环、无锚点轨迹提议模块以数据驱动的方式生成自适应轨迹锚点，然后是基于锚点的轨迹细化模块，用于预测轨迹锚点的偏移。然而，QCNet 的原始解码器没有考虑未来时间步长的智能体之间的社交互动，因为它只聚合当前时间步长的相邻智能体的编码。因此，QCNet 解码器仅适用于边缘轨迹预测。为了解决这个问题，论文提出了一种新的类似 DETR 的解码器，可以捕获未来的社交互动。论文的解码器的详细架构如下图所示：</p><p>下图是QCNxet的解码器</p><p><img src="image-20230902190544810.png" alt></p><p>下面是QCNet：</p><p><img src="image-20230903153240693.png" alt="image-20230903153240693"></p><p>通过对比QCNext最大的改进是增加了一个增加了一个在未来时间上的交互(见上图中的Model2Time Cross-Attn模块)，这种直观上的感觉是正确的，既然我们在进行编码的时候就显示的考虑智能体之间的交互，那么我们在对未来预测的时候也应该考虑智能体之间的交互。我们接下来从实验部分来分析引入未来的交互（也就是考虑联合分布）的优势所在。</p><h2 id="实验结果"><a class="markdownIt-Anchor" href="#实验结果"></a> 实验结果</h2><p>通过上述操作模型在过去的方法上提升了预测的效果：</p><p><img src="image-20230909162809478.png" alt="image-20230909162809478"></p><p><img src="image-20230909162818737.png" alt="image-20230909162818737"></p><p>在实验过程中论文在原有的单一模型的基础上加入了集成的方法：</p><ul><li>论文使用不同的随机种子来训练 8 个模型，总共产生 48 个场景级预测。对于每个场景，48 个场景级预测用于基于加权 k 均值算法的集成。具体来说，场景中所有目标agent的联合端点作为加权k-means算法的输入，场景级分数作为样本权重。聚类分配后，对每个聚类内的联合轨迹进行平均。这可以被视为边际轨迹预测常用集成策略的简单扩展。</li></ul><p>QCNeXt 在 Argoverse 2 多智能体运动预测基准上的性能如表 1 所示可以看到集成策略可以显着提高模型的性能。但即使不使用集成，论文的方法在所有指标上都已经明显优于所有方法，这证明了论文的建模框架的优越性。</p><p>论文发现 Argoverse 2 验证/测试集中大约 20% 的场景仅评估一个智能体的预测结果。在这种情况下，联合轨迹分布和边缘轨迹分布的公式变得等效，因此论文很好奇联合预测模型和边缘预测模型在这些场景下的性能比较。此前，文献认为联合预测模型在边际指标上无法达到与边际预测模型相同的性能水平，因为联合预测任务必须考虑代理未来轨迹的一致性，因此是一项更具挑战性的任务。然而，论文惊讶地发现这个结论并不适合论文的方法。如表所示。如表 2 所示，在 minFDE6 和 MR6 等边际指标上，QCNeXt 的性能优于 Argoverse 2 上最强大的边际预测模型 QCNet 。更进一步说明了联合预测的有效性。</p><h1 id="关于下一代的讨论"><a class="markdownIt-Anchor" href="#关于下一代的讨论"></a> 关于“下一代的讨论”</h1><p>我们更宽泛的对“下一代”进行讨论，从轨迹预测模型的历史来看这一代代的模型是如何发展的。</p><p>从过去到如今轨迹预测模型经历了三个阶段：基于物理的方法，基于maneuver的方法，基于交互感知的方法。</p><h2 id="基于物理的方法"><a class="markdownIt-Anchor" href="#基于物理的方法"></a> 基于物理的方法</h2><p><strong>基于物理的方法</strong>根据车辆的运动学和动力学特征预测车辆的未来轨迹。这些方法忽略了其他车辆和基础设施对目标车辆运动的影响，因此它们经常在超过一秒的预测范围内失败。</p><ul><li><p>如过去的一些跟车模型IDM模型，GIPPS模型等，这些模型一般是基于统计物理的方法得到的。能够处理一些简单的场景；IDM模型（预测未来的速度）展示如下，模型只考虑了前车和自车的一些驾驶方法：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>v</mi><mo>˙</mo></mover><mo>=</mo><mi>a</mi><mo stretchy="false">[</mo><mn>1</mn><mo>−</mo><mo stretchy="false">(</mo><mfrac><mi>v</mi><msub><mi>v</mi><mn>0</mn></msub></mfrac><msup><mo stretchy="false">)</mo><mi>δ</mi></msup><mo>−</mo><mo stretchy="false">(</mo><mfrac><mrow><msup><mi>s</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><mi mathvariant="normal">Δ</mi><mi>v</mi><mo stretchy="false">)</mo></mrow><mi>s</mi></mfrac><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo><mspace linebreak="newline"></mspace><msup><mi>s</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><mi mathvariant="normal">Δ</mi><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>s</mi><mn>0</mn></msub><mo>+</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>v</mi><mi>T</mi><mo>+</mo><mfrac><mrow><mi>v</mi><mi mathvariant="normal">Δ</mi><mi>v</mi></mrow><mrow><mn>2</mn><msqrt><mrow><mi>a</mi><mi>b</mi></mrow></msqrt></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\dot{v} =a [1-(\frac{v}{v_0} )^\delta -(\frac{s^* (v ,\Delta v)}{s} )^2] \\s^*(v, \Delta v) = s_0 + max(0,vT+\frac{v \Delta v}{2\sqrt{ab}}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66786em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11111000000000001em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mopen">[</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.9435600000000002em;vertical-align:-0.8360000000000001em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.29033em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.17778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.93222em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">a</span><span class="mord mathnormal">b</span></span></span><span style="top:-2.89222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.10777999999999999em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p></li><li><p>而且早期的这类模型其实并不是服务于自动驾驶，而是服务于微观驾驶行为的研究——如跟驰行为和换道行为。</p></li><li><p>这类模型深处的时代也是以传统的数学，物理，统计学为基础的时代。</p></li><li><p>在该时代也出现了一种新的任务即：模型参数标定，不像深度学习，这类模型的一些参数是有实际意义的，可以结合数据的标定结果去分析数据的一些特性。</p></li></ul><h2 id="基于机动的方法这一块了解不多"><a class="markdownIt-Anchor" href="#基于机动的方法这一块了解不多"></a> 基于机动的方法（这一块了解不多）</h2><p>基于机动的方法根据一组机动原型（maneuver prototype）预测目标车辆的未来运动。这些将道路的结构考虑在内进行长期预测，但仍然忽略了车辆间的交互作用。</p><ul><li><p>加入道路等因素的考虑，相当于开始将车辆放在了真实的场景中进行分析</p></li><li><p>此时采用的方法也不局限于传统的物理的方法，开始采用统计机器学习的一些方法如在论文[4]中就采用了贝叶斯网络如下图所示：</p><p><img src="image-20230903161928954.png" alt="image-20230903161928954"></p></li><li><p>通过引入道路等约束可以避免一些不切实际的行为出现。</p></li></ul><h2 id="基于交互感知的方法主要是看了这个"><a class="markdownIt-Anchor" href="#基于交互感知的方法主要是看了这个"></a> 基于交互感知的方法（主要是看了这个）</h2><p>基于交互感知的方法，将驾驶作为一种交互活动，吸引了越来越多的兴趣，与那些非交互感知方法相比表现出更好的性能。</p><p>得益于深度学习强大的自动表征能力，此时的方法更加以深度学习的方法为主。我阅读的第一篇关于交互感知的论文是：Social lstm：这是一篇用于行人轨迹预测的方法，采用了social pooling来提取agent与agent之间的交互：</p><p><img src="image-20230903163238615.png" alt="image-20230903163238615"></p><p>随着图神经网络的发展，图神经网络在构建空间交互，非欧结构数据方面有着独有的优势。其中VectorNet就采用了图神经网络来结合车辆和场景的信息，建模交互：</p><p><img src="image-20230903163831523.png" alt></p><p>也有用transformer进行编码的：如mmtransformer：</p><p><img src="image-20230907222418790.png" alt></p><p>现在的比较热门的方法基本都属于交互感知的方法：如TNT，Dense TNT，HOME，QCNet等方法。基本的框架是：</p><ul><li>编码器：编码场景上下文信息和车辆的轨迹信息</li><li>解码器：结合编码器的输出：输出agent未来的轨迹（每个时间步的坐标点）</li></ul><p>在交互感知的方法中也出现了一些的分支，我们就输出结果的方式进行探讨：</p><p>就输出结果而言：分为单模态输出，多模态输出；单智能体输出，多智能体输出；并行输出，循环输出</p><ul><li><p>单模态输出是模型只输出一条轨迹，该方法存在一定的缺陷，在论文[3]中通过实验发现该输出结果会是多模态输出的一种平均形式，会造成与实际不符合的情况</p><p><img src="image-20230903164343922.png" alt="image-20230903164343922"></p></li><li><p>多模态输出是一种比较火也是比较复合实际的输出方式，这样的输出模拟的人的不确定性驾驶行为，模仿人类的驾驶意图，且效果更好。(如上图的子图a,c)</p></li><li><p>单智能体输出是指模型只输出一个智能体的结果，并且该模型可以在所有智能体上使用，这样可以节省计算成本，降低耗时；也可以看成是每辆车在未来没有交互，和被当成是边缘分布一样。</p></li><li><p>多智能体输出</p><ul><li><p>边缘分布的方法：每个智能体类似于单独输出的，关于未来不存在交互</p></li><li><p>联合分布的方法：每个智能体在未来是有交互的，不独立。这样可以一定程度上保证一点的安全性，避免不安全的轨迹出现（这种联合分布预测的发展也是一种趋势）</p><ul><li><p>除了本文所采用的方法之外（隐式的对安全性进行建模，因为联合分布中包括后面的评分，对轨迹冲突的分数会很低甚至不会出现对应的情况）；</p></li><li><p>另一种可以参考UniAD这篇论文，利用了未来估计的occupancy网格来使得驾驶更加安全。</p><p><img src="image-20230903164708621.png" alt="image-20230903164708621"></p></li></ul></li></ul></li></ul><ul><li>并行输出是指像MLP或TNT这样（MLP可能隐含学习了未来时间步之间的一种表示；对于TNT这种可能在对anchor修正的时候也潜在的学习了未来时间步之间的联系）这样直接输出几个时间步内的结果，这存在一个潜在的假设（在给定anchor的情况下（TNT，multipath））未来的时间步是独立的；这样的计算效率更高</li><li>循环输出类似于social-LSTM这样，一个一个时间步的输出，这样的效率比较低，之间学习了未来时间步之间的联系。</li></ul><p>除了对输出结果的讨论，还有对任务的讨论：单任务学习，多任务联合学习</p><ul><li><p>单任务学习是指模型只服务于一个任务，对本篇文章而言就是轨迹预测，像QCNext，QCNet，TNT，HOME等都是属于单任务的；</p></li><li><p>多任务学习是指多个任务共同组成一条end-to-end的pipeline，多个任务的联合学习可以对每个任务都有一定的提升效果。而且也更符合自动驾驶算法的整体运行流程</p><ul><li><p>早期的有IntentNet，将目标检测与轨迹预测结合起来学习。</p></li><li><p>现在随着大模型的发展，基于transformer的的自动驾驶大模型也被提出：UniAD；该算法统一了自动驾驶的感知，跟踪，预测和规划模块。</p><p><img src="image-20231008111236344.png" alt="image-20231008111236344"></p></li></ul></li></ul><h2 id="关于未来的探讨"><a class="markdownIt-Anchor" href="#关于未来的探讨"></a> 关于未来的探讨</h2><p>QCNext在QCNet的基础上进行完善提出了一种考虑未来交互的一种新的预测方式，提升了模型的效果。未来在轨迹预测方面我认为这种考虑未来的交互模型也是一个值得挖掘的点。</p><p>同时除了单一的轨迹预测模型，端到端的大模型应用到自动驾驶中去也是也是一个趋势，像UniAD，FusionAD，等模型将感知，预测，规划结合起来进行学习和优化。这也是人工智能：算法，大数据，算力共同推动的结果。</p><h1 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h1><p>[1]Zhou Z, Wen Z, Wang J, et al. QCNeXt: A Next-Generation Framework For Joint Multi-Agent Trajectory Prediction[J]. arXiv preprint arXiv:2306.10508, 2023.<a href="https://arxiv.org/abs/2306.10508">https://arxiv.org/abs/2306.10508</a></p><p>[2]Mo X, Xing Y, Lv C. Recog: A deep learning framework with heterogeneous graph for interaction-aware trajectory prediction[J]. arXiv preprint arXiv:2012.05032, 2020.<a href="https://arxiv.org/abs/2012.05032">https://arxiv.org/abs/2012.05032</a></p><p>[3]Cui H, Radosavljevic V, Chou F C, et al. Multimodal trajectory predictions for autonomous driving using deep convolutional networks[C]//2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019: 2090-2096.<a href="https://arxiv.org/abs/1809.10732">https://arxiv.org/abs/1809.10732</a></p><p>[4]Schreier M, Willert V, Adamy J. An integrated approach to maneuver-based trajectory prediction and criticality assessment in arbitrary road environments[J]. IEEE Transactions on Intelligent Transportation Systems, 2016, 17(10): 2751-2766.<a href="https://ieeexplore.ieee.org/abstract/document/7412746">https://ieeexplore.ieee.org/abstract/document/7412746</a></p><p>[5]A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei and S. Savarese, “Social LSTM: Human Trajectory Prediction in Crowded Spaces,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, 2016, pp. 961-971, doi: 10.1109/CVPR.2016.110.<a href="https://ieeexplore.ieee.org/document/7780479">https://ieeexplore.ieee.org/document/7780479</a></p><p>[6] Gao J, Sun C, Zhao H, et al. Vectornet: Encoding hd maps and agent dynamics from vectorized representation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 11525-11533.<a href="https://arxiv.org/abs/2005.04259">https://arxiv.org/abs/2005.04259</a></p><p>[7] Liu Y, Zhang J, Fang L, et al. Multimodal motion prediction with stacked transformers[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 7577-7586.<a href="https://arxiv.org/abs/2103.11624">https://arxiv.org/abs/2103.11624</a></p><p>[8] Hu Y, Yang J, Chen L, et al. Goal-oriented Autonomous Driving[J]. arXiv preprint arXiv:2212.10156, 2022.<a href="https://arxiv.org/abs/2212.10156">https://arxiv.org/abs/2212.10156</a></p><p>[9]Casas S, Luo W, Urtasun R. Intentnet: Learning to predict intention from raw sensor data[C]//Conference on Robot Learning. PMLR, 2018: 947-956.<a href="https://arxiv.org/abs/2101.07907">https://arxiv.org/abs/2101.07907</a></p>]]></content>
      
      
      <categories>
          
          <category> 轨迹预测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 自动驾驶 </tag>
            
            <tag> 轨迹预测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_torch.autograd.Function</title>
      <link href="/2023/08/24/pytorch-torch-autograd-Function/"/>
      <url>/2023/08/24/pytorch-torch-autograd-Function/</url>
      
        <content type="html"><![CDATA[<h1 id="这是关于torchautogradfunction"><a class="markdownIt-Anchor" href="#这是关于torchautogradfunction"></a> 这是关于torch.autograd.Function</h1><p>在 PyTorch 中，<code>torch.autograd.Function</code> 是一个基础类，用于定义自定义的autograd函数，使你能够实现任意的前向传播和反向传播操作。这对于实现自定义的操作和损失函数，或者对已有操作进行修改，都非常有用。</p><span id="more"></span><p>要使用 <code>torch.autograd.Function</code>，你需要创建一个继承自它的子类，并实现以下两个方法：<code>forward</code> 和 <code>backward</code>。</p><ol><li><p><code>forward</code> 方法：<br>这个方法定义了自定义函数的前向传播过程。它接收输入张量或其他变量作为参数，并返回计算结果。在 <code>forward</code> 方法中，你可以执行任意计算，包括创建新的张量和执行运算符。</p></li><li><p><code>backward</code> 方法：<br>这个方法定义了自定义函数的反向传播过程。它接收关于输出的梯度（通常是一个梯度张量）作为参数，并计算相对于输入的梯度。在 <code>backward</code> 方法中，你需要计算输入变量的梯度，以便在整个计算图中进行梯度传播。</p></li></ol><p>以下是一个简单的示例，演示如何使用 <code>torch.autograd.Function</code> 来实现一个自定义函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="comment"># 在 forward 方法中执行前向传播计算</span></span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>)</span><br><span class="line">        output = <span class="built_in">input</span> * <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="comment"># 在 backward 方法中计算梯度</span></span><br><span class="line">        <span class="built_in">input</span>, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output * <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义函数</span></span><br><span class="line">x = torch.tensor([<span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = MyFunction.apply(x)</span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Input gradient:&quot;</span>, x.grad)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Input gradient: tensor([2.])</span></span><br><span class="line"><span class="string">tensor([2.], grad_fn=&lt;MyFunctionBackward&gt;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>在这个示例中，<code>MyFunction</code> 继承自 <code>torch.autograd.Function</code>，并实现了 <code>forward</code> 和 <code>backward</code> 方法。你可以通过 <code>MyFunction.apply()</code> 来使用这个自定义函数。在后续的反向传播中，PyTorch 将会使用 <code>backward</code> 方法计算梯度。</p><p>这就是如何使用 <code>torch.autograd.Function</code> 来实现自定义函数，并在自定义的计算中使用 PyTorch 的自动微分。</p><ul><li><p><code>@staticmethod</code> 是 Python 中的一个装饰器（Decorator），用于将一个方法定义为静态方法。静态方法是指在类中定义的方法，不依赖于类的实例，因此可以直接通过类名调用，而不需要创建类的对象实例。</p><p>在你提供的代码中，<code>@staticmethod</code> 装饰器用于将方法定义为静态方法。具体来说，它用于 <code>SpecialSpmmFunction</code> 类中的两个方法：<code>forward</code> 和 <code>backward</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SpecialSpmmFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, indices, values, shape, b</span>):</span><br><span class="line">        <span class="comment"># ... implementation ...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="comment"># ... implementation ...</span></span><br></pre></td></tr></table></figure><p>通过将这两个方法定义为静态方法，你可以在不创建类的实例的情况下，直接通过类名调用这些方法。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">indices = ...</span><br><span class="line">values = ...</span><br><span class="line">shape = ...</span><br><span class="line">b = ...</span><br><span class="line">result = SpecialSpmmFunction.forward(indices, values, shape, b)</span><br></pre></td></tr></table></figure><p>这种方法非常适合在定义类的方法时，不需要访问实例属性或方法，或者在类的实例不存在的情况下执行一些操作。静态方法不会自动接收类的实例作为第一个参数（通常是 <code>self</code>），因此它们不依赖于类的状态。</p></li><li><p>在上面的代码中，<code>y = MyFunction.apply(x)</code> 这一行代码是通过调用 <code>MyFunction</code> 类的 <code>apply</code> 方法来计算前向传播的结果 <code>y</code>。在这个特定的示例中，<code>MyFunction</code> 类的 <code>forward</code> 方法执行的操作是将输入张量 <code>x</code> 乘以 2，因此 <code>y</code> 的值将是 <code>x</code> 的两倍。</p><p>这里，<code>MyFunction.apply(x)</code> 实际上是在前向传播中使用了自定义的操作，并返回计算得到的输出。因为我们定义了自定义函数 <code>MyFunction</code> 的 <code>forward</code> 方法，所以调用 <code>.apply(x)</code> 实际上就是调用了我们自己实现的操作。</p><p>在更复杂的情况下，自定义函数可能会执行许多不同的操作，从而实现复杂的前向传播。<code>apply</code> 方法允许我们将输入传递给这些操作，并返回输出。通常情况下，PyTorch 的模块和函数也是这样工作的，只是在内部使用了更多的优化和组件。</p><p>简而言之，<code>y = MyFunction.apply(x)</code> 将会调用自定义函数 <code>MyFunction</code> 的前向传播方法，执行该方法中的操作，并将操作的结果存储在 <code>y</code> 中。</p></li><li><p>对于print(y)</p><ul><li><p>在上面的代码中，<code>y = MyFunction.apply(x)</code> 这一行代码是通过调用 <code>MyFunction</code> 类的 <code>apply</code> 方法来计算<strong>前向传播的结果</strong> <code>y</code>。在这个特定的示例中，<code>MyFunction</code> 类的 <code>forward</code> 方法执行的操作是将输入张量 <code>x</code> 乘以 2，因此 <code>y</code> 的值将是 <code>x</code> 的两倍。</p><p>这里，<code>MyFunction.apply(x)</code> 实际上是在前向传播中使用了自定义的操作，并返回计算得到的输出。因为我们定义了自定义函数 <code>MyFunction</code> 的 <code>forward</code> 方法，所以调用 <code>.apply(x)</code> 实际上就是调用了我们自己实现的操作。</p><p>在更复杂的情况下，自定义函数可能会执行许多不同的操作，从而实现复杂的前向传播。<code>apply</code> 方法允许我们将输入传递给这些操作，并返回输出。通常情况下，PyTorch 的模块和函数也是这样工作的，只是在内部使用了更多的优化和组件。</p><p>简而言之，<code>y = MyFunction.apply(x)</code> 将会调用自定义函数 <code>MyFunction</code> 的前向传播方法，执行该方法中的操作，并将操作的结果存储在 <code>y</code> 中。</p></li></ul></li><li><p>如果令c=y.backward(),print©输出的结果为None</p></li><li><p>如果将y.backward()注释掉，print(“Input gradient:”, x.grad)为Input gradient:None</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用户新增预测挑战赛</title>
      <link href="/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/"/>
      <url>/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/</url>
      
        <content type="html"><![CDATA[<h2 id="1数据说明"><a class="markdownIt-Anchor" href="#1数据说明"></a> 1.数据说明</h2><p>赛题数据由约62万条训练集、20万条测试集数据组成，共包含13个字段。其中uuid为样本唯一标识，eid为访问行为ID，udmap为行为属性，其中的key1到key9表示不同的行为属性，如项目名、项目id等相关字段，common_ts为应用访问记录发生时间（毫秒时间戳），其余字段x1至x8为用户相关的属性，为匿名处理字段。target字段为预测目标，即是否为新增用户。</p><h2 id="2评估指标"><a class="markdownIt-Anchor" href="#2评估指标"></a> 2.评估指标</h2><p>本次竞赛的评价标准采用f1_score，分数越高，效果越好。</p><span id="more"></span><h2 id="3解题思路"><a class="markdownIt-Anchor" href="#3解题思路"></a> 3.解题思路</h2><p>参赛选手的任务是基于训练集的样本数据，构建一个模型来预测测试集中用户的新增情况。这是一个二分类任务，其中目标是根据用户的行为、属性以及访问时间等特征，预测该用户是否属于新增用户。具体来说，选手需要利用给定的数据集进行特征工程、模型选择和训练，然后使用训练好的模型对测试集中的用户进行预测，并生成相应的预测结果。</p><h2 id="4遇到的问题"><a class="markdownIt-Anchor" href="#4遇到的问题"></a> 4.遇到的问题</h2><ul><li>数据量比较大，但是特征比较少，经过处理的特征没几个，因此目的是先增加特征然后再对特征进行处理以及特征降维</li><li>还不知道数据集的具体情况，可以对数据集进行筛选（暂时还没进行）</li></ul><h2 id="5方案"><a class="markdownIt-Anchor" href="#5方案"></a> 5.方案</h2><h3 id="相关模块和数据的导入"><a class="markdownIt-Anchor" href="#相关模块和数据的导入"></a> 相关模块和数据的导入：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="comment">#简单来说LabelEncoder就是把n个类别值编码为0~n-1之间的整数，建立起1-1映射</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="comment">#load() missing 1 required positional argument: &#x27;Loader&#x27;</span></span><br><span class="line"><span class="comment">#E:\software\anaconda\anaconda3\Lib\site-packages\distributed\config.py文件里的</span></span><br><span class="line"><span class="comment">#yaml.load(f)改成yaml.safe_load(f)</span></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> HistGradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取训练集和测试集</span></span><br><span class="line"><span class="comment"># 使用 read_csv() 函数从文件中读取训练集数据，文件名为 &#x27;train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">&#x27;用户新增预测挑战赛公开数据/train.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用 read_csv() 函数从文件中读取测试集数据，文件名为 &#x27;test.csv&#x27;</span></span><br><span class="line">test_data = pd.read_csv(<span class="string">&#x27;用户新增预测挑战赛公开数据/test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_data<span class="comment">#用于观察数据集</span></span><br></pre></td></tr></table></figure><h3 id="udmap的处理将-字典中的数据和unknown数据以one-hot的存储"><a class="markdownIt-Anchor" href="#udmap的处理将-字典中的数据和unknown数据以one-hot的存储"></a> udmap的处理，将 字典中的数据和unknown数据以one-hot的存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. 将 &#x27;udmap&#x27; 列进行 One-Hot 编码 </span></span><br><span class="line"><span class="comment"># 数据样例：</span></span><br><span class="line"><span class="comment">#                    udmap  key1  key2  key3  key4  key5  key6  key7  key8  key9</span></span><br><span class="line"><span class="comment"># 0           &#123;&#x27;key1&#x27;: 2&#125;     2     0     0     0     0     0     0     0     0</span></span><br><span class="line"><span class="comment"># 1           &#123;&#x27;key2&#x27;: 1&#125;     0     1     0     0     0     0     0     0     0</span></span><br><span class="line"><span class="comment"># 2  &#123;&#x27;key1&#x27;: 3, &#x27;key2&#x27;: 2&#125;   3     2     0     0     0     0     0     0     0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 python 中, 形如 &#123;&#x27;key1&#x27;: 3, &#x27;key2&#x27;: 2&#125; 格式的为字典类型对象, 通过key-value键值对的方式存储</span></span><br><span class="line"><span class="comment"># 而在本数据集中, udmap实际是以字符的形式存储, 所以处理时需要先用eval 函数将&#x27;udmap&#x27; 解析为字典</span></span><br><span class="line"><span class="comment"># 具体实现代码：</span></span><br><span class="line"><span class="comment"># 定义函数 udmap_onethot，用于将 &#x27;udmap&#x27; 列进行 One-Hot 编码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">udmap_onethot</span>(<span class="params">d</span>):</span><br><span class="line">    v = np.zeros(<span class="number">9</span>)  <span class="comment"># 创建一个长度为 9 的零数组</span></span><br><span class="line">    <span class="keyword">if</span> d == <span class="string">&#x27;unknown&#x27;</span>:  <span class="comment"># 如果 &#x27;udmap&#x27; 的值是 &#x27;unknown&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> v  <span class="comment"># 返回零数组</span></span><br><span class="line">    d = <span class="built_in">eval</span>(d)  <span class="comment"># 将 &#x27;udmap&#x27; 的值解析为一个字典</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):  <span class="comment"># 遍历 &#x27;key1&#x27; 到 &#x27;key9&#x27;, 注意, 这里不包括10本身</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">in</span> d:  <span class="comment"># 如果当前键存在于字典中</span></span><br><span class="line">            v[i-<span class="number">1</span>] = d[<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i)]  <span class="comment"># 将字典中的值存储在对应的索引位置上</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> v  <span class="comment"># 返回 One-Hot 编码后的数组</span></span><br></pre></td></tr></table></figure><h3 id="数据集特征提取"><a class="markdownIt-Anchor" href="#数据集特征提取"></a> 数据集特征提取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 注: 对于不理解的步骤, 可以逐行 print 内容查看</span></span><br><span class="line"><span class="comment"># 使用 apply() 方法将 udmap_onethot 函数应用于每个样本的 &#x27;udmap&#x27; 列</span></span><br><span class="line"><span class="comment"># np.vstack() 用于将结果堆叠成一个数组</span></span><br><span class="line">train_udmap_df = pd.DataFrame(np.vstack(train_data[<span class="string">&#x27;udmap&#x27;</span>].apply(udmap_onethot)))</span><br><span class="line">test_udmap_df = pd.DataFrame(np.vstack(test_data[<span class="string">&#x27;udmap&#x27;</span>].apply(udmap_onethot)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">apply() 函数的自由度较高，可以直接对 Series 或者 DataFrame 中元素进行逐元素遍历操作，方便且高效，具有类似于 Numpy 的特性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为新的特征 DataFrame 命名列名</span></span><br><span class="line">train_udmap_df.columns = [<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line">test_udmap_df.columns = [<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line"><span class="comment"># 将编码后的 udmap 特征与原始数据进行拼接，沿着列方向拼接</span></span><br><span class="line">train_data = pd.concat([train_data, train_udmap_df], axis=<span class="number">1</span>)</span><br><span class="line">test_data = pd.concat([test_data, test_udmap_df], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 编码 udmap 是否为空</span></span><br><span class="line"><span class="comment"># 使用比较运算符将每个样本的 &#x27;udmap&#x27; 列与字符串 &#x27;unknown&#x27; 进行比较，返回一个布尔值的 Series</span></span><br><span class="line"><span class="comment"># 使用 astype(int) 将布尔值转换为整数（0 或 1），以便进行后续的数值计算和分析</span></span><br><span class="line">train_data[<span class="string">&#x27;udmap_isunknown&#x27;</span>] = (train_data[<span class="string">&#x27;udmap&#x27;</span>] == <span class="string">&#x27;unknown&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">test_data[<span class="string">&#x27;udmap_isunknown&#x27;</span>] = (test_data[<span class="string">&#x27;udmap&#x27;</span>] == <span class="string">&#x27;unknown&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 提取 eid 的频次特征</span></span><br><span class="line"><span class="comment"># 使用 map() 方法将每个样本的 eid 映射到训练数据中 eid 的频次计数</span></span><br><span class="line"><span class="comment"># train_data[&#x27;eid&#x27;].value_counts() 返回每个 eid 出现的频次计数</span></span><br><span class="line">train_data[<span class="string">&#x27;eid_freq&#x27;</span>] = train_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;eid&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;eid_freq&#x27;</span>] = test_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;eid&#x27;</span>].value_counts())<span class="comment">#这里在测试数据集上用的是训练集的eid的频率</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">map可以接受函数，字典，以及series（和字典类似）。然后这里会进行匹配。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 提取 eid 的标签特征</span></span><br><span class="line"><span class="comment"># 使用 groupby() 方法按照 eid 进行分组，然后计算每个 eid 分组的目标值均值</span></span><br><span class="line"><span class="comment"># train_data.groupby(&#x27;eid&#x27;)[&#x27;target&#x27;].mean() 返回每个 eid 分组的目标值均值</span></span><br><span class="line">train_data[<span class="string">&#x27;eid_mean&#x27;</span>] = train_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;eid&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;eid_mean&#x27;</span>] = test_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;eid&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">这里现根据eid进行分组</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 提取时间戳</span></span><br><span class="line"><span class="comment"># 使用 pd.to_datetime() 函数将时间戳列转换为 datetime 类型</span></span><br><span class="line"><span class="comment"># 样例：1678932546000-&gt;2023-03-15 15:14:16</span></span><br><span class="line"><span class="comment"># 注: 需要注意时间戳的长度, 如果是13位则unit 为 毫秒, 如果是10位则为 秒, 这是转时间戳时容易踩的坑</span></span><br><span class="line"><span class="comment"># 具体实现代码：</span></span><br><span class="line">train_data[<span class="string">&#x27;common_ts&#x27;</span>] = pd.to_datetime(train_data[<span class="string">&#x27;common_ts&#x27;</span>], unit=<span class="string">&#x27;ms&#x27;</span>)</span><br><span class="line">test_data[<span class="string">&#x27;common_ts&#x27;</span>] = pd.to_datetime(test_data[<span class="string">&#x27;common_ts&#x27;</span>], unit=<span class="string">&#x27;ms&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 dt.hour 属性从 datetime 列中提取小时信息，并将提取的小时信息存储在新的列 &#x27;common_ts_hour&#x27;</span></span><br><span class="line">train_data[<span class="string">&#x27;common_ts_hour&#x27;</span>] = train_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.hour</span><br><span class="line">test_data[<span class="string">&#x27;common_ts_hour&#x27;</span>] = test_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.hour</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;common_ts_day&#x27;</span>] = train_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.day</span><br><span class="line">test_data[<span class="string">&#x27;common_ts_day&#x27;</span>] = test_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.day</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x1_freq&#x27;</span>] = train_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x1&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x1_freq&#x27;</span>] = test_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x1&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x1_mean&#x27;</span>] = train_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x1&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x1_mean&#x27;</span>] = test_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x1&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x2_freq&#x27;</span>] = train_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x2&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x2_freq&#x27;</span>] = test_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x2&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x2_mean&#x27;</span>] = train_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x2&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x2_mean&#x27;</span>] = test_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x2&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#train_data[&#x27;x3_freq&#x27;] = train_data[&#x27;x3&#x27;].map(train_data[&#x27;x3&#x27;].value_counts())</span></span><br><span class="line"><span class="comment">#test_data[&#x27;x3_freq&#x27;] = test_data[&#x27;x3&#x27;].map(train_data[&#x27;x3&#x27;].value_counts())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#train_data[&#x27;x4_freq&#x27;] = train_data[&#x27;x4&#x27;].map(train_data[&#x27;x4&#x27;].value_counts())</span></span><br><span class="line"><span class="comment">#test_data[&#x27;x4_freq&#x27;] = test_data[&#x27;x4&#x27;].map(train_data[&#x27;x4&#x27;].value_counts())</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这两个数据有问题，在test中会因为数据不匹配导致NaN的出现因此这两个数据剔除</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x6_freq&#x27;</span>] = train_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x6&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x6_freq&#x27;</span>] = test_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x6&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x6_mean&#x27;</span>] = train_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x6&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x6_mean&#x27;</span>] = test_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x6&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x7_freq&#x27;</span>] = train_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x7&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x7_freq&#x27;</span>] = test_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x7&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x7_mean&#x27;</span>] = train_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x7&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x7_mean&#x27;</span>] = test_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x7&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x8_freq&#x27;</span>] = train_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x8&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x8_freq&#x27;</span>] = test_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x8&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x8_mean&#x27;</span>] = train_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x8&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x8_mean&#x27;</span>] = test_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x8&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#df.groupby(分组依据)[数据来源].使用操作</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train=train_data.drop([<span class="string">&#x27;udmap&#x27;</span>,<span class="string">&#x27;uuid&#x27;</span>,<span class="string">&#x27;target&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">test=test_data.drop([<span class="string">&#x27;udmap&#x27;</span>,<span class="string">&#x27;uuid&#x27;</span>,],axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#我们保留了common_ts这个数据，接下来对这个特征的归一化</span></span><br></pre></td></tr></table></figure><h4 id="数据归一化处理"><a class="markdownIt-Anchor" href="#数据归一化处理"></a> 数据归一化处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对数据进行归一化处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train.columns:</span><br><span class="line">    MAX=<span class="built_in">max</span>(train[i])</span><br><span class="line">    MIN=<span class="built_in">min</span>(train[i])<span class="comment">#用训练集的数据区归一化测试集的数据</span></span><br><span class="line">    LEN=MAX-MIN</span><br><span class="line">    train[i]=train[i].apply(<span class="keyword">lambda</span> x:(x-MIN)/LEN)</span><br><span class="line">    test[i]=test[i].apply(<span class="keyword">lambda</span> x:(x-MIN)/LEN)</span><br></pre></td></tr></table></figure><h3 id="特征组合"><a class="markdownIt-Anchor" href="#特征组合"></a> 特征组合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暴力Feature 行为</span></span><br><span class="line"><span class="comment"># 暴力Feature 时间</span></span><br><span class="line"><span class="comment"># 暴力Feature 用户属性</span></span><br><span class="line"><span class="comment">#这里暂时不考虑特征的随机组合</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴力Feature 行为</span></span><br><span class="line">f = [<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>, <span class="string">&#x27;key3&#x27;</span>, <span class="string">&#x27;key4&#x27;</span>, <span class="string">&#x27;key5&#x27;</span>, <span class="string">&#x27;key6&#x27;</span>, <span class="string">&#x27;key7&#x27;</span>, <span class="string">&#x27;key8&#x27;</span>, <span class="string">&#x27;key9&#x27;</span>,<span class="string">&#x27;udmap_isunknown&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line"><span class="comment">#加f后可以在字符串里面使用用花括号括起来的变量和表达式，如果字符串里面没有表达式，那么前面加不加f输出应该都一样。</span></span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line"><span class="comment"># 暴力Feature 时间</span></span><br><span class="line">f = [<span class="string">&#x27;common_ts_hour&#x27;</span>,<span class="string">&#x27;common_ts_day&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>-<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] - df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>*<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] * df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>/<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] / (df[f[j]]+<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 暴力Feature 用户属性</span></span><br><span class="line">f = [<span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;x2&#x27;</span>, <span class="string">&#x27;x3&#x27;</span>, <span class="string">&#x27;x4&#x27;</span>, <span class="string">&#x27;x5&#x27;</span>, <span class="string">&#x27;x6&#x27;</span>, <span class="string">&#x27;x7&#x27;</span>, <span class="string">&#x27;x8&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="数据降维"><a class="markdownIt-Anchor" href="#数据降维"></a> 数据降维</h3><ul><li>利用xgboost进行特征选择，最终选出70组特征</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#采用xgboost的特征筛选的功能</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">6</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">xgbc.fit(train, label)</span><br><span class="line">importances_xgb = xgbc.feature_importances_/np.<span class="built_in">sum</span>( xgbc.feature_importances_)</span><br><span class="line"><span class="comment"># print(importances)</span></span><br><span class="line">indices_xgb = np.argsort(importances_xgb)[::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># print(indices)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看结果</span></span><br><span class="line">feat_labels = train.columns</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(train.shape[<span class="number">1</span>]):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % \</span><br><span class="line">          (f + <span class="number">1</span>, <span class="number">30</span>, feat_labels[indices_xgb[f]], importances_xgb[indices_xgb[f]]))</span><br><span class="line"></span><br><span class="line">features=np.array(feat_labels)</span><br><span class="line">num_imo=features[<span class="built_in">list</span>(indices_xgb[<span class="number">0</span>:<span class="number">60</span>])]<span class="comment">#选择60个特征</span></span><br><span class="line"></span><br><span class="line">train=train[num_imo]</span><br><span class="line">test=test[num_imo]</span><br></pre></td></tr></table></figure><h3 id="交叉验证模型"><a class="markdownIt-Anchor" href="#交叉验证模型"></a> 交叉验证模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常见的交叉验证模型框架</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_train</span>(<span class="params">model, model_name, kfold=<span class="number">5</span></span>):</span><br><span class="line">    oof_preds = np.zeros((train.shape[<span class="number">0</span>]))<span class="comment">#构造一个series令所有行全部为0</span></span><br><span class="line">    test_preds = np.zeros(test.shape[<span class="number">0</span>])</span><br><span class="line">    skf = StratifiedKFold(n_splits=kfold)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Model = <span class="subst">&#123;model_name&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train.columns))</span><br><span class="line">    <span class="keyword">for</span> k, (train_index, test_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(skf.split(train, label)):</span><br><span class="line">        x_train, x_test = train.iloc[train_index, :], train.iloc[test_index, :]</span><br><span class="line">        y_train, y_test = label.iloc[train_index], label.iloc[test_index]</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">        model.fit(x_train,y_train)</span><br><span class="line">        <span class="comment">#print(2)</span></span><br><span class="line">        y_pred = model.predict_proba(x_test)[:,<span class="number">1</span>]</span><br><span class="line">        <span class="comment">##在这里第一列是预测为0的概率，第二列是预测为1的概率</span></span><br><span class="line">        oof_preds[test_index] = y_pred.ravel()</span><br><span class="line">        auc = roc_auc_score(y_test,y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;- KFold = %d, val_auc = %.4f&quot;</span> % (k, auc))</span><br><span class="line">        test_fold_preds = model.predict_proba(test)[:, <span class="number">1</span>]</span><br><span class="line">        test_preds += test_fold_preds.ravel()<span class="comment">#将给定Series对象的基础数据作为ndarray返回。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Overall Model = %s, F1 = %.4f&quot;</span> % (model_name, f1_score(label, oof_preds, average=<span class="string">&#x27;macro&#x27;</span>)))</span><br><span class="line">    <span class="keyword">return</span> test_preds / kfold<span class="comment">#取平均值</span></span><br></pre></td></tr></table></figure><h3 id="数据清洗通过10交叉验证判断数据是否存在问题"><a class="markdownIt-Anchor" href="#数据清洗通过10交叉验证判断数据是否存在问题"></a> 数据清洗，通过10交叉验证判断数据是否存在问题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">xgbc = XGBClassifier(</span></span><br><span class="line"><span class="string">    objective=&#x27;binary:logistic&#x27;,</span></span><br><span class="line"><span class="string">    eval_metric=&#x27;auc&#x27;,</span></span><br><span class="line"><span class="string">    n_estimators=100, </span></span><br><span class="line"><span class="string">    max_depth=6, </span></span><br><span class="line"><span class="string">    learning_rate=0.1</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">xgbc_test_preds = model_train(xgbc, &quot;XGBClassifier&quot;, 10)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这里用于挑选异常训练集</span></span><br><span class="line"><span class="comment">#看误差是否过大</span></span><br></pre></td></tr></table></figure><h3 id="验证集和训练集构建"><a class="markdownIt-Anchor" href="#验证集和训练集构建"></a> 验证集和训练集构建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将训练数据划分成训练集和验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split( train, label, stratify=label, random_state=<span class="number">2022</span>)</span><br><span class="line"><span class="comment">#75%的训练集</span></span><br></pre></td></tr></table></figure><h3 id="模型选择"><a class="markdownIt-Anchor" href="#模型选择"></a> 模型选择</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xgboost实验</span></span><br><span class="line"><span class="comment"># max_depth不能太小否则会出问题</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">50</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">xgbc.fit(x_train,y_train)</span><br><span class="line">y_pred = xgbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策树实验</span></span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line">DT.fit(x_train,y_train)</span><br><span class="line">y_pred = DT.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机森林实验</span></span><br><span class="line">RF=RandomForestClassifier(n_estimators=<span class="number">50</span>)</span><br><span class="line">RF.fit(x_train,y_train)</span><br><span class="line">y_pred = RF.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GDBT实验</span></span><br><span class="line"><span class="comment">#是不是树的深度太浅导致的</span></span><br><span class="line">gbc = GradientBoostingClassifier(</span><br><span class="line">    n_estimators=<span class="number">10</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">gbc.fit(x_train,y_train)</span><br><span class="line">y_pred = gbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#HGBC 实验</span></span><br><span class="line">hgbc = HistGradientBoostingClassifier(</span><br><span class="line">    max_iter=<span class="number">20</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">gbc.fit(x_train,y_train)</span><br><span class="line">y_pred = gbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #LGMB 实验</span></span><br><span class="line"><span class="comment"># gbm = LGBMClassifier(</span></span><br><span class="line"><span class="comment">#     objective=&#x27;binary&#x27;,</span></span><br><span class="line"><span class="comment">#     boosting_type=&#x27;gbdt,</span></span><br><span class="line"><span class="comment">#     num_leaves=2 ** 6, </span></span><br><span class="line"><span class="comment">#     max_depth=50,</span></span><br><span class="line"><span class="comment">#     colsample_bytree=0.8,</span></span><br><span class="line"><span class="comment">#     subsample_freq=1,</span></span><br><span class="line"><span class="comment">#     max_bin=255,</span></span><br><span class="line"><span class="comment">#     learning_rate=0.05, </span></span><br><span class="line"><span class="comment">#     n_estimators=4000, </span></span><br><span class="line"><span class="comment">#     metrics=&#x27;auc&#x27;</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"><span class="comment"># gbm.fit(x_train,y_train)</span></span><br><span class="line"><span class="comment"># y_pred = gbm.predict_proba(x_train)[:, 1]</span></span><br><span class="line"><span class="comment"># threshold=0.5</span></span><br><span class="line"><span class="comment"># y_pred = (y_pred &gt;= threshold).astype(int)</span></span><br><span class="line"><span class="comment"># f1 = f1_score(y_train, y_pred, average=&#x27;macro&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;F1 = %.8f&#x27; % f1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cbc = CatBoostClassifier(</span></span><br><span class="line"><span class="comment">#     iterations=20, </span></span><br><span class="line"><span class="comment">#     depth=16, </span></span><br><span class="line"><span class="comment">#     learning_rate=0.03, </span></span><br><span class="line"><span class="comment">#     l2_leaf_reg=1, </span></span><br><span class="line"><span class="comment">#     loss_function=&#x27;Logloss&#x27;, </span></span><br><span class="line"><span class="comment">#     verbose=0</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"><span class="comment"># cbc.fit(x_train,y_train)</span></span><br><span class="line"><span class="comment"># y_pred = cbc.predict_proba(x_train)[:, 1]</span></span><br><span class="line"><span class="comment"># threshold=0.5</span></span><br><span class="line"><span class="comment"># y_pred = (y_pred &gt;= threshold).astype(int)</span></span><br><span class="line"><span class="comment"># f1 = f1_score(y_train, y_pred, average=&#x27;macro&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;F1 = %.8f&#x27; % f1)</span></span><br><span class="line"></span><br><span class="line">ada=AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">50</span>),</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">    learning_rate=<span class="number">0.01</span></span><br><span class="line">    )<span class="comment">#默认是CART决策树作为单模型</span></span><br><span class="line">ada.fit(x_train,y_train)</span><br><span class="line">y_pred = ada.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br></pre></td></tr></table></figure><h3 id="模型融合"><a class="markdownIt-Anchor" href="#模型融合"></a> 模型融合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最终决定：决策树，xgboost， RF，GBDT，HGBC,adaboost这几个模型stack</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">50</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line">RF=RandomForestClassifier(n_estimators=<span class="number">50</span>)</span><br><span class="line">gbc = GradientBoostingClassifier(</span><br><span class="line">    n_estimators=<span class="number">10</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">hgbc = HistGradientBoostingClassifier(</span><br><span class="line">    max_iter=<span class="number">20</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">ada=AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">50</span>),</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">    learning_rate=<span class="number">0.01</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;xgbc&#x27;</span>, xgbc),</span><br><span class="line">    (<span class="string">&#x27;DT&#x27;</span>,DT),</span><br><span class="line">    (<span class="string">&#x27;RF&#x27;</span>,RF),</span><br><span class="line">    (<span class="string">&#x27;gbc&#x27;</span>, gbc),</span><br><span class="line">    (<span class="string">&#x27;hgbc&#x27;</span>, hgbc),</span><br><span class="line">    (<span class="string">&#x27;ada&#x27;</span>, ada),</span><br><span class="line">]</span><br><span class="line">clf = StackingClassifier(</span><br><span class="line">    estimators=estimators, </span><br><span class="line">    final_estimator=LogisticRegression()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用组合模型训练</span></span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line">y_pred = clf.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br></pre></td></tr></table></figure><h3 id="结果提交"><a class="markdownIt-Anchor" href="#结果提交"></a> 结果提交</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #这里的分类器我不单单想用上面的，我打算重新训练所有数据集来进行预测</span></span><br><span class="line"><span class="comment"># clf_test_preds = model_train(clf, &quot;StackingClassifier&quot;)</span></span><br><span class="line"><span class="comment"># #还是用全部的数据进行训练 </span></span><br><span class="line"><span class="comment"># clf.fit(train,label)</span></span><br><span class="line"></span><br><span class="line">result_df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;uuid&#x27;</span>: test_data[<span class="string">&#x27;uuid&#x27;</span>],  <span class="comment"># 使用测试数据集中的 &#x27;uuid&#x27; 列作为 &#x27;uuid&#x27; 列的值</span></span><br><span class="line">    <span class="string">&#x27;target&#x27;</span>: clf.predict(test)  <span class="comment"># 使用模型 clf 对测试数据集进行预测，并将预测结果存储在 &#x27;target&#x27; 列中</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">result_df.to_csv(<span class="string">&#x27;submit.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 竞赛 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_data&amp;detach</title>
      <link href="/2023/08/24/pytorch-data-detach/"/>
      <url>/2023/08/24/pytorch-data-detach/</url>
      
        <content type="html"><![CDATA[<p>这是关于pytorch中的.data操和detach()操作的区分和介绍</p><p>这两个方法都可以用来从原有的计算图中分离出某一个tensor，有相似的地方，也有不同的地方，下面来比较性的看一看</p><p>原文链接：<a href="https://blog.csdn.net/qq_27825451/article/details/96837905">https://blog.csdn.net/qq_27825451/article/details/96837905</a></p><span id="more"></span><h1 id="data"><a class="markdownIt-Anchor" href="#data"></a> data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> </span><br><span class="line">a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.</span>], requires_grad = <span class="literal">True</span>)</span><br><span class="line">out = a.sigmoid()</span><br><span class="line">c = out.data  <span class="comment"># 需要走注意的是，通过.data “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化</span></span><br><span class="line">c.zero_()     <span class="comment"># 改变c的值，原来的out也会改变</span></span><br><span class="line"><span class="built_in">print</span>(c.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(out.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------------------------------------------&quot;</span>)</span><br><span class="line"> </span><br><span class="line">out.<span class="built_in">sum</span>().backward() <span class="comment"># 对原来的out求导，</span></span><br><span class="line"><span class="built_in">print</span>(a.grad)  <span class="comment"># 不会报错，但是结果却并不正确</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;运行结果为：</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.])</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.], grad_fn=&lt;SigmoidBackward&gt;)</span></span><br><span class="line"><span class="string">----------------------------------------------</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>（1）tensor .data 返回和 x 的相同数据 tensor,而且这个新的tensor和原来的tensor是共用数据的，一者改变，另一者也会跟着改变，而且新分离得到的tensor的require s_grad = False, 即不可求导的。（这一点其实detach是一样的）</p><p>（2）使用tensor.data的局限性。文档中说使用tensor.data是不安全的, 因为 <mark><strong>x.data 不能被 autograd 追踪求微分</strong></mark> 。什么意思呢？从上面的例子可以看出，**由于我更改分离之后的变量值c,导致原来的张量out的值也跟着改变了，但是这种改变对于autograd是没有察觉的，它依然按照求导规则来求导，导致得出完全错误的导数值却浑然不知。**它的风险性就是如果我再任意一个地方更改了某一个张量，求导的时候也没有通知我已经在某处更改了，导致得出的导数值完全不正确，故而风险大。</p><p>(也就是说.data修改数据后不会被检测到，但是原始操作已经修改)</p><h1 id="detach"><a class="markdownIt-Anchor" href="#detach"></a> detach()</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> </span><br><span class="line">a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.</span>], requires_grad = <span class="literal">True</span>)</span><br><span class="line">out = a.sigmoid()</span><br><span class="line">c = out.detach()  <span class="comment"># 需要走注意的是，通过.detach() “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化</span></span><br><span class="line">c.zero_()     <span class="comment"># 改变c的值，原来的out也会改变</span></span><br><span class="line"><span class="built_in">print</span>(c.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(out.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------------------------------------------&quot;</span>)</span><br><span class="line"> </span><br><span class="line">out.<span class="built_in">sum</span>().backward() <span class="comment"># 对原来的out求导，</span></span><br><span class="line"><span class="built_in">print</span>(a.grad)  <span class="comment"># 此时会报错，错误结果参考下面,显示梯度计算所需要的张量已经被“原位操作inplace”所更改了。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.])</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.], grad_fn=&lt;SigmoidBackward&gt;)</span></span><br><span class="line"><span class="string">----------------------------------------------</span></span><br><span class="line"><span class="string">RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>tensor.detach()的两点总结：</p><p>（1）tensor .detach() 返回和 x 的相同数据 tensor,而且这个新的tensor和原来的tensor是共用数据的，一者改变，另一者也会跟着改变，而且新分离得到的tensor的require s_grad = False, 即不可求导的。（这一点其实 .data是一样的）（也是在原数据集上操作）</p><p>（2）使用tensor.detach()的优点。从上面的例子可以看出，由于我更改分离之后的变量值c,导致原来的张量out的值也跟着改变了，这个时候如果依然按照求导规则来求导，由于out已经更改了，所以不会再继续求导了，而是报错，这样就避免了得出完全牛头不对马嘴的求导结果。</p><h1 id="区别总结"><a class="markdownIt-Anchor" href="#区别总结"></a> 区别总结</h1><p>相同点：tensor.data和tensor.detach() 都是变量从图中分离，但而这都是“原位操作 inplace operation”。</p><p>不同点：</p><p>（1）.data 是一个属性，二.detach()是一个方法；</p><p>（2）.data 是不安全的，.detach()是安全的。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAT和GCN中的注意事项</title>
      <link href="/2023/08/24/GAT%E5%92%8CGCN%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
      <url>/2023/08/24/GAT%E5%92%8CGCN%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="inductive-learning-and-transductive-learning"><a class="markdownIt-Anchor" href="#inductive-learning-and-transductive-learning"></a> “Inductive learning” and “Transductive learning”</h1><p>“Inductive learning”意为归纳学习，“Transductive learning”意为直推学习</p><p>对于GCN而言我们认为其是：直推学习，也就是说当测试集出现了训练集未学习过的节点时即图结构发生了变化时，网络需要重新训练。</p><p>对于GAT而言：归纳学习；也就是训练阶段见不到的数据（在图书剧中可以指新的节点，也可以指新的图）                                                                                                                                        直接进行预测而不需要重新训练。</p><span id="more"></span><p>GCN就像是没有权重的GAT一样，见如下公式：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mi>C</mi><mi>N</mi><mo>=</mo><mover accent="true"><mi>A</mi><mo>~</mo></mover><mi>X</mi><mi>W</mi><mspace linebreak="newline"></mspace><mi>G</mi><mi>A</mi><mi>T</mi><mo>=</mo><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo>~</mo></mover><mo>⊙</mo><mi>M</mi><mo stretchy="false">)</mo><mi>X</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">GCN=\tilde{A}XW \\GAT=(\tilde A \odot M)XW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9201899999999998em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1701899999999998em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span></span></p><p>这里的需不需要重新训练围殴认为是其关注的重点，对于GCN而言重点关注的<strong>图的全局结构</strong>，因此当图的结果变换的时候自然需要重新训练。</p><p>而对于GAT而言虽说用到了邻接矩阵，但训练的目标是<mark>中心节点</mark>和<mark>邻居节点</mark>间的聚合操作。</p><p>某种意义上来说，GCN是一种考虑了整体图结构的方法；而GAT一定程度上放弃了整体结构，这使得其能够完成Inductive任务。<br>链接：<a href="https://www.zhihu.com/question/409415383/answer/1361505060">https://www.zhihu.com/question/409415383/answer/1361505060</a></p><p>其实是否确保inductive，本质上在于两点：首先是你要确保你这个算法的node-level input不能是one hot而必须是实在的node attribute，一旦onehot了就必是只能transductive，原因显然。其次是training方式，不能是依赖于整图的矩阵运算，而必须是graphsage里面appendix a的minibatch training模式下的分割方案，而这才是graphsage有底气说自己inductive牛逼的主要原因。你确保这两点，几乎现在市面上所有message passing架构的gnn都是inductive的。<br>链接：<a href="https://www.zhihu.com/question/409415383/answer/1361596817">https://www.zhihu.com/question/409415383/answer/1361596817</a></p><p>这个地方还可以参考论文：<a href="https://www.researchgate.net/publication/352513259_A_Subgraph-based_Knowledge_Reasoning_Method_for_Collective_Fraud_Detection_in_E-commerce">https://www.researchgate.net/publication/352513259_A_Subgraph-based_Knowledge_Reasoning_Method_for_Collective_Fraud_Detection_in_E-commerce</a></p><p>里面提到了了一个<strong>全局和局部</strong>的观念</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>First-Hello World</title>
      <link href="/2023/06/24/hello-world/"/>
      <url>/2023/06/24/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><span id="more"></span><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><h3 id="github同步"><a class="markdownIt-Anchor" href="#github同步"></a> GitHub同步</h3><p>hexo clean</p><p>hexo d -g</p><p>会有一点延迟，更新得等一会</p><h3 id="显示部分内容"><a class="markdownIt-Anchor" href="#显示部分内容"></a> 显示部分内容</h3><p>在你写 md 文章的时候，可以在内容中加上 <code>&lt;!--more--&gt;</code>，这样首页和列表页展示的文章内容就是 <code>&lt;!--more--&gt;</code> 之前的文字，而之后的就不会显示了。</p>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
