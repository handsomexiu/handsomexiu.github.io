<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GAT</title>
      <link href="/2023/09/07/GAT/"/>
      <url>/2023/09/07/GAT/</url>
      
        <content type="html"><![CDATA[<p>这是关于GAT的一些介绍，注意力机制在图神经网络中的应用；inductive learning；局部信息的聚合</p><span id="more"></span><p><mark>相较于GCN，GAT更加的注重局部环境</mark></p><h1 id="图注意力层"><a class="markdownIt-Anchor" href="#图注意力层"></a> 图注意力层</h1><p>注意力机制的三要素：query,source,attention value。可以设置如下</p><ul><li>Query :设置成当前中心节点的特征向量</li><li>Source设置为所有邻居的特征向量</li><li>attention value：设置为中心节点经过聚合操作后的新的特征向量<br>设图中任意节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在第l层所对应的特征向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup></msup></mrow><annotation encoding="application/x-tex">h_{i}\in R^{d^{(l)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">d^{(l)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>表示节点特征的长度；经过一个以注意力机制为核心的聚合操作之后，输出的是每个节点的新特征向量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>∈</mo><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></msup></mrow><annotation encoding="application/x-tex">h_{i}&#x27;\in R^{d^{(l+1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.010556em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">d^{(l+1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>表示输出的特征向量的长度。这个聚合操作叫做：图注意力层（GAL）！</li></ul><p><img src="GAT%5CPasted%20image%2020230907155121.png" alt><br>假设中心节点为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，我们假设邻居节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">v_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的权重系数为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><mi>W</mi><msub><mi>h</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij}=a(Wh_i,W_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi>R</mi><mrow><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>×</mo><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">W\in R^{d^{(l+1)}\times d^{(l)})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>是该层节点特征变换的权重参数。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>是相关度计算，只要满足<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></msup><mo>×</mo><msup><mi>R</mi><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup></msup><mo>→</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">R^{d^{(l+1)}}\times R^{d^{(l)}} \rightarrow R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1230299999999998em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span></p><p>论文采用一个单层全连接层来处理：其中权重参数：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∈</mo><msup><mi>R</mi><mrow><mn>2</mn><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow></msup></mrow><annotation encoding="application/x-tex">a\in R^{2d^{(l+1)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0396999999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0396999999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667142857142857em;"><span style="top:-2.966714285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>Leaky ReLU</mtext><mo stretchy="false">(</mo><msup><mi>a</mi><mi>T</mi></msup><mo stretchy="false">[</mo><mi>W</mi><msub><mi>h</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>W</mi><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij}=\text{Leaky ReLU}(a^T[Wh_i||Wh_j])</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.177439em;vertical-align:-0.286108em;"></span><span class="mord text"><span class="mord">Leaky ReLU</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mclose">)</span></span></span></span></span></p><p>其实我认为这里有点问题，从计算（代码）来看更因该像这样<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>Leaky ReLU</mtext><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>W</mi><msub><mi>h</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>W</mi><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">]</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij}=\text{Leaky ReLU}([Wh_i||Wh_j]a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord text"><span class="mord">Leaky ReLU</span></span><span class="mopen">(</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>，中间是拼接操作。代码采用采用了一种很神奇的方式：没有使用拼接技术将两个矩阵拼接起来，而是采用了——广播机制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_prepare_attentional_mechanism_input</span>(<span class="params">self, Wh</span>):</span><br><span class="line">    <span class="comment"># Wh.shape (N, out_feature)</span></span><br><span class="line">    <span class="comment"># self.a.shape (2 * out_feature, 1)</span></span><br><span class="line">    <span class="comment"># Wh1&amp;2.shape (N, 1)</span></span><br><span class="line">    <span class="comment"># e.shape (N, N)#这样就构成了一个相似度矩阵</span></span><br><span class="line">    Wh1 = torch.matmul(Wh, self.a[:self.out_features, :])</span><br><span class="line">    Wh2 = torch.matmul(Wh, self.a[self.out_features:, :])</span><br><span class="line">    <span class="comment"># broadcast add</span></span><br><span class="line">    e = Wh1 + Wh2.T<span class="comment"># N×1+1×N</span></span><br><span class="line">    <span class="comment">#通过广播机制得到一个相似度矩阵</span></span><br><span class="line">    <span class="comment">#这里和拼接和在和a相乘在进行扩展的原理是一样的，只不过这里利用广播机制来进行计算。</span></span><br><span class="line">    <span class="comment"># 而且这里的计算量更小由4O^2变成了2O^2</span></span><br><span class="line">    <span class="keyword">return</span> self.leakyrelu(e)</span><br></pre></td></tr></table></figure><p>采用了广播机制减少了计算量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><msup><mi>O</mi><mn>2</mn></msup><mo>→</mo><mn>2</mn><msup><mi>O</mi><mn>2</mn></msup><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">(</mo><mtext>out_features</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">4O^2\rightarrow 2O^2,O(\text{out\_features})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1241079999999999em;vertical-align:-0.31em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord text"><span class="mord">out_features</span></span><span class="mclose">)</span></span></span></span></p><p>最后的权重系数：对e进行归一化处理：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mover accent="true"><mi>N</mi><mo>~</mo></mover><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_{ij}=softmax_j(e_{ij})=\frac{\exp(e_{ij})}{\sum\limits_{v_{k}\in \tilde{N}(v_{i})}\exp(e_{ik})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.448138em;vertical-align:-2.021138em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7500050000000001em;"><span style="top:-1.9398620000000002em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.3023300000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0000050000000003em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop op-symbol small-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.335138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.021138em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>这样就保证了所有邻居的权重系数的和为1.完成权重系数的计算对节点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>进行更新：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mover accent="true"><mi>N</mi><mo>~</mo></mover><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></munder><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>W</mi><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_i&#x27;=\sigma(\sum\limits_{v_{k}\in \tilde{N}(v_{i})}\alpha_{ij}Wh_{j})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.048892em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8018919999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.685143em;vertical-align:-1.635138em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.689862em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.3023300000000004em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.635138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>当然也可以采用多头注意力机制：<br><img src="GAT%5CPasted%20image%2020230907164456.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGAE</title>
      <link href="/2023/09/07/VGAE/"/>
      <url>/2023/09/07/VGAE/</url>
      
        <content type="html"><![CDATA[<p>本篇文章是关于VGAE的介绍，VGAE是变分自编码器再图神经网络上的应用</p><span id="more"></span><ul><li>图变分自编码器</li><li>就是将变分自编码器用到了图上</li><li>是一种无监督学习</li><li>目的是重构误差最小</li><li>损失函数的设计和VAE的一致，考虑的是极大似然估计</li></ul><p>论文考虑的是无向无权重图，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">G</mi><mo>=</mo><mrow><mi mathvariant="script">V</mi><mo separator="true">,</mo><mi mathvariant="script">E</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{G}={\mathcal{V},\mathcal{E}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78055em;vertical-align:-0.09722em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.0593em;">G</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08944em;">E</span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">N=\mathcal{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.08222em;">V</span></span></span></span></span>表示节点数量。这里的邻接矩阵A有点不一样的是，这里考虑到了自连接也就是A的对角线不为1，为0。（<code>这里为什么要考虑自连接了</code>）</p><p>对于VAE中采用的是神经网络来拟合隐变量的方差和均值——这里隐变量的数量和样本（节点）数量是一致的。<br>对于VGAE而言论文利用了两层图卷积网络来拟合均值和方差。</p><p>推断模型</p><ul><li><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>q</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext>    </mtext><mi>q</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>μ</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">(</mo><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(Z|X,A)=\prod_{i=1}^{N}q(z_i|X,A),with\ \ \ \ q(z_i|X,A)=\mathcal{N}(z_i|\mu_i,diag(\sigma_i^2))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p></li></ul><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>G</mi><mi>C</mi><msub><mi>N</mi><mi>μ</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mu=GCN_{\mu}(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>表示均值向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span></span></span></span>的矩阵。同理论文对方差的拟合用的是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>σ</mi><mo>=</mo><mi>G</mi><mi>C</mi><msub><mi>N</mi><mi>σ</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log \sigma=GCN_{\sigma}(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>C</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">GCN(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>的公式如下：</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>C</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>R</mi><mi>E</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>X</mi><msub><mi>W</mi><mn>0</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">GCN(X,A)=\hat ARELU(\hat AXW_0)W_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.19677em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中对于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo>^</mo></mover><mo>=</mo><msup><mi>D</mi><mrow><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mi>A</mi><msup><mi>D</mi><mrow><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">\hat A=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9540200000000001em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span>对称归一化邻接矩阵。</p><p>生成模型：是由潜在变量的内积给出来的</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>z</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext>   </mtext><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>z</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(A|Z)=\prod_{i=1}^N\prod_{j=1}^{N}P(A_{ij}|z_i,z_j),with \ \ \ P(A_{ij}|z_i,z_j)=\sigma(z_i^Tz_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.2421130000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.177439em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>学习目标</p><ul><li><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>Z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>−</mo><mi>K</mi><mi>L</mi><mo stretchy="false">[</mo><mi>q</mi><mo stretchy="false">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}=\mathbb{E}_{q(Z|X,A)}[\log p(A|Z)]-KL[q(Z|X,A)||p(Z)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">Z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">A</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord">∣</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p></li><li><p>Non-probabilistic graph auto-encoder (GAE) model(这里因该是一般的GAE的形式)</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo>^</mo></mover><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>Z</mi><msup><mi>Z</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mtext>   </mtext><mi>Z</mi><mo>=</mo><mi>G</mi><mi>C</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat A=\sigma(ZZ^{T}),with\ \ \ Z=GCN(X,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9467699999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span></li></ul></li></ul><p><a href="https://zhuanlan.zhihu.com/p/64485020"> 一文理解变分自编码器（VAE）</a></p><p><a href="https://zhuanlan.zhihu.com/p/78340397">VGAE（Variational graph auto-encoders）论文详解</a></p><p><a href="https://zhuanlan.zhihu.com/p/91900950">深度学习中常见的互信息的变分上下界(详细推导)</a></p><p><a href="https://blog.csdn.net/lj2048/article/details/105846421">【GNN五大类 VGAE】（变分图自编码器）：Variational Graph Auto-Encoders</a><br><a href="https://blog.csdn.net/oldmao_2001/article/details/118729806">第六周.02.VGAE带读+代码实操</a></p><p><a href="https://blog.csdn.net/oldmao_2001/article/details/120468742">CS224W摘要09.Theory of Graph Neural Networks</a></p><p><a href="https://zhuanlan.zhihu.com/p/348498294">机器学习方法—优雅的模型（一）：变分自编码器（VAE）</a></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>插入图片</title>
      <link href="/2023/09/03/%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/"/>
      <url>/2023/09/03/%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/</url>
      
        <content type="html"><![CDATA[<p>插入图片的方法：<a href="https://zhuanlan.zhihu.com/p/542101567">https://zhuanlan.zhihu.com/p/542101567</a></p><p>注意：使用：</p><span id="more"></span><p><img src="image-20230902165946533.png" alt></p><p>而不是</p><p><img src="%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%5Cimage-20230902165946533.png" alt>（此时这里的图片不会显示)</p><p>也就是说路径要用 /这个，要是路径用了\会导致结果不会显示</p><p>而且图片要插入到笔记同名的且文件夹中（会自动创建）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">用：![](插入图片/image-20230902165946533.png)，/</span><br><span class="line">不用：![](插入图片\image-20230902165946533.png)，\</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>QCNext:何为下一代？</title>
      <link href="/2023/09/02/QCNext-%E4%BD%95%E4%B8%BA%E4%B8%8B%E4%B8%80%E4%BB%A3%EF%BC%9F/"/>
      <url>/2023/09/02/QCNext-%E4%BD%95%E4%B8%BA%E4%B8%8B%E4%B8%80%E4%BB%A3%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<p>QCNxet的论文《QCNeXt: A Next-Generation Framework For Joint Multi-Agent Trajectory Prediction》。文章主要是对“下一代”进行讨论.</p><span id="more"></span><h1 id="下一代"><a class="markdownIt-Anchor" href="#下一代"></a> “下一代”</h1><p>论文中所提到的“下一代”是指 QCNet 的下一代。（其实就是在QCNet上的解释）</p><p>论文中提到了两个词语：“marginal distribution”和“joint distribution”，我们结合轨迹预测这个问题域进行解释：我们首先假设有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>个智能体，未来的时间步为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>。</p><ul><li><p>“marginal distribution”——边缘分布：模型在进行多只能预测的通过解码器直接输出需要预测的N个之智能体体的轨迹，并没有考虑智能体在未来时间步内的交互。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>每个智能体都独立的服从一个分布（边缘分布）</mtext><mspace linebreak="newline"></mspace><msub><mi>X</mi><mn>1</mn></msub><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>N</mi></msub><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mtext>对于轨迹的预测就分别从这</mtext><mi>N</mi><mtext>个分布中对轨迹进行采样</mtext><mi>T</mi><mtext>条轨迹。</mtext><mspace linebreak="newline"></mspace><mtext>每条轨迹都是独立的没有联系</mtext></mrow><annotation encoding="application/x-tex">\text{每个智能体都独立的服从一个分布（边缘分布）}\\X_1\sim P(X_1),X_2\sim P(X_2),\dots,X_N\sim P(X_N)\\对于轨迹的预测就分别从这N个分布中对轨迹进行采样T条轨迹。\\每条轨迹都是独立的没有联系</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">每个智能体都独立的服从一个分布（边缘分布）</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">于</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">预</span><span class="mord cjk_fallback">测</span><span class="mord cjk_fallback">就</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">别</span><span class="mord cjk_fallback">从</span><span class="mord cjk_fallback">这</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">布</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">进</span><span class="mord cjk_fallback">行</span><span class="mord cjk_fallback">采</span><span class="mord cjk_fallback">样</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord cjk_fallback">条</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">。</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">条</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">都</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">独</span><span class="mord cjk_fallback">立</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">没</span><span class="mord cjk_fallback">有</span><span class="mord cjk_fallback">联</span><span class="mord cjk_fallback">系</span></span></span></span></span></p></li><li><p>“joint distribution”——联合分布：模型显示的考虑了智能体未来的交互，因此是联合分布。相较于边缘分布的相互独立的提取轨迹。这里更像是一个场景一个场景的进行预测：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>显示的考虑智能体之间的交互，智能体未来轨迹的分布是一个联合分布</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mtext>对于轨迹的预测就统一的抽取</mtext><mi>T</mi><mtext>次样本，每次都涉及到</mtext><mi>N</mi><mtext>个智能体之间轨迹点。</mtext><mspace linebreak="newline"></mspace><mtext>这里更像是一个一个场景的提取</mtext></mrow><annotation encoding="application/x-tex">显示的考虑智能体之间的交互，智能体未来轨迹的分布是一个联合分布\\(X_1,X_2,\dots,X_N)\sim P(X_1,X_2,\dots,X_N)\\对于轨迹的预测就统一的抽取T次样本，每次都涉及到N个智能体之间轨迹点。\\这里更像是一个一个场景的提取</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">显</span><span class="mord cjk_fallback">示</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">考</span><span class="mord cjk_fallback">虑</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">之</span><span class="mord cjk_fallback">间</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">交</span><span class="mord cjk_fallback">互</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">未</span><span class="mord cjk_fallback">来</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">布</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">联</span><span class="mord cjk_fallback">合</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">布</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">于</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">预</span><span class="mord cjk_fallback">测</span><span class="mord cjk_fallback">就</span><span class="mord cjk_fallback">统</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">抽</span><span class="mord cjk_fallback">取</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord cjk_fallback">次</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">次</span><span class="mord cjk_fallback">都</span><span class="mord cjk_fallback">涉</span><span class="mord cjk_fallback">及</span><span class="mord cjk_fallback">到</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">之</span><span class="mord cjk_fallback">间</span><span class="mord cjk_fallback">轨</span><span class="mord cjk_fallback">迹</span><span class="mord cjk_fallback">点</span><span class="mord cjk_fallback">。</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord cjk_fallback">这</span><span class="mord cjk_fallback">里</span><span class="mord cjk_fallback">更</span><span class="mord cjk_fallback">像</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">场</span><span class="mord cjk_fallback">景</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">提</span><span class="mord cjk_fallback">取</span></span></span></span></span></p></li></ul><p>下图是QCNxet的解码器</p><p><img src="image-20230902190544810.png" alt></p><p>下面是QCNet：</p><p><img src="image-20230903153240693.png" alt="image-20230903153240693"></p><p>通过对比QCNext最大的改进是增加了一个增加了一个在未来时间上的交互，这种直观上的感觉是正确的，既然我们在进行编码的时候就显示的考虑智能体之间的交互，那么我们在对未来预测的时候也因该考虑智能体之间的交互。</p><h1 id="关于下一代的讨论"><a class="markdownIt-Anchor" href="#关于下一代的讨论"></a> 关于“下一代的讨论”</h1><p>我们更宽泛的对“下一代”进行讨论，从轨迹预测模型的历史来看这一代代的模型是如何发展的。</p><p>从过去到如今轨迹预测模型经历了三个阶段：基于物理的方法，基于maneuver的方法，基于交互感知的方法。</p><h2 id="基于物理的方法"><a class="markdownIt-Anchor" href="#基于物理的方法"></a> 基于物理的方法</h2><p><strong>基于物理的方法</strong>根据车辆的运动学和动力学特征预测车辆的未来轨迹。这些方法忽略了其他车辆和基础设施对目标车辆运动的影响，因此它们经常在超过一秒的预测范围内失败。</p><ul><li><p>如过去的一些跟车模型IDM模型，GIPPS模型等，这些模型一般是基于统计物理的方法得到的。能够处理一些简单的场景；IDM模型（预测未来的速度）展示如下，模型只考虑了前车和自车的一些驾驶方法：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>v</mi><mo>˙</mo></mover><mo>=</mo><mi>a</mi><mo stretchy="false">[</mo><mn>1</mn><mo>−</mo><mo stretchy="false">(</mo><mfrac><mi>v</mi><msub><mi>v</mi><mn>0</mn></msub></mfrac><msup><mo stretchy="false">)</mo><mi>δ</mi></msup><mo>−</mo><mo stretchy="false">(</mo><mfrac><mrow><msup><mi>s</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><mi mathvariant="normal">Δ</mi><mi>v</mi><mo stretchy="false">)</mo></mrow><mi>s</mi></mfrac><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo><mspace linebreak="newline"></mspace><msup><mi>s</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><mi mathvariant="normal">Δ</mi><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>s</mi><mn>0</mn></msub><mo>+</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>v</mi><mi>T</mi><mo>+</mo><mfrac><mrow><mi>v</mi><mi mathvariant="normal">Δ</mi><mi>v</mi></mrow><mrow><mn>2</mn><msqrt><mrow><mi>a</mi><mi>b</mi></mrow></msqrt></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\dot{v} =a [1-(\frac{v}{v_0} )^\delta -(\frac{s^* (v ,\Delta v)}{s} )^2] \\s^*(v, \Delta v) = s_0 + max(0,vT+\frac{v \Delta v}{2\sqrt{ab}}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66786em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11111000000000001em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mopen">[</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.9435600000000002em;vertical-align:-0.8360000000000001em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.29033em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.17778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.93222em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">a</span><span class="mord mathnormal">b</span></span></span><span style="top:-2.89222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.10777999999999999em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p></li><li><p>而且早期的这类模型其实并不是服务于自动驾驶，而是服务于</p></li><li><p>这类模型深处的时代也是以传统的数学，物理，统计学为基础的时代。</p></li><li><p>在该时代也出现了一种新的任务即：模型参数标定，不像深度学习，这类模型的一些参数是有实际意义的，可以结合数据的标定结果去分析数据的一些特性。</p></li></ul><h2 id="基于机动的方法这一块了解不多"><a class="markdownIt-Anchor" href="#基于机动的方法这一块了解不多"></a> 基于机动的方法（这一块了解不多）</h2><p>基于机动的方法根据一组机动原型（maneuver prototype）预测目标车辆的未来运动。这些将道路的结构考虑在内进行长期预测，但仍然忽略了车辆间的交互作用。</p><ul><li><p>加入道路等因素的考虑，相当于开始将车辆放在了真实的场景中进行分析</p></li><li><p>此时采用的方法也不局限于传统的物理的方法，开始采用统计机器学习的一些方法如在论文[4]中就采用了贝叶斯网络如下图所示：</p><p><img src="image-20230903161928954.png" alt="image-20230903161928954"></p></li><li><p>通过引入道路等越苏可以避免一些不切实际的行为出现。</p></li></ul><h2 id="基于交互感知的方法主要是看了这个"><a class="markdownIt-Anchor" href="#基于交互感知的方法主要是看了这个"></a> 基于交互感知的方法（主要是看了这个）</h2><p>基于交互感知的方法，将驾驶作为一种交互活动，吸引了越来越多的兴趣，与那些非交互感知方法相比表现出更好的性能。</p><p>得益于深度学习强大的自动表征能力，此时的方法更加以深度学习的方法为主。我阅读的第一篇关于交互感知的论文是：Social lstm：这是一篇用于行人轨迹预测的方法，采用了social pooling来提取agent与agent之间的交互：</p><p><img src="image-20230903163238615.png" alt="image-20230903163238615"></p><p>随着图神经网络的发展，图神经网络在构建空间交互，非欧结构数据方面有着独有的优势。其中VectorNet就采用了图神经网络来结合车辆和场景的信息，建模交互：</p><p><img src="image-20230903163831523.png" alt></p><p>也有用transformer进行编码的：如mmtransformer：</p><p><img src="image-20230907222418790.png" alt></p><p>现在的比较热门的方法基本都属于交互感知的方法：如TNT，Dense TNT，HOME，QCNet等方法。基本的框架是：</p><ul><li>编码器：编码场景上下文信息和车辆的轨迹信息</li><li>解码器：结合编码器的输出：输出agent未来的轨迹（每个时间步的坐标点）</li></ul><p>在交互感知的方法中也出现了一些的分支，我们就输出结果的方式进行探讨：</p><p>就输出结果而言：分为单模态输出，多模态输出；单智能体输出，多智能体输出；并行输出，循环输出</p><ul><li><p>单模态输出是模型只输出一条轨迹，该方法存在一定的缺陷，在论文[3]中通过实验发现该输出结果会是多模态输出的一种平均形式，会造成与实际不符合的情况</p><p><img src="image-20230903164343922.png" alt="image-20230903164343922"></p></li><li><p>多模态输出是一种比较火也是比较复合实际的输出方式，这样的输出模拟的人的不确定性驾驶行为，模仿人类的驾驶意图，且效果更好。(如上图的子图a,c)</p></li><li><p>单智能体输出是指模型只输出一个智能体的结果，并且该模型可以在所有智能体上使用，这样可以节省计算成本，降低耗时；也可以看成是每辆车在未来没有交互，和被当成是边缘分布一样。</p></li><li><p>多智能体输出</p><ul><li><p>边缘分布的方法：每个智能体类似于单独输出的，关于未来不存在交互</p></li><li><p>联合分布的方法：每个智能体在未来是有交互的，不独立。这样可以一定程度上保证一点的安全性，避免不安全的轨迹出现（这种联合分布预测的发展也是一种趋势）</p><ul><li><p>除了本文所采用的方法之外（隐式的对安全性进行建模，因为联合分布中包括后面的评分，对轨迹冲突的分数会很低甚至不会出现对应的情况）；</p></li><li><p>另一种可以参考UniAD这篇论文，利用了未来估计的occupancy网格来使得驾驶更加安全。</p><p><img src="image-20230903164708621.png" alt="image-20230903164708621"></p></li></ul></li></ul></li></ul><ul><li>并行输出是指像MLP或TNT这样（MLP可能隐含学习了未来时间步之间的一种表示；对于TNT这种可能在对anchor修正的时候也潜在的学习了未来时间步之间的联系）这样直接输出几个时间步内的结果，这存在一个潜在的假设（在给定anchor的情况下（TNT，multipath））未来的时间步是独立的；这样的计算效率更高</li><li>循环输出类似于social-LSTM这样，一个一个时间步的输出，这样的效率比较低，之间学习了未来时间步之间的联系。</li></ul><p>除了对输出结果的讨论，还有对任务的讨论：单任务学习，多任务联合学习</p><ul><li>单任务学习是指模型只服务于一个任务，对本篇文章而言就是轨迹预测，像QCNext，QCNet，TNT，HOME等都是属于单任务的；</li><li>多任务学习是指多个任务共同组成一条end-to-end的pipeline，多个任务的联合学习可以对每个任务都有一定的提升效果。而且也更符合自动驾驶算法的整体运行流程<ul><li>早期的有IntentNet，将目标检测与轨迹预测结合起来学习。</li><li>现在随着大模型的发展，基于transformer的的自动驾驶大模型也被提出：UniAD；该算法统一了自动驾驶的感知，跟踪，预测和规划模块。</li></ul></li></ul><p>我认为未来的一个大趋势就是统一的端到端的大模型应用到自动驾驶中去，这也是人工智能：算法，大数据，算力共同推动的结果。</p><h1 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h1><p>[1]Zhou Z, Wen Z, Wang J, et al. QCNeXt: A Next-Generation Framework For Joint Multi-Agent Trajectory Prediction[J]. arXiv preprint arXiv:2306.10508, 2023.<a href="https://arxiv.org/abs/2306.10508">https://arxiv.org/abs/2306.10508</a></p><p>[2]Mo X, Xing Y, Lv C. Recog: A deep learning framework with heterogeneous graph for interaction-aware trajectory prediction[J]. arXiv preprint arXiv:2012.05032, 2020.<a href="https://arxiv.org/abs/2012.05032">https://arxiv.org/abs/2012.05032</a></p><p>[3]Cui H, Radosavljevic V, Chou F C, et al. Multimodal trajectory predictions for autonomous driving using deep convolutional networks[C]//2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019: 2090-2096.<a href="https://arxiv.org/abs/1809.10732">https://arxiv.org/abs/1809.10732</a></p><p>[4]Schreier M, Willert V, Adamy J. An integrated approach to maneuver-based trajectory prediction and criticality assessment in arbitrary road environments[J]. IEEE Transactions on Intelligent Transportation Systems, 2016, 17(10): 2751-2766.<a href="https://ieeexplore.ieee.org/abstract/document/7412746">https://ieeexplore.ieee.org/abstract/document/7412746</a></p><p>[5]A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei and S. Savarese, “Social LSTM: Human Trajectory Prediction in Crowded Spaces,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, 2016, pp. 961-971, doi: 10.1109/CVPR.2016.110.<a href="https://ieeexplore.ieee.org/document/7780479">https://ieeexplore.ieee.org/document/7780479</a></p><p>[6] Gao J, Sun C, Zhao H, et al. Vectornet: Encoding hd maps and agent dynamics from vectorized representation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 11525-11533.<a href="https://arxiv.org/abs/2005.04259">https://arxiv.org/abs/2005.04259</a></p><p>[7] Liu Y, Zhang J, Fang L, et al. Multimodal motion prediction with stacked transformers[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 7577-7586.<a href="https://arxiv.org/abs/2103.11624">https://arxiv.org/abs/2103.11624</a></p><p>[8] Hu Y, Yang J, Chen L, et al. Goal-oriented Autonomous Driving[J]. arXiv preprint arXiv:2212.10156, 2022.<a href="https://arxiv.org/abs/2212.10156">https://arxiv.org/abs/2212.10156</a></p><p>[9]Casas S, Luo W, Urtasun R. Intentnet: Learning to predict intention from raw sensor data[C]//Conference on Robot Learning. PMLR, 2018: 947-956.<a href="https://arxiv.org/abs/2101.07907">https://arxiv.org/abs/2101.07907</a></p>]]></content>
      
      
      <categories>
          
          <category> 轨迹预测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 自动驾驶 </tag>
            
            <tag> 轨迹预测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_torch.autograd.Function</title>
      <link href="/2023/08/24/pytorch-torch-autograd-Function/"/>
      <url>/2023/08/24/pytorch-torch-autograd-Function/</url>
      
        <content type="html"><![CDATA[<h1 id="这是关于torchautogradfunction"><a class="markdownIt-Anchor" href="#这是关于torchautogradfunction"></a> 这是关于torch.autograd.Function</h1><p>在 PyTorch 中，<code>torch.autograd.Function</code> 是一个基础类，用于定义自定义的autograd函数，使你能够实现任意的前向传播和反向传播操作。这对于实现自定义的操作和损失函数，或者对已有操作进行修改，都非常有用。</p><span id="more"></span><p>要使用 <code>torch.autograd.Function</code>，你需要创建一个继承自它的子类，并实现以下两个方法：<code>forward</code> 和 <code>backward</code>。</p><ol><li><p><code>forward</code> 方法：<br>这个方法定义了自定义函数的前向传播过程。它接收输入张量或其他变量作为参数，并返回计算结果。在 <code>forward</code> 方法中，你可以执行任意计算，包括创建新的张量和执行运算符。</p></li><li><p><code>backward</code> 方法：<br>这个方法定义了自定义函数的反向传播过程。它接收关于输出的梯度（通常是一个梯度张量）作为参数，并计算相对于输入的梯度。在 <code>backward</code> 方法中，你需要计算输入变量的梯度，以便在整个计算图中进行梯度传播。</p></li></ol><p>以下是一个简单的示例，演示如何使用 <code>torch.autograd.Function</code> 来实现一个自定义函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="comment"># 在 forward 方法中执行前向传播计算</span></span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>)</span><br><span class="line">        output = <span class="built_in">input</span> * <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="comment"># 在 backward 方法中计算梯度</span></span><br><span class="line">        <span class="built_in">input</span>, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output * <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义函数</span></span><br><span class="line">x = torch.tensor([<span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = MyFunction.apply(x)</span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Input gradient:&quot;</span>, x.grad)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Input gradient: tensor([2.])</span></span><br><span class="line"><span class="string">tensor([2.], grad_fn=&lt;MyFunctionBackward&gt;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>在这个示例中，<code>MyFunction</code> 继承自 <code>torch.autograd.Function</code>，并实现了 <code>forward</code> 和 <code>backward</code> 方法。你可以通过 <code>MyFunction.apply()</code> 来使用这个自定义函数。在后续的反向传播中，PyTorch 将会使用 <code>backward</code> 方法计算梯度。</p><p>这就是如何使用 <code>torch.autograd.Function</code> 来实现自定义函数，并在自定义的计算中使用 PyTorch 的自动微分。</p><ul><li><p><code>@staticmethod</code> 是 Python 中的一个装饰器（Decorator），用于将一个方法定义为静态方法。静态方法是指在类中定义的方法，不依赖于类的实例，因此可以直接通过类名调用，而不需要创建类的对象实例。</p><p>在你提供的代码中，<code>@staticmethod</code> 装饰器用于将方法定义为静态方法。具体来说，它用于 <code>SpecialSpmmFunction</code> 类中的两个方法：<code>forward</code> 和 <code>backward</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SpecialSpmmFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, indices, values, shape, b</span>):</span><br><span class="line">        <span class="comment"># ... implementation ...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="comment"># ... implementation ...</span></span><br></pre></td></tr></table></figure><p>通过将这两个方法定义为静态方法，你可以在不创建类的实例的情况下，直接通过类名调用这些方法。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">indices = ...</span><br><span class="line">values = ...</span><br><span class="line">shape = ...</span><br><span class="line">b = ...</span><br><span class="line">result = SpecialSpmmFunction.forward(indices, values, shape, b)</span><br></pre></td></tr></table></figure><p>这种方法非常适合在定义类的方法时，不需要访问实例属性或方法，或者在类的实例不存在的情况下执行一些操作。静态方法不会自动接收类的实例作为第一个参数（通常是 <code>self</code>），因此它们不依赖于类的状态。</p></li><li><p>在上面的代码中，<code>y = MyFunction.apply(x)</code> 这一行代码是通过调用 <code>MyFunction</code> 类的 <code>apply</code> 方法来计算前向传播的结果 <code>y</code>。在这个特定的示例中，<code>MyFunction</code> 类的 <code>forward</code> 方法执行的操作是将输入张量 <code>x</code> 乘以 2，因此 <code>y</code> 的值将是 <code>x</code> 的两倍。</p><p>这里，<code>MyFunction.apply(x)</code> 实际上是在前向传播中使用了自定义的操作，并返回计算得到的输出。因为我们定义了自定义函数 <code>MyFunction</code> 的 <code>forward</code> 方法，所以调用 <code>.apply(x)</code> 实际上就是调用了我们自己实现的操作。</p><p>在更复杂的情况下，自定义函数可能会执行许多不同的操作，从而实现复杂的前向传播。<code>apply</code> 方法允许我们将输入传递给这些操作，并返回输出。通常情况下，PyTorch 的模块和函数也是这样工作的，只是在内部使用了更多的优化和组件。</p><p>简而言之，<code>y = MyFunction.apply(x)</code> 将会调用自定义函数 <code>MyFunction</code> 的前向传播方法，执行该方法中的操作，并将操作的结果存储在 <code>y</code> 中。</p></li><li><p>对于print(y)</p><ul><li><p>在上面的代码中，<code>y = MyFunction.apply(x)</code> 这一行代码是通过调用 <code>MyFunction</code> 类的 <code>apply</code> 方法来计算<strong>前向传播的结果</strong> <code>y</code>。在这个特定的示例中，<code>MyFunction</code> 类的 <code>forward</code> 方法执行的操作是将输入张量 <code>x</code> 乘以 2，因此 <code>y</code> 的值将是 <code>x</code> 的两倍。</p><p>这里，<code>MyFunction.apply(x)</code> 实际上是在前向传播中使用了自定义的操作，并返回计算得到的输出。因为我们定义了自定义函数 <code>MyFunction</code> 的 <code>forward</code> 方法，所以调用 <code>.apply(x)</code> 实际上就是调用了我们自己实现的操作。</p><p>在更复杂的情况下，自定义函数可能会执行许多不同的操作，从而实现复杂的前向传播。<code>apply</code> 方法允许我们将输入传递给这些操作，并返回输出。通常情况下，PyTorch 的模块和函数也是这样工作的，只是在内部使用了更多的优化和组件。</p><p>简而言之，<code>y = MyFunction.apply(x)</code> 将会调用自定义函数 <code>MyFunction</code> 的前向传播方法，执行该方法中的操作，并将操作的结果存储在 <code>y</code> 中。</p></li></ul></li><li><p>如果令c=y.backward(),print©输出的结果为None</p></li><li><p>如果将y.backward()注释掉，print(“Input gradient:”, x.grad)为Input gradient:None</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用户新增预测挑战赛</title>
      <link href="/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/"/>
      <url>/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/</url>
      
        <content type="html"><![CDATA[<h2 id="1数据说明"><a class="markdownIt-Anchor" href="#1数据说明"></a> 1.数据说明</h2><p>赛题数据由约62万条训练集、20万条测试集数据组成，共包含13个字段。其中uuid为样本唯一标识，eid为访问行为ID，udmap为行为属性，其中的key1到key9表示不同的行为属性，如项目名、项目id等相关字段，common_ts为应用访问记录发生时间（毫秒时间戳），其余字段x1至x8为用户相关的属性，为匿名处理字段。target字段为预测目标，即是否为新增用户。</p><h2 id="2评估指标"><a class="markdownIt-Anchor" href="#2评估指标"></a> 2.评估指标</h2><p>本次竞赛的评价标准采用f1_score，分数越高，效果越好。</p><span id="more"></span><h2 id="3解题思路"><a class="markdownIt-Anchor" href="#3解题思路"></a> 3.解题思路</h2><p>参赛选手的任务是基于训练集的样本数据，构建一个模型来预测测试集中用户的新增情况。这是一个二分类任务，其中目标是根据用户的行为、属性以及访问时间等特征，预测该用户是否属于新增用户。具体来说，选手需要利用给定的数据集进行特征工程、模型选择和训练，然后使用训练好的模型对测试集中的用户进行预测，并生成相应的预测结果。</p><h2 id="4遇到的问题"><a class="markdownIt-Anchor" href="#4遇到的问题"></a> 4.遇到的问题</h2><ul><li>数据量比较大，但是特征比较少，经过处理的特征没几个，因此目的是先增加特征然后再对特征进行处理以及特征降维</li><li>还不知道数据集的具体情况，可以对数据集进行筛选（暂时还没进行）</li></ul><h2 id="5方案"><a class="markdownIt-Anchor" href="#5方案"></a> 5.方案</h2><h3 id="相关模块和数据的导入"><a class="markdownIt-Anchor" href="#相关模块和数据的导入"></a> 相关模块和数据的导入：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="comment">#简单来说LabelEncoder就是把n个类别值编码为0~n-1之间的整数，建立起1-1映射</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="comment">#load() missing 1 required positional argument: &#x27;Loader&#x27;</span></span><br><span class="line"><span class="comment">#E:\software\anaconda\anaconda3\Lib\site-packages\distributed\config.py文件里的</span></span><br><span class="line"><span class="comment">#yaml.load(f)改成yaml.safe_load(f)</span></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> HistGradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取训练集和测试集</span></span><br><span class="line"><span class="comment"># 使用 read_csv() 函数从文件中读取训练集数据，文件名为 &#x27;train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">&#x27;用户新增预测挑战赛公开数据/train.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用 read_csv() 函数从文件中读取测试集数据，文件名为 &#x27;test.csv&#x27;</span></span><br><span class="line">test_data = pd.read_csv(<span class="string">&#x27;用户新增预测挑战赛公开数据/test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_data<span class="comment">#用于观察数据集</span></span><br></pre></td></tr></table></figure><h3 id="udmap的处理将-字典中的数据和unknown数据以one-hot的存储"><a class="markdownIt-Anchor" href="#udmap的处理将-字典中的数据和unknown数据以one-hot的存储"></a> udmap的处理，将 字典中的数据和unknown数据以one-hot的存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. 将 &#x27;udmap&#x27; 列进行 One-Hot 编码 </span></span><br><span class="line"><span class="comment"># 数据样例：</span></span><br><span class="line"><span class="comment">#                    udmap  key1  key2  key3  key4  key5  key6  key7  key8  key9</span></span><br><span class="line"><span class="comment"># 0           &#123;&#x27;key1&#x27;: 2&#125;     2     0     0     0     0     0     0     0     0</span></span><br><span class="line"><span class="comment"># 1           &#123;&#x27;key2&#x27;: 1&#125;     0     1     0     0     0     0     0     0     0</span></span><br><span class="line"><span class="comment"># 2  &#123;&#x27;key1&#x27;: 3, &#x27;key2&#x27;: 2&#125;   3     2     0     0     0     0     0     0     0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 python 中, 形如 &#123;&#x27;key1&#x27;: 3, &#x27;key2&#x27;: 2&#125; 格式的为字典类型对象, 通过key-value键值对的方式存储</span></span><br><span class="line"><span class="comment"># 而在本数据集中, udmap实际是以字符的形式存储, 所以处理时需要先用eval 函数将&#x27;udmap&#x27; 解析为字典</span></span><br><span class="line"><span class="comment"># 具体实现代码：</span></span><br><span class="line"><span class="comment"># 定义函数 udmap_onethot，用于将 &#x27;udmap&#x27; 列进行 One-Hot 编码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">udmap_onethot</span>(<span class="params">d</span>):</span><br><span class="line">    v = np.zeros(<span class="number">9</span>)  <span class="comment"># 创建一个长度为 9 的零数组</span></span><br><span class="line">    <span class="keyword">if</span> d == <span class="string">&#x27;unknown&#x27;</span>:  <span class="comment"># 如果 &#x27;udmap&#x27; 的值是 &#x27;unknown&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> v  <span class="comment"># 返回零数组</span></span><br><span class="line">    d = <span class="built_in">eval</span>(d)  <span class="comment"># 将 &#x27;udmap&#x27; 的值解析为一个字典</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):  <span class="comment"># 遍历 &#x27;key1&#x27; 到 &#x27;key9&#x27;, 注意, 这里不包括10本身</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">in</span> d:  <span class="comment"># 如果当前键存在于字典中</span></span><br><span class="line">            v[i-<span class="number">1</span>] = d[<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i)]  <span class="comment"># 将字典中的值存储在对应的索引位置上</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> v  <span class="comment"># 返回 One-Hot 编码后的数组</span></span><br></pre></td></tr></table></figure><h3 id="数据集特征提取"><a class="markdownIt-Anchor" href="#数据集特征提取"></a> 数据集特征提取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 注: 对于不理解的步骤, 可以逐行 print 内容查看</span></span><br><span class="line"><span class="comment"># 使用 apply() 方法将 udmap_onethot 函数应用于每个样本的 &#x27;udmap&#x27; 列</span></span><br><span class="line"><span class="comment"># np.vstack() 用于将结果堆叠成一个数组</span></span><br><span class="line">train_udmap_df = pd.DataFrame(np.vstack(train_data[<span class="string">&#x27;udmap&#x27;</span>].apply(udmap_onethot)))</span><br><span class="line">test_udmap_df = pd.DataFrame(np.vstack(test_data[<span class="string">&#x27;udmap&#x27;</span>].apply(udmap_onethot)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">apply() 函数的自由度较高，可以直接对 Series 或者 DataFrame 中元素进行逐元素遍历操作，方便且高效，具有类似于 Numpy 的特性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为新的特征 DataFrame 命名列名</span></span><br><span class="line">train_udmap_df.columns = [<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line">test_udmap_df.columns = [<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line"><span class="comment"># 将编码后的 udmap 特征与原始数据进行拼接，沿着列方向拼接</span></span><br><span class="line">train_data = pd.concat([train_data, train_udmap_df], axis=<span class="number">1</span>)</span><br><span class="line">test_data = pd.concat([test_data, test_udmap_df], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 编码 udmap 是否为空</span></span><br><span class="line"><span class="comment"># 使用比较运算符将每个样本的 &#x27;udmap&#x27; 列与字符串 &#x27;unknown&#x27; 进行比较，返回一个布尔值的 Series</span></span><br><span class="line"><span class="comment"># 使用 astype(int) 将布尔值转换为整数（0 或 1），以便进行后续的数值计算和分析</span></span><br><span class="line">train_data[<span class="string">&#x27;udmap_isunknown&#x27;</span>] = (train_data[<span class="string">&#x27;udmap&#x27;</span>] == <span class="string">&#x27;unknown&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">test_data[<span class="string">&#x27;udmap_isunknown&#x27;</span>] = (test_data[<span class="string">&#x27;udmap&#x27;</span>] == <span class="string">&#x27;unknown&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 提取 eid 的频次特征</span></span><br><span class="line"><span class="comment"># 使用 map() 方法将每个样本的 eid 映射到训练数据中 eid 的频次计数</span></span><br><span class="line"><span class="comment"># train_data[&#x27;eid&#x27;].value_counts() 返回每个 eid 出现的频次计数</span></span><br><span class="line">train_data[<span class="string">&#x27;eid_freq&#x27;</span>] = train_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;eid&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;eid_freq&#x27;</span>] = test_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;eid&#x27;</span>].value_counts())<span class="comment">#这里在测试数据集上用的是训练集的eid的频率</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">map可以接受函数，字典，以及series（和字典类似）。然后这里会进行匹配。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 提取 eid 的标签特征</span></span><br><span class="line"><span class="comment"># 使用 groupby() 方法按照 eid 进行分组，然后计算每个 eid 分组的目标值均值</span></span><br><span class="line"><span class="comment"># train_data.groupby(&#x27;eid&#x27;)[&#x27;target&#x27;].mean() 返回每个 eid 分组的目标值均值</span></span><br><span class="line">train_data[<span class="string">&#x27;eid_mean&#x27;</span>] = train_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;eid&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;eid_mean&#x27;</span>] = test_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;eid&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">这里现根据eid进行分组</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 提取时间戳</span></span><br><span class="line"><span class="comment"># 使用 pd.to_datetime() 函数将时间戳列转换为 datetime 类型</span></span><br><span class="line"><span class="comment"># 样例：1678932546000-&gt;2023-03-15 15:14:16</span></span><br><span class="line"><span class="comment"># 注: 需要注意时间戳的长度, 如果是13位则unit 为 毫秒, 如果是10位则为 秒, 这是转时间戳时容易踩的坑</span></span><br><span class="line"><span class="comment"># 具体实现代码：</span></span><br><span class="line">train_data[<span class="string">&#x27;common_ts&#x27;</span>] = pd.to_datetime(train_data[<span class="string">&#x27;common_ts&#x27;</span>], unit=<span class="string">&#x27;ms&#x27;</span>)</span><br><span class="line">test_data[<span class="string">&#x27;common_ts&#x27;</span>] = pd.to_datetime(test_data[<span class="string">&#x27;common_ts&#x27;</span>], unit=<span class="string">&#x27;ms&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 dt.hour 属性从 datetime 列中提取小时信息，并将提取的小时信息存储在新的列 &#x27;common_ts_hour&#x27;</span></span><br><span class="line">train_data[<span class="string">&#x27;common_ts_hour&#x27;</span>] = train_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.hour</span><br><span class="line">test_data[<span class="string">&#x27;common_ts_hour&#x27;</span>] = test_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.hour</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;common_ts_day&#x27;</span>] = train_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.day</span><br><span class="line">test_data[<span class="string">&#x27;common_ts_day&#x27;</span>] = test_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.day</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x1_freq&#x27;</span>] = train_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x1&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x1_freq&#x27;</span>] = test_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x1&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x1_mean&#x27;</span>] = train_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x1&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x1_mean&#x27;</span>] = test_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x1&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x2_freq&#x27;</span>] = train_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x2&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x2_freq&#x27;</span>] = test_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x2&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x2_mean&#x27;</span>] = train_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x2&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x2_mean&#x27;</span>] = test_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x2&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#train_data[&#x27;x3_freq&#x27;] = train_data[&#x27;x3&#x27;].map(train_data[&#x27;x3&#x27;].value_counts())</span></span><br><span class="line"><span class="comment">#test_data[&#x27;x3_freq&#x27;] = test_data[&#x27;x3&#x27;].map(train_data[&#x27;x3&#x27;].value_counts())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#train_data[&#x27;x4_freq&#x27;] = train_data[&#x27;x4&#x27;].map(train_data[&#x27;x4&#x27;].value_counts())</span></span><br><span class="line"><span class="comment">#test_data[&#x27;x4_freq&#x27;] = test_data[&#x27;x4&#x27;].map(train_data[&#x27;x4&#x27;].value_counts())</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这两个数据有问题，在test中会因为数据不匹配导致NaN的出现因此这两个数据剔除</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x6_freq&#x27;</span>] = train_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x6&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x6_freq&#x27;</span>] = test_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x6&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x6_mean&#x27;</span>] = train_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x6&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x6_mean&#x27;</span>] = test_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x6&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x7_freq&#x27;</span>] = train_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x7&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x7_freq&#x27;</span>] = test_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x7&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x7_mean&#x27;</span>] = train_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x7&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x7_mean&#x27;</span>] = test_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x7&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x8_freq&#x27;</span>] = train_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x8&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x8_freq&#x27;</span>] = test_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x8&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x8_mean&#x27;</span>] = train_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x8&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x8_mean&#x27;</span>] = test_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x8&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#df.groupby(分组依据)[数据来源].使用操作</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train=train_data.drop([<span class="string">&#x27;udmap&#x27;</span>,<span class="string">&#x27;uuid&#x27;</span>,<span class="string">&#x27;target&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">test=test_data.drop([<span class="string">&#x27;udmap&#x27;</span>,<span class="string">&#x27;uuid&#x27;</span>,],axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#我们保留了common_ts这个数据，接下来对这个特征的归一化</span></span><br></pre></td></tr></table></figure><h4 id="数据归一化处理"><a class="markdownIt-Anchor" href="#数据归一化处理"></a> 数据归一化处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对数据进行归一化处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train.columns:</span><br><span class="line">    MAX=<span class="built_in">max</span>(train[i])</span><br><span class="line">    MIN=<span class="built_in">min</span>(train[i])<span class="comment">#用训练集的数据区归一化测试集的数据</span></span><br><span class="line">    LEN=MAX-MIN</span><br><span class="line">    train[i]=train[i].apply(<span class="keyword">lambda</span> x:(x-MIN)/LEN)</span><br><span class="line">    test[i]=test[i].apply(<span class="keyword">lambda</span> x:(x-MIN)/LEN)</span><br></pre></td></tr></table></figure><h3 id="特征组合"><a class="markdownIt-Anchor" href="#特征组合"></a> 特征组合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暴力Feature 行为</span></span><br><span class="line"><span class="comment"># 暴力Feature 时间</span></span><br><span class="line"><span class="comment"># 暴力Feature 用户属性</span></span><br><span class="line"><span class="comment">#这里暂时不考虑特征的随机组合</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴力Feature 行为</span></span><br><span class="line">f = [<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>, <span class="string">&#x27;key3&#x27;</span>, <span class="string">&#x27;key4&#x27;</span>, <span class="string">&#x27;key5&#x27;</span>, <span class="string">&#x27;key6&#x27;</span>, <span class="string">&#x27;key7&#x27;</span>, <span class="string">&#x27;key8&#x27;</span>, <span class="string">&#x27;key9&#x27;</span>,<span class="string">&#x27;udmap_isunknown&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line"><span class="comment">#加f后可以在字符串里面使用用花括号括起来的变量和表达式，如果字符串里面没有表达式，那么前面加不加f输出应该都一样。</span></span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line"><span class="comment"># 暴力Feature 时间</span></span><br><span class="line">f = [<span class="string">&#x27;common_ts_hour&#x27;</span>,<span class="string">&#x27;common_ts_day&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>-<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] - df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>*<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] * df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>/<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] / (df[f[j]]+<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 暴力Feature 用户属性</span></span><br><span class="line">f = [<span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;x2&#x27;</span>, <span class="string">&#x27;x3&#x27;</span>, <span class="string">&#x27;x4&#x27;</span>, <span class="string">&#x27;x5&#x27;</span>, <span class="string">&#x27;x6&#x27;</span>, <span class="string">&#x27;x7&#x27;</span>, <span class="string">&#x27;x8&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="数据降维"><a class="markdownIt-Anchor" href="#数据降维"></a> 数据降维</h3><ul><li>利用xgboost进行特征选择，最终选出70组特征</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#采用xgboost的特征筛选的功能</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">6</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">xgbc.fit(train, label)</span><br><span class="line">importances_xgb = xgbc.feature_importances_/np.<span class="built_in">sum</span>( xgbc.feature_importances_)</span><br><span class="line"><span class="comment"># print(importances)</span></span><br><span class="line">indices_xgb = np.argsort(importances_xgb)[::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># print(indices)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看结果</span></span><br><span class="line">feat_labels = train.columns</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(train.shape[<span class="number">1</span>]):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % \</span><br><span class="line">          (f + <span class="number">1</span>, <span class="number">30</span>, feat_labels[indices_xgb[f]], importances_xgb[indices_xgb[f]]))</span><br><span class="line"></span><br><span class="line">features=np.array(feat_labels)</span><br><span class="line">num_imo=features[<span class="built_in">list</span>(indices_xgb[<span class="number">0</span>:<span class="number">60</span>])]<span class="comment">#选择60个特征</span></span><br><span class="line"></span><br><span class="line">train=train[num_imo]</span><br><span class="line">test=test[num_imo]</span><br></pre></td></tr></table></figure><h3 id="交叉验证模型"><a class="markdownIt-Anchor" href="#交叉验证模型"></a> 交叉验证模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常见的交叉验证模型框架</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_train</span>(<span class="params">model, model_name, kfold=<span class="number">5</span></span>):</span><br><span class="line">    oof_preds = np.zeros((train.shape[<span class="number">0</span>]))<span class="comment">#构造一个series令所有行全部为0</span></span><br><span class="line">    test_preds = np.zeros(test.shape[<span class="number">0</span>])</span><br><span class="line">    skf = StratifiedKFold(n_splits=kfold)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Model = <span class="subst">&#123;model_name&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train.columns))</span><br><span class="line">    <span class="keyword">for</span> k, (train_index, test_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(skf.split(train, label)):</span><br><span class="line">        x_train, x_test = train.iloc[train_index, :], train.iloc[test_index, :]</span><br><span class="line">        y_train, y_test = label.iloc[train_index], label.iloc[test_index]</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">        model.fit(x_train,y_train)</span><br><span class="line">        <span class="comment">#print(2)</span></span><br><span class="line">        y_pred = model.predict_proba(x_test)[:,<span class="number">1</span>]</span><br><span class="line">        <span class="comment">##在这里第一列是预测为0的概率，第二列是预测为1的概率</span></span><br><span class="line">        oof_preds[test_index] = y_pred.ravel()</span><br><span class="line">        auc = roc_auc_score(y_test,y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;- KFold = %d, val_auc = %.4f&quot;</span> % (k, auc))</span><br><span class="line">        test_fold_preds = model.predict_proba(test)[:, <span class="number">1</span>]</span><br><span class="line">        test_preds += test_fold_preds.ravel()<span class="comment">#将给定Series对象的基础数据作为ndarray返回。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Overall Model = %s, F1 = %.4f&quot;</span> % (model_name, f1_score(label, oof_preds, average=<span class="string">&#x27;macro&#x27;</span>)))</span><br><span class="line">    <span class="keyword">return</span> test_preds / kfold<span class="comment">#取平均值</span></span><br></pre></td></tr></table></figure><h3 id="数据清洗通过10交叉验证判断数据是否存在问题"><a class="markdownIt-Anchor" href="#数据清洗通过10交叉验证判断数据是否存在问题"></a> 数据清洗，通过10交叉验证判断数据是否存在问题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">xgbc = XGBClassifier(</span></span><br><span class="line"><span class="string">    objective=&#x27;binary:logistic&#x27;,</span></span><br><span class="line"><span class="string">    eval_metric=&#x27;auc&#x27;,</span></span><br><span class="line"><span class="string">    n_estimators=100, </span></span><br><span class="line"><span class="string">    max_depth=6, </span></span><br><span class="line"><span class="string">    learning_rate=0.1</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">xgbc_test_preds = model_train(xgbc, &quot;XGBClassifier&quot;, 10)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这里用于挑选异常训练集</span></span><br><span class="line"><span class="comment">#看误差是否过大</span></span><br></pre></td></tr></table></figure><h3 id="验证集和训练集构建"><a class="markdownIt-Anchor" href="#验证集和训练集构建"></a> 验证集和训练集构建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将训练数据划分成训练集和验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split( train, label, stratify=label, random_state=<span class="number">2022</span>)</span><br><span class="line"><span class="comment">#75%的训练集</span></span><br></pre></td></tr></table></figure><h3 id="模型选择"><a class="markdownIt-Anchor" href="#模型选择"></a> 模型选择</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xgboost实验</span></span><br><span class="line"><span class="comment"># max_depth不能太小否则会出问题</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">50</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">xgbc.fit(x_train,y_train)</span><br><span class="line">y_pred = xgbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策树实验</span></span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line">DT.fit(x_train,y_train)</span><br><span class="line">y_pred = DT.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机森林实验</span></span><br><span class="line">RF=RandomForestClassifier(n_estimators=<span class="number">50</span>)</span><br><span class="line">RF.fit(x_train,y_train)</span><br><span class="line">y_pred = RF.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GDBT实验</span></span><br><span class="line"><span class="comment">#是不是树的深度太浅导致的</span></span><br><span class="line">gbc = GradientBoostingClassifier(</span><br><span class="line">    n_estimators=<span class="number">10</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">gbc.fit(x_train,y_train)</span><br><span class="line">y_pred = gbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#HGBC 实验</span></span><br><span class="line">hgbc = HistGradientBoostingClassifier(</span><br><span class="line">    max_iter=<span class="number">20</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">gbc.fit(x_train,y_train)</span><br><span class="line">y_pred = gbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #LGMB 实验</span></span><br><span class="line"><span class="comment"># gbm = LGBMClassifier(</span></span><br><span class="line"><span class="comment">#     objective=&#x27;binary&#x27;,</span></span><br><span class="line"><span class="comment">#     boosting_type=&#x27;gbdt,</span></span><br><span class="line"><span class="comment">#     num_leaves=2 ** 6, </span></span><br><span class="line"><span class="comment">#     max_depth=50,</span></span><br><span class="line"><span class="comment">#     colsample_bytree=0.8,</span></span><br><span class="line"><span class="comment">#     subsample_freq=1,</span></span><br><span class="line"><span class="comment">#     max_bin=255,</span></span><br><span class="line"><span class="comment">#     learning_rate=0.05, </span></span><br><span class="line"><span class="comment">#     n_estimators=4000, </span></span><br><span class="line"><span class="comment">#     metrics=&#x27;auc&#x27;</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"><span class="comment"># gbm.fit(x_train,y_train)</span></span><br><span class="line"><span class="comment"># y_pred = gbm.predict_proba(x_train)[:, 1]</span></span><br><span class="line"><span class="comment"># threshold=0.5</span></span><br><span class="line"><span class="comment"># y_pred = (y_pred &gt;= threshold).astype(int)</span></span><br><span class="line"><span class="comment"># f1 = f1_score(y_train, y_pred, average=&#x27;macro&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;F1 = %.8f&#x27; % f1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cbc = CatBoostClassifier(</span></span><br><span class="line"><span class="comment">#     iterations=20, </span></span><br><span class="line"><span class="comment">#     depth=16, </span></span><br><span class="line"><span class="comment">#     learning_rate=0.03, </span></span><br><span class="line"><span class="comment">#     l2_leaf_reg=1, </span></span><br><span class="line"><span class="comment">#     loss_function=&#x27;Logloss&#x27;, </span></span><br><span class="line"><span class="comment">#     verbose=0</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"><span class="comment"># cbc.fit(x_train,y_train)</span></span><br><span class="line"><span class="comment"># y_pred = cbc.predict_proba(x_train)[:, 1]</span></span><br><span class="line"><span class="comment"># threshold=0.5</span></span><br><span class="line"><span class="comment"># y_pred = (y_pred &gt;= threshold).astype(int)</span></span><br><span class="line"><span class="comment"># f1 = f1_score(y_train, y_pred, average=&#x27;macro&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;F1 = %.8f&#x27; % f1)</span></span><br><span class="line"></span><br><span class="line">ada=AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">50</span>),</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">    learning_rate=<span class="number">0.01</span></span><br><span class="line">    )<span class="comment">#默认是CART决策树作为单模型</span></span><br><span class="line">ada.fit(x_train,y_train)</span><br><span class="line">y_pred = ada.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br></pre></td></tr></table></figure><h3 id="模型融合"><a class="markdownIt-Anchor" href="#模型融合"></a> 模型融合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最终决定：决策树，xgboost， RF，GBDT，HGBC,adaboost这几个模型stack</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">50</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line">RF=RandomForestClassifier(n_estimators=<span class="number">50</span>)</span><br><span class="line">gbc = GradientBoostingClassifier(</span><br><span class="line">    n_estimators=<span class="number">10</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">hgbc = HistGradientBoostingClassifier(</span><br><span class="line">    max_iter=<span class="number">20</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">ada=AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">50</span>),</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">    learning_rate=<span class="number">0.01</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;xgbc&#x27;</span>, xgbc),</span><br><span class="line">    (<span class="string">&#x27;DT&#x27;</span>,DT),</span><br><span class="line">    (<span class="string">&#x27;RF&#x27;</span>,RF),</span><br><span class="line">    (<span class="string">&#x27;gbc&#x27;</span>, gbc),</span><br><span class="line">    (<span class="string">&#x27;hgbc&#x27;</span>, hgbc),</span><br><span class="line">    (<span class="string">&#x27;ada&#x27;</span>, ada),</span><br><span class="line">]</span><br><span class="line">clf = StackingClassifier(</span><br><span class="line">    estimators=estimators, </span><br><span class="line">    final_estimator=LogisticRegression()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用组合模型训练</span></span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line">y_pred = clf.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br></pre></td></tr></table></figure><h3 id="结果提交"><a class="markdownIt-Anchor" href="#结果提交"></a> 结果提交</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #这里的分类器我不单单想用上面的，我打算重新训练所有数据集来进行预测</span></span><br><span class="line"><span class="comment"># clf_test_preds = model_train(clf, &quot;StackingClassifier&quot;)</span></span><br><span class="line"><span class="comment"># #还是用全部的数据进行训练 </span></span><br><span class="line"><span class="comment"># clf.fit(train,label)</span></span><br><span class="line"></span><br><span class="line">result_df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;uuid&#x27;</span>: test_data[<span class="string">&#x27;uuid&#x27;</span>],  <span class="comment"># 使用测试数据集中的 &#x27;uuid&#x27; 列作为 &#x27;uuid&#x27; 列的值</span></span><br><span class="line">    <span class="string">&#x27;target&#x27;</span>: clf.predict(test)  <span class="comment"># 使用模型 clf 对测试数据集进行预测，并将预测结果存储在 &#x27;target&#x27; 列中</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">result_df.to_csv(<span class="string">&#x27;submit.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 竞赛 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_data&amp;detach</title>
      <link href="/2023/08/24/pytorch-data-detach/"/>
      <url>/2023/08/24/pytorch-data-detach/</url>
      
        <content type="html"><![CDATA[<p>这是关于pytorch中的.data操和detach()操作的区分和介绍</p><p>这两个方法都可以用来从原有的计算图中分离出某一个tensor，有相似的地方，也有不同的地方，下面来比较性的看一看</p><p>原文链接：<a href="https://blog.csdn.net/qq_27825451/article/details/96837905">https://blog.csdn.net/qq_27825451/article/details/96837905</a></p><span id="more"></span><h1 id="data"><a class="markdownIt-Anchor" href="#data"></a> data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> </span><br><span class="line">a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.</span>], requires_grad = <span class="literal">True</span>)</span><br><span class="line">out = a.sigmoid()</span><br><span class="line">c = out.data  <span class="comment"># 需要走注意的是，通过.data “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化</span></span><br><span class="line">c.zero_()     <span class="comment"># 改变c的值，原来的out也会改变</span></span><br><span class="line"><span class="built_in">print</span>(c.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(out.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------------------------------------------&quot;</span>)</span><br><span class="line"> </span><br><span class="line">out.<span class="built_in">sum</span>().backward() <span class="comment"># 对原来的out求导，</span></span><br><span class="line"><span class="built_in">print</span>(a.grad)  <span class="comment"># 不会报错，但是结果却并不正确</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;运行结果为：</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.])</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.], grad_fn=&lt;SigmoidBackward&gt;)</span></span><br><span class="line"><span class="string">----------------------------------------------</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>（1）tensor .data 返回和 x 的相同数据 tensor,而且这个新的tensor和原来的tensor是共用数据的，一者改变，另一者也会跟着改变，而且新分离得到的tensor的require s_grad = False, 即不可求导的。（这一点其实detach是一样的）</p><p>（2）使用tensor.data的局限性。文档中说使用tensor.data是不安全的, 因为 <mark><strong>x.data 不能被 autograd 追踪求微分</strong></mark> 。什么意思呢？从上面的例子可以看出，**由于我更改分离之后的变量值c,导致原来的张量out的值也跟着改变了，但是这种改变对于autograd是没有察觉的，它依然按照求导规则来求导，导致得出完全错误的导数值却浑然不知。**它的风险性就是如果我再任意一个地方更改了某一个张量，求导的时候也没有通知我已经在某处更改了，导致得出的导数值完全不正确，故而风险大。</p><p>(也就是说.data修改数据后不会被检测到，但是原始操作已经修改)</p><h1 id="detach"><a class="markdownIt-Anchor" href="#detach"></a> detach()</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> </span><br><span class="line">a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.</span>], requires_grad = <span class="literal">True</span>)</span><br><span class="line">out = a.sigmoid()</span><br><span class="line">c = out.detach()  <span class="comment"># 需要走注意的是，通过.detach() “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化</span></span><br><span class="line">c.zero_()     <span class="comment"># 改变c的值，原来的out也会改变</span></span><br><span class="line"><span class="built_in">print</span>(c.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(out.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------------------------------------------&quot;</span>)</span><br><span class="line"> </span><br><span class="line">out.<span class="built_in">sum</span>().backward() <span class="comment"># 对原来的out求导，</span></span><br><span class="line"><span class="built_in">print</span>(a.grad)  <span class="comment"># 此时会报错，错误结果参考下面,显示梯度计算所需要的张量已经被“原位操作inplace”所更改了。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.])</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">tensor([0., 0., 0.], grad_fn=&lt;SigmoidBackward&gt;)</span></span><br><span class="line"><span class="string">----------------------------------------------</span></span><br><span class="line"><span class="string">RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>tensor.detach()的两点总结：</p><p>（1）tensor .detach() 返回和 x 的相同数据 tensor,而且这个新的tensor和原来的tensor是共用数据的，一者改变，另一者也会跟着改变，而且新分离得到的tensor的require s_grad = False, 即不可求导的。（这一点其实 .data是一样的）（也是在原数据集上操作）</p><p>（2）使用tensor.detach()的优点。从上面的例子可以看出，由于我更改分离之后的变量值c,导致原来的张量out的值也跟着改变了，这个时候如果依然按照求导规则来求导，由于out已经更改了，所以不会再继续求导了，而是报错，这样就避免了得出完全牛头不对马嘴的求导结果。</p><h1 id="区别总结"><a class="markdownIt-Anchor" href="#区别总结"></a> 区别总结</h1><p>相同点：tensor.data和tensor.detach() 都是变量从图中分离，但而这都是“原位操作 inplace operation”。</p><p>不同点：</p><p>（1）.data 是一个属性，二.detach()是一个方法；</p><p>（2）.data 是不安全的，.detach()是安全的。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAT和GCN中的注意事项</title>
      <link href="/2023/08/24/GAT%E5%92%8CGCN%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
      <url>/2023/08/24/GAT%E5%92%8CGCN%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="inductive-learning-and-transductive-learning"><a class="markdownIt-Anchor" href="#inductive-learning-and-transductive-learning"></a> “Inductive learning” and “Transductive learning”</h1><p>“Inductive learning”意为归纳学习，“Transductive learning”意为直推学习</p><p>对于GCN而言我们认为其是：直推学习，也就是说当测试集出现了训练集未学习过的节点时即图结构发生了变化时，网络需要重新训练。</p><p>对于GAT而言：归纳学习；也就是训练阶段见不到的数据（在图书剧中可以指新的节点，也可以指新的图）                                                                                                                                        直接进行预测而不需要重新训练。</p><span id="more"></span><p>GCN就像是没有权重的GAT一样，见如下公式：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mi>C</mi><mi>N</mi><mo>=</mo><mover accent="true"><mi>A</mi><mo>~</mo></mover><mi>X</mi><mi>W</mi><mspace linebreak="newline"></mspace><mi>G</mi><mi>A</mi><mi>T</mi><mo>=</mo><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo>~</mo></mover><mo>⊙</mo><mi>M</mi><mo stretchy="false">)</mo><mi>X</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">GCN=\tilde{A}XW \\GAT=(\tilde A \odot M)XW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9201899999999998em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1701899999999998em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span></span></p><p>这里的需不需要重新训练围殴认为是其关注的重点，对于GCN而言重点关注的<strong>图的全局结构</strong>，因此当图的结果变换的时候自然需要重新训练。</p><p>而对于GAT而言虽说用到了邻接矩阵，但训练的目标是<mark>中心节点</mark>和<mark>邻居节点</mark>间的聚合操作。</p><p>某种意义上来说，GCN是一种考虑了整体图结构的方法；而GAT一定程度上放弃了整体结构，这使得其能够完成Inductive任务。<br>链接：<a href="https://www.zhihu.com/question/409415383/answer/1361505060">https://www.zhihu.com/question/409415383/answer/1361505060</a></p><p>其实是否确保inductive，本质上在于两点：首先是你要确保你这个算法的node-level input不能是one hot而必须是实在的node attribute，一旦onehot了就必是只能transductive，原因显然。其次是training方式，不能是依赖于整图的矩阵运算，而必须是graphsage里面appendix a的minibatch training模式下的分割方案，而这才是graphsage有底气说自己inductive牛逼的主要原因。你确保这两点，几乎现在市面上所有message passing架构的gnn都是inductive的。<br>链接：<a href="https://www.zhihu.com/question/409415383/answer/1361596817">https://www.zhihu.com/question/409415383/answer/1361596817</a></p><p>这个地方还可以参考论文：<a href="https://www.researchgate.net/publication/352513259_A_Subgraph-based_Knowledge_Reasoning_Method_for_Collective_Fraud_Detection_in_E-commerce">https://www.researchgate.net/publication/352513259_A_Subgraph-based_Knowledge_Reasoning_Method_for_Collective_Fraud_Detection_in_E-commerce</a></p><p>里面提到了了一个<strong>全局和局部</strong>的观念</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>First-Hello World</title>
      <link href="/2023/06/24/hello-world/"/>
      <url>/2023/06/24/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><span id="more"></span><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><h3 id="github同步"><a class="markdownIt-Anchor" href="#github同步"></a> GitHub同步</h3><p>hexo clean</p><p>hexo d -g</p><p>会有一点延迟，更新得等一会</p><h3 id="显示部分内容"><a class="markdownIt-Anchor" href="#显示部分内容"></a> 显示部分内容</h3><p>在你写 md 文章的时候，可以在内容中加上 <code>&lt;!--more--&gt;</code>，这样首页和列表页展示的文章内容就是 <code>&lt;!--more--&gt;</code> 之前的文字，而之后的就不会显示了。</p>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
