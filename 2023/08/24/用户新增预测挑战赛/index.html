<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.17.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null,"show_result":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"giscus","storage":true,"lazyload":false,"nav":null,"activeClass":"giscus"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":"ture","trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="1.数据说明 赛题数据由约62万条训练集、20万条测试集数据组成，共包含13个字段。其中uuid为样本唯一标识，eid为访问行为ID，udmap为行为属性，其中的key1到key9表示不同的行为属性，如项目名、项目id等相关字段，common_ts为应用访问记录发生时间（毫秒时间戳），其余字段x1至x8为用户相关的属性，为匿名处理字段。target字段为预测目标，即是否为新增用户。  2.评估指">
<meta property="og:type" content="article">
<meta property="og:title" content="用户新增预测挑战赛">
<meta property="og:url" content="http://example.com/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/index.html">
<meta property="og:site_name" content="YNY&#39;s BLOG">
<meta property="og:description" content="1.数据说明 赛题数据由约62万条训练集、20万条测试集数据组成，共包含13个字段。其中uuid为样本唯一标识，eid为访问行为ID，udmap为行为属性，其中的key1到key9表示不同的行为属性，如项目名、项目id等相关字段，common_ts为应用访问记录发生时间（毫秒时间戳），其余字段x1至x8为用户相关的属性，为匿名处理字段。target字段为预测目标，即是否为新增用户。  2.评估指">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-24T07:51:37.000Z">
<meta property="article:modified_time" content="2023-08-27T05:11:27.831Z">
<meta property="article:author" content="YNY">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="竞赛">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/","path":"2023/08/24/用户新增预测挑战赛/","title":"用户新增预测挑战赛"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>用户新增预测挑战赛 | YNY's BLOG</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">YNY's BLOG</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">YOLO</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E"><span class="nav-number">1.</span> <span class="nav-text"> 1.数据说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="nav-number">2.</span> <span class="nav-text"> 2.评估指标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E8%A7%A3%E9%A2%98%E6%80%9D%E8%B7%AF"><span class="nav-number">3.</span> <span class="nav-text"> 3.解题思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">4.</span> <span class="nav-text"> 4.遇到的问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5%E6%96%B9%E6%A1%88"><span class="nav-number">5.</span> <span class="nav-text"> 5.方案</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9D%97%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="nav-number">5.1.</span> <span class="nav-text"> 相关模块和数据的导入：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#udmap%E7%9A%84%E5%A4%84%E7%90%86%E5%B0%86-%E5%AD%97%E5%85%B8%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%92%8Cunknown%E6%95%B0%E6%8D%AE%E4%BB%A5one-hot%E7%9A%84%E5%AD%98%E5%82%A8"><span class="nav-number">5.2.</span> <span class="nav-text"> udmap的处理，将 字典中的数据和unknown数据以one-hot的存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-number">5.3.</span> <span class="nav-text"> 数据集特征提取</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="nav-number">5.3.1.</span> <span class="nav-text"> 数据归一化处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88"><span class="nav-number">5.4.</span> <span class="nav-text"> 特征组合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4"><span class="nav-number">5.5.</span> <span class="nav-text"> 数据降维</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.6.</span> <span class="nav-text"> 交叉验证模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E9%80%9A%E8%BF%8710%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98"><span class="nav-number">5.7.</span> <span class="nav-text"> 数据清洗，通过10交叉验证判断数据是否存在问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E8%AE%AD%E7%BB%83%E9%9B%86%E6%9E%84%E5%BB%BA"><span class="nav-number">5.8.</span> <span class="nav-text"> 验证集和训练集构建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">5.9.</span> <span class="nav-text"> 模型选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88"><span class="nav-number">5.10.</span> <span class="nav-text"> 模型融合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C%E6%8F%90%E4%BA%A4"><span class="nav-number">5.11.</span> <span class="nav-text"> 结果提交</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YNY"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">YNY</p>
  <div class="site-description" itemprop="description">他强任他强，清风拂山岗</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/handsomexiu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;handsomexiu" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1184817330@qq.com" title="E-Mail → mailto:1184817330@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/08/24/%E7%94%A8%E6%88%B7%E6%96%B0%E5%A2%9E%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="YNY">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YNY's BLOG">
      <meta itemprop="description" content="他强任他强，清风拂山岗">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="用户新增预测挑战赛 | YNY's BLOG">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          用户新增预测挑战赛
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-08-24 15:51:37" itemprop="dateCreated datePublished" datetime="2023-08-24T15:51:37+08:00">2023-08-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-08-27 13:11:27" itemprop="dateModified" datetime="2023-08-27T13:11:27+08:00">2023-08-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>16k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="1数据说明"><a class="markdownIt-Anchor" href="#1数据说明"></a> 1.数据说明</h2>
<p>赛题数据由约62万条训练集、20万条测试集数据组成，共包含13个字段。其中uuid为样本唯一标识，eid为访问行为ID，udmap为行为属性，其中的key1到key9表示不同的行为属性，如项目名、项目id等相关字段，common_ts为应用访问记录发生时间（毫秒时间戳），其余字段x1至x8为用户相关的属性，为匿名处理字段。target字段为预测目标，即是否为新增用户。</p>
<h2 id="2评估指标"><a class="markdownIt-Anchor" href="#2评估指标"></a> 2.评估指标</h2>
<p>本次竞赛的评价标准采用f1_score，分数越高，效果越好。</p>
<span id="more"></span>
<h2 id="3解题思路"><a class="markdownIt-Anchor" href="#3解题思路"></a> 3.解题思路</h2>
<p>参赛选手的任务是基于训练集的样本数据，构建一个模型来预测测试集中用户的新增情况。这是一个二分类任务，其中目标是根据用户的行为、属性以及访问时间等特征，预测该用户是否属于新增用户。具体来说，选手需要利用给定的数据集进行特征工程、模型选择和训练，然后使用训练好的模型对测试集中的用户进行预测，并生成相应的预测结果。</p>
<h2 id="4遇到的问题"><a class="markdownIt-Anchor" href="#4遇到的问题"></a> 4.遇到的问题</h2>
<ul>
<li>数据量比较大，但是特征比较少，经过处理的特征没几个，因此目的是先增加特征然后再对特征进行处理以及特征降维</li>
<li>还不知道数据集的具体情况，可以对数据集进行筛选（暂时还没进行）</li>
</ul>
<h2 id="5方案"><a class="markdownIt-Anchor" href="#5方案"></a> 5.方案</h2>
<h3 id="相关模块和数据的导入"><a class="markdownIt-Anchor" href="#相关模块和数据的导入"></a> 相关模块和数据的导入：</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="comment">#简单来说LabelEncoder就是把n个类别值编码为0~n-1之间的整数，建立起1-1映射</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="comment">#load() missing 1 required positional argument: &#x27;Loader&#x27;</span></span><br><span class="line"><span class="comment">#E:\software\anaconda\anaconda3\Lib\site-packages\distributed\config.py文件里的</span></span><br><span class="line"><span class="comment">#yaml.load(f)改成yaml.safe_load(f)</span></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> HistGradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> StackingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取训练集和测试集</span></span><br><span class="line"><span class="comment"># 使用 read_csv() 函数从文件中读取训练集数据，文件名为 &#x27;train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">&#x27;用户新增预测挑战赛公开数据/train.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用 read_csv() 函数从文件中读取测试集数据，文件名为 &#x27;test.csv&#x27;</span></span><br><span class="line">test_data = pd.read_csv(<span class="string">&#x27;用户新增预测挑战赛公开数据/test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_data<span class="comment">#用于观察数据集</span></span><br></pre></td></tr></table></figure>
<h3 id="udmap的处理将-字典中的数据和unknown数据以one-hot的存储"><a class="markdownIt-Anchor" href="#udmap的处理将-字典中的数据和unknown数据以one-hot的存储"></a> udmap的处理，将 字典中的数据和unknown数据以one-hot的存储</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. 将 &#x27;udmap&#x27; 列进行 One-Hot 编码 </span></span><br><span class="line"><span class="comment"># 数据样例：</span></span><br><span class="line"><span class="comment">#                    udmap  key1  key2  key3  key4  key5  key6  key7  key8  key9</span></span><br><span class="line"><span class="comment"># 0           &#123;&#x27;key1&#x27;: 2&#125;     2     0     0     0     0     0     0     0     0</span></span><br><span class="line"><span class="comment"># 1           &#123;&#x27;key2&#x27;: 1&#125;     0     1     0     0     0     0     0     0     0</span></span><br><span class="line"><span class="comment"># 2  &#123;&#x27;key1&#x27;: 3, &#x27;key2&#x27;: 2&#125;   3     2     0     0     0     0     0     0     0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 python 中, 形如 &#123;&#x27;key1&#x27;: 3, &#x27;key2&#x27;: 2&#125; 格式的为字典类型对象, 通过key-value键值对的方式存储</span></span><br><span class="line"><span class="comment"># 而在本数据集中, udmap实际是以字符的形式存储, 所以处理时需要先用eval 函数将&#x27;udmap&#x27; 解析为字典</span></span><br><span class="line"><span class="comment"># 具体实现代码：</span></span><br><span class="line"><span class="comment"># 定义函数 udmap_onethot，用于将 &#x27;udmap&#x27; 列进行 One-Hot 编码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">udmap_onethot</span>(<span class="params">d</span>):</span><br><span class="line">    v = np.zeros(<span class="number">9</span>)  <span class="comment"># 创建一个长度为 9 的零数组</span></span><br><span class="line">    <span class="keyword">if</span> d == <span class="string">&#x27;unknown&#x27;</span>:  <span class="comment"># 如果 &#x27;udmap&#x27; 的值是 &#x27;unknown&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> v  <span class="comment"># 返回零数组</span></span><br><span class="line">    d = <span class="built_in">eval</span>(d)  <span class="comment"># 将 &#x27;udmap&#x27; 的值解析为一个字典</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):  <span class="comment"># 遍历 &#x27;key1&#x27; 到 &#x27;key9&#x27;, 注意, 这里不包括10本身</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">in</span> d:  <span class="comment"># 如果当前键存在于字典中</span></span><br><span class="line">            v[i-<span class="number">1</span>] = d[<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i)]  <span class="comment"># 将字典中的值存储在对应的索引位置上</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> v  <span class="comment"># 返回 One-Hot 编码后的数组</span></span><br></pre></td></tr></table></figure>
<h3 id="数据集特征提取"><a class="markdownIt-Anchor" href="#数据集特征提取"></a> 数据集特征提取</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 注: 对于不理解的步骤, 可以逐行 print 内容查看</span></span><br><span class="line"><span class="comment"># 使用 apply() 方法将 udmap_onethot 函数应用于每个样本的 &#x27;udmap&#x27; 列</span></span><br><span class="line"><span class="comment"># np.vstack() 用于将结果堆叠成一个数组</span></span><br><span class="line">train_udmap_df = pd.DataFrame(np.vstack(train_data[<span class="string">&#x27;udmap&#x27;</span>].apply(udmap_onethot)))</span><br><span class="line">test_udmap_df = pd.DataFrame(np.vstack(test_data[<span class="string">&#x27;udmap&#x27;</span>].apply(udmap_onethot)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">apply() 函数的自由度较高，可以直接对 Series 或者 DataFrame 中元素进行逐元素遍历操作，方便且高效，具有类似于 Numpy 的特性。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为新的特征 DataFrame 命名列名</span></span><br><span class="line">train_udmap_df.columns = [<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line">test_udmap_df.columns = [<span class="string">&#x27;key&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line"><span class="comment"># 将编码后的 udmap 特征与原始数据进行拼接，沿着列方向拼接</span></span><br><span class="line">train_data = pd.concat([train_data, train_udmap_df], axis=<span class="number">1</span>)</span><br><span class="line">test_data = pd.concat([test_data, test_udmap_df], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 编码 udmap 是否为空</span></span><br><span class="line"><span class="comment"># 使用比较运算符将每个样本的 &#x27;udmap&#x27; 列与字符串 &#x27;unknown&#x27; 进行比较，返回一个布尔值的 Series</span></span><br><span class="line"><span class="comment"># 使用 astype(int) 将布尔值转换为整数（0 或 1），以便进行后续的数值计算和分析</span></span><br><span class="line">train_data[<span class="string">&#x27;udmap_isunknown&#x27;</span>] = (train_data[<span class="string">&#x27;udmap&#x27;</span>] == <span class="string">&#x27;unknown&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">test_data[<span class="string">&#x27;udmap_isunknown&#x27;</span>] = (test_data[<span class="string">&#x27;udmap&#x27;</span>] == <span class="string">&#x27;unknown&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 提取 eid 的频次特征</span></span><br><span class="line"><span class="comment"># 使用 map() 方法将每个样本的 eid 映射到训练数据中 eid 的频次计数</span></span><br><span class="line"><span class="comment"># train_data[&#x27;eid&#x27;].value_counts() 返回每个 eid 出现的频次计数</span></span><br><span class="line">train_data[<span class="string">&#x27;eid_freq&#x27;</span>] = train_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;eid&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;eid_freq&#x27;</span>] = test_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;eid&#x27;</span>].value_counts())<span class="comment">#这里在测试数据集上用的是训练集的eid的频率</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">map可以接受函数，字典，以及series（和字典类似）。然后这里会进行匹配。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 提取 eid 的标签特征</span></span><br><span class="line"><span class="comment"># 使用 groupby() 方法按照 eid 进行分组，然后计算每个 eid 分组的目标值均值</span></span><br><span class="line"><span class="comment"># train_data.groupby(&#x27;eid&#x27;)[&#x27;target&#x27;].mean() 返回每个 eid 分组的目标值均值</span></span><br><span class="line">train_data[<span class="string">&#x27;eid_mean&#x27;</span>] = train_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;eid&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;eid_mean&#x27;</span>] = test_data[<span class="string">&#x27;eid&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;eid&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">这里现根据eid进行分组</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 提取时间戳</span></span><br><span class="line"><span class="comment"># 使用 pd.to_datetime() 函数将时间戳列转换为 datetime 类型</span></span><br><span class="line"><span class="comment"># 样例：1678932546000-&gt;2023-03-15 15:14:16</span></span><br><span class="line"><span class="comment"># 注: 需要注意时间戳的长度, 如果是13位则unit 为 毫秒, 如果是10位则为 秒, 这是转时间戳时容易踩的坑</span></span><br><span class="line"><span class="comment"># 具体实现代码：</span></span><br><span class="line">train_data[<span class="string">&#x27;common_ts&#x27;</span>] = pd.to_datetime(train_data[<span class="string">&#x27;common_ts&#x27;</span>], unit=<span class="string">&#x27;ms&#x27;</span>)</span><br><span class="line">test_data[<span class="string">&#x27;common_ts&#x27;</span>] = pd.to_datetime(test_data[<span class="string">&#x27;common_ts&#x27;</span>], unit=<span class="string">&#x27;ms&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 dt.hour 属性从 datetime 列中提取小时信息，并将提取的小时信息存储在新的列 &#x27;common_ts_hour&#x27;</span></span><br><span class="line">train_data[<span class="string">&#x27;common_ts_hour&#x27;</span>] = train_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.hour</span><br><span class="line">test_data[<span class="string">&#x27;common_ts_hour&#x27;</span>] = test_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.hour</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;common_ts_day&#x27;</span>] = train_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.day</span><br><span class="line">test_data[<span class="string">&#x27;common_ts_day&#x27;</span>] = test_data[<span class="string">&#x27;common_ts&#x27;</span>].dt.day</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x1_freq&#x27;</span>] = train_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x1&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x1_freq&#x27;</span>] = test_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x1&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x1_mean&#x27;</span>] = train_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x1&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x1_mean&#x27;</span>] = test_data[<span class="string">&#x27;x1&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x1&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x2_freq&#x27;</span>] = train_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x2&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x2_freq&#x27;</span>] = test_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x2&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x2_mean&#x27;</span>] = train_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x2&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x2_mean&#x27;</span>] = test_data[<span class="string">&#x27;x2&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x2&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#train_data[&#x27;x3_freq&#x27;] = train_data[&#x27;x3&#x27;].map(train_data[&#x27;x3&#x27;].value_counts())</span></span><br><span class="line"><span class="comment">#test_data[&#x27;x3_freq&#x27;] = test_data[&#x27;x3&#x27;].map(train_data[&#x27;x3&#x27;].value_counts())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#train_data[&#x27;x4_freq&#x27;] = train_data[&#x27;x4&#x27;].map(train_data[&#x27;x4&#x27;].value_counts())</span></span><br><span class="line"><span class="comment">#test_data[&#x27;x4_freq&#x27;] = test_data[&#x27;x4&#x27;].map(train_data[&#x27;x4&#x27;].value_counts())</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这两个数据有问题，在test中会因为数据不匹配导致NaN的出现因此这两个数据剔除</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x6_freq&#x27;</span>] = train_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x6&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x6_freq&#x27;</span>] = test_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x6&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x6_mean&#x27;</span>] = train_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x6&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x6_mean&#x27;</span>] = test_data[<span class="string">&#x27;x6&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x6&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x7_freq&#x27;</span>] = train_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x7&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x7_freq&#x27;</span>] = test_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x7&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x7_mean&#x27;</span>] = train_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x7&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x7_mean&#x27;</span>] = test_data[<span class="string">&#x27;x7&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x7&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;x8_freq&#x27;</span>] = train_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x8&#x27;</span>].value_counts())</span><br><span class="line">test_data[<span class="string">&#x27;x8_freq&#x27;</span>] = test_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data[<span class="string">&#x27;x8&#x27;</span>].value_counts())</span><br><span class="line">train_data[<span class="string">&#x27;x8_mean&#x27;</span>] = train_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x8&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line">test_data[<span class="string">&#x27;x8_mean&#x27;</span>] = test_data[<span class="string">&#x27;x8&#x27;</span>].<span class="built_in">map</span>(train_data.groupby(<span class="string">&#x27;x8&#x27;</span>)[<span class="string">&#x27;target&#x27;</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment">#df.groupby(分组依据)[数据来源].使用操作</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train=train_data.drop([<span class="string">&#x27;udmap&#x27;</span>,<span class="string">&#x27;uuid&#x27;</span>,<span class="string">&#x27;target&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">test=test_data.drop([<span class="string">&#x27;udmap&#x27;</span>,<span class="string">&#x27;uuid&#x27;</span>,],axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#我们保留了common_ts这个数据，接下来对这个特征的归一化</span></span><br></pre></td></tr></table></figure>
<h4 id="数据归一化处理"><a class="markdownIt-Anchor" href="#数据归一化处理"></a> 数据归一化处理</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对数据进行归一化处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train.columns:</span><br><span class="line">    MAX=<span class="built_in">max</span>(train[i])</span><br><span class="line">    MIN=<span class="built_in">min</span>(train[i])<span class="comment">#用训练集的数据区归一化测试集的数据</span></span><br><span class="line">    LEN=MAX-MIN</span><br><span class="line">    train[i]=train[i].apply(<span class="keyword">lambda</span> x:(x-MIN)/LEN)</span><br><span class="line">    test[i]=test[i].apply(<span class="keyword">lambda</span> x:(x-MIN)/LEN)</span><br></pre></td></tr></table></figure>
<h3 id="特征组合"><a class="markdownIt-Anchor" href="#特征组合"></a> 特征组合</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暴力Feature 行为</span></span><br><span class="line"><span class="comment"># 暴力Feature 时间</span></span><br><span class="line"><span class="comment"># 暴力Feature 用户属性</span></span><br><span class="line"><span class="comment">#这里暂时不考虑特征的随机组合</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴力Feature 行为</span></span><br><span class="line">f = [<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>, <span class="string">&#x27;key3&#x27;</span>, <span class="string">&#x27;key4&#x27;</span>, <span class="string">&#x27;key5&#x27;</span>, <span class="string">&#x27;key6&#x27;</span>, <span class="string">&#x27;key7&#x27;</span>, <span class="string">&#x27;key8&#x27;</span>, <span class="string">&#x27;key9&#x27;</span>,<span class="string">&#x27;udmap_isunknown&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line"><span class="comment">#加f后可以在字符串里面使用用花括号括起来的变量和表达式，如果字符串里面没有表达式，那么前面加不加f输出应该都一样。</span></span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line"><span class="comment"># 暴力Feature 时间</span></span><br><span class="line">f = [<span class="string">&#x27;common_ts_hour&#x27;</span>,<span class="string">&#x27;common_ts_day&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>-<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] - df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>*<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] * df[f[j]]</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>/<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] / (df[f[j]]+<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 暴力Feature 用户属性</span></span><br><span class="line">f = [<span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;x2&#x27;</span>, <span class="string">&#x27;x3&#x27;</span>, <span class="string">&#x27;x4&#x27;</span>, <span class="string">&#x27;x5&#x27;</span>, <span class="string">&#x27;x6&#x27;</span>, <span class="string">&#x27;x7&#x27;</span>, <span class="string">&#x27;x8&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train, test]:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(f)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(f)):</span><br><span class="line">            df[<span class="string">f&#x27;<span class="subst">&#123;f[i]&#125;</span>+<span class="subst">&#123;f[j]&#125;</span>&#x27;</span>] = df[f[i]] + df[f[j]]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="数据降维"><a class="markdownIt-Anchor" href="#数据降维"></a> 数据降维</h3>
<ul>
<li>利用xgboost进行特征选择，最终选出70组特征</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#采用xgboost的特征筛选的功能</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">6</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">xgbc.fit(train, label)</span><br><span class="line">importances_xgb = xgbc.feature_importances_/np.<span class="built_in">sum</span>( xgbc.feature_importances_)</span><br><span class="line"><span class="comment"># print(importances)</span></span><br><span class="line">indices_xgb = np.argsort(importances_xgb)[::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># print(indices)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看结果</span></span><br><span class="line">feat_labels = train.columns</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(train.shape[<span class="number">1</span>]):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % \</span><br><span class="line">          (f + <span class="number">1</span>, <span class="number">30</span>, feat_labels[indices_xgb[f]], importances_xgb[indices_xgb[f]]))</span><br><span class="line"></span><br><span class="line">features=np.array(feat_labels)</span><br><span class="line">num_imo=features[<span class="built_in">list</span>(indices_xgb[<span class="number">0</span>:<span class="number">60</span>])]<span class="comment">#选择60个特征</span></span><br><span class="line"></span><br><span class="line">train=train[num_imo]</span><br><span class="line">test=test[num_imo]</span><br></pre></td></tr></table></figure>
<h3 id="交叉验证模型"><a class="markdownIt-Anchor" href="#交叉验证模型"></a> 交叉验证模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常见的交叉验证模型框架</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_train</span>(<span class="params">model, model_name, kfold=<span class="number">5</span></span>):</span><br><span class="line">    oof_preds = np.zeros((train.shape[<span class="number">0</span>]))<span class="comment">#构造一个series令所有行全部为0</span></span><br><span class="line">    test_preds = np.zeros(test.shape[<span class="number">0</span>])</span><br><span class="line">    skf = StratifiedKFold(n_splits=kfold)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Model = <span class="subst">&#123;model_name&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train.columns))</span><br><span class="line">    <span class="keyword">for</span> k, (train_index, test_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(skf.split(train, label)):</span><br><span class="line">        x_train, x_test = train.iloc[train_index, :], train.iloc[test_index, :]</span><br><span class="line">        y_train, y_test = label.iloc[train_index], label.iloc[test_index]</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">        model.fit(x_train,y_train)</span><br><span class="line">        <span class="comment">#print(2)</span></span><br><span class="line">        y_pred = model.predict_proba(x_test)[:,<span class="number">1</span>]</span><br><span class="line">        <span class="comment">##在这里第一列是预测为0的概率，第二列是预测为1的概率</span></span><br><span class="line">        oof_preds[test_index] = y_pred.ravel()</span><br><span class="line">        auc = roc_auc_score(y_test,y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;- KFold = %d, val_auc = %.4f&quot;</span> % (k, auc))</span><br><span class="line">        test_fold_preds = model.predict_proba(test)[:, <span class="number">1</span>]</span><br><span class="line">        test_preds += test_fold_preds.ravel()<span class="comment">#将给定Series对象的基础数据作为ndarray返回。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Overall Model = %s, F1 = %.4f&quot;</span> % (model_name, f1_score(label, oof_preds, average=<span class="string">&#x27;macro&#x27;</span>)))</span><br><span class="line">    <span class="keyword">return</span> test_preds / kfold<span class="comment">#取平均值</span></span><br></pre></td></tr></table></figure>
<h3 id="数据清洗通过10交叉验证判断数据是否存在问题"><a class="markdownIt-Anchor" href="#数据清洗通过10交叉验证判断数据是否存在问题"></a> 数据清洗，通过10交叉验证判断数据是否存在问题</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">xgbc = XGBClassifier(</span></span><br><span class="line"><span class="string">    objective=&#x27;binary:logistic&#x27;,</span></span><br><span class="line"><span class="string">    eval_metric=&#x27;auc&#x27;,</span></span><br><span class="line"><span class="string">    n_estimators=100, </span></span><br><span class="line"><span class="string">    max_depth=6, </span></span><br><span class="line"><span class="string">    learning_rate=0.1</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">xgbc_test_preds = model_train(xgbc, &quot;XGBClassifier&quot;, 10)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这里用于挑选异常训练集</span></span><br><span class="line"><span class="comment">#看误差是否过大</span></span><br></pre></td></tr></table></figure>
<h3 id="验证集和训练集构建"><a class="markdownIt-Anchor" href="#验证集和训练集构建"></a> 验证集和训练集构建</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将训练数据划分成训练集和验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split( train, label, stratify=label, random_state=<span class="number">2022</span>)</span><br><span class="line"><span class="comment">#75%的训练集</span></span><br></pre></td></tr></table></figure>
<h3 id="模型选择"><a class="markdownIt-Anchor" href="#模型选择"></a> 模型选择</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xgboost实验</span></span><br><span class="line"><span class="comment"># max_depth不能太小否则会出问题</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">50</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">xgbc.fit(x_train,y_train)</span><br><span class="line">y_pred = xgbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策树实验</span></span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line">DT.fit(x_train,y_train)</span><br><span class="line">y_pred = DT.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机森林实验</span></span><br><span class="line">RF=RandomForestClassifier(n_estimators=<span class="number">50</span>)</span><br><span class="line">RF.fit(x_train,y_train)</span><br><span class="line">y_pred = RF.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GDBT实验</span></span><br><span class="line"><span class="comment">#是不是树的深度太浅导致的</span></span><br><span class="line">gbc = GradientBoostingClassifier(</span><br><span class="line">    n_estimators=<span class="number">10</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">gbc.fit(x_train,y_train)</span><br><span class="line">y_pred = gbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#HGBC 实验</span></span><br><span class="line">hgbc = HistGradientBoostingClassifier(</span><br><span class="line">    max_iter=<span class="number">20</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">gbc.fit(x_train,y_train)</span><br><span class="line">y_pred = gbc.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># #LGMB 实验</span></span><br><span class="line"><span class="comment"># gbm = LGBMClassifier(</span></span><br><span class="line"><span class="comment">#     objective=&#x27;binary&#x27;,</span></span><br><span class="line"><span class="comment">#     boosting_type=&#x27;gbdt,</span></span><br><span class="line"><span class="comment">#     num_leaves=2 ** 6, </span></span><br><span class="line"><span class="comment">#     max_depth=50,</span></span><br><span class="line"><span class="comment">#     colsample_bytree=0.8,</span></span><br><span class="line"><span class="comment">#     subsample_freq=1,</span></span><br><span class="line"><span class="comment">#     max_bin=255,</span></span><br><span class="line"><span class="comment">#     learning_rate=0.05, </span></span><br><span class="line"><span class="comment">#     n_estimators=4000, </span></span><br><span class="line"><span class="comment">#     metrics=&#x27;auc&#x27;</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"><span class="comment"># gbm.fit(x_train,y_train)</span></span><br><span class="line"><span class="comment"># y_pred = gbm.predict_proba(x_train)[:, 1]</span></span><br><span class="line"><span class="comment"># threshold=0.5</span></span><br><span class="line"><span class="comment"># y_pred = (y_pred &gt;= threshold).astype(int)</span></span><br><span class="line"><span class="comment"># f1 = f1_score(y_train, y_pred, average=&#x27;macro&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;F1 = %.8f&#x27; % f1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cbc = CatBoostClassifier(</span></span><br><span class="line"><span class="comment">#     iterations=20, </span></span><br><span class="line"><span class="comment">#     depth=16, </span></span><br><span class="line"><span class="comment">#     learning_rate=0.03, </span></span><br><span class="line"><span class="comment">#     l2_leaf_reg=1, </span></span><br><span class="line"><span class="comment">#     loss_function=&#x27;Logloss&#x27;, </span></span><br><span class="line"><span class="comment">#     verbose=0</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"><span class="comment"># cbc.fit(x_train,y_train)</span></span><br><span class="line"><span class="comment"># y_pred = cbc.predict_proba(x_train)[:, 1]</span></span><br><span class="line"><span class="comment"># threshold=0.5</span></span><br><span class="line"><span class="comment"># y_pred = (y_pred &gt;= threshold).astype(int)</span></span><br><span class="line"><span class="comment"># f1 = f1_score(y_train, y_pred, average=&#x27;macro&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;F1 = %.8f&#x27; % f1)</span></span><br><span class="line"></span><br><span class="line">ada=AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">50</span>),</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">    learning_rate=<span class="number">0.01</span></span><br><span class="line">    )<span class="comment">#默认是CART决策树作为单模型</span></span><br><span class="line">ada.fit(x_train,y_train)</span><br><span class="line">y_pred = ada.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br></pre></td></tr></table></figure>
<h3 id="模型融合"><a class="markdownIt-Anchor" href="#模型融合"></a> 模型融合</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最终决定：决策树，xgboost， RF，GBDT，HGBC,adaboost这几个模型stack</span></span><br><span class="line">xgbc = XGBClassifier(</span><br><span class="line">    objective=<span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">50</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line">DT = DecisionTreeClassifier()</span><br><span class="line">RF=RandomForestClassifier(n_estimators=<span class="number">50</span>)</span><br><span class="line">gbc = GradientBoostingClassifier(</span><br><span class="line">    n_estimators=<span class="number">10</span>, </span><br><span class="line">    learning_rate=<span class="number">0.1</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">hgbc = HistGradientBoostingClassifier(</span><br><span class="line">    max_iter=<span class="number">20</span>,</span><br><span class="line">    max_depth=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">ada=AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">50</span>),</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">    learning_rate=<span class="number">0.01</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">estimators = [</span><br><span class="line">    (<span class="string">&#x27;xgbc&#x27;</span>, xgbc),</span><br><span class="line">    (<span class="string">&#x27;DT&#x27;</span>,DT),</span><br><span class="line">    (<span class="string">&#x27;RF&#x27;</span>,RF),</span><br><span class="line">    (<span class="string">&#x27;gbc&#x27;</span>, gbc),</span><br><span class="line">    (<span class="string">&#x27;hgbc&#x27;</span>, hgbc),</span><br><span class="line">    (<span class="string">&#x27;ada&#x27;</span>, ada),</span><br><span class="line">]</span><br><span class="line">clf = StackingClassifier(</span><br><span class="line">    estimators=estimators, </span><br><span class="line">    final_estimator=LogisticRegression()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用组合模型训练</span></span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line">y_pred = clf.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">threshold=<span class="number">0.5</span></span><br><span class="line">y_pred = (y_pred &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">f1 = f1_score(y_test, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1 = %.8f&#x27;</span> % f1)</span><br></pre></td></tr></table></figure>
<h3 id="结果提交"><a class="markdownIt-Anchor" href="#结果提交"></a> 结果提交</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #这里的分类器我不单单想用上面的，我打算重新训练所有数据集来进行预测</span></span><br><span class="line"><span class="comment"># clf_test_preds = model_train(clf, &quot;StackingClassifier&quot;)</span></span><br><span class="line"><span class="comment"># #还是用全部的数据进行训练 </span></span><br><span class="line"><span class="comment"># clf.fit(train,label)</span></span><br><span class="line"></span><br><span class="line">result_df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;uuid&#x27;</span>: test_data[<span class="string">&#x27;uuid&#x27;</span>],  <span class="comment"># 使用测试数据集中的 &#x27;uuid&#x27; 列作为 &#x27;uuid&#x27; 列的值</span></span><br><span class="line">    <span class="string">&#x27;target&#x27;</span>: clf.predict(test)  <span class="comment"># 使用模型 clf 对测试数据集进行预测，并将预测结果存储在 &#x27;target&#x27; 列中</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">result_df.to_csv(<span class="string">&#x27;submit.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E7%AB%9E%E8%B5%9B/" rel="tag"># 竞赛</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/08/24/pytorch-data-detach/" rel="prev" title="pytorch_data&detach">
                  <i class="fa fa-chevron-left"></i> pytorch_data&detach
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/08/24/pytorch-torch-autograd-Function/" rel="next" title="pytorch_torch.autograd.Function">
                  pytorch_torch.autograd.Function <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  
  <div class="comments giscus-container">
  </div>
  
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YNY</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">28k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">25 分钟</span>
  </span>
</div>



    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css" integrity="sha256-hLTCMFlKxdNgPXyWlSSxYN0ykJmxxq9Yt3MNfdRGWeA=" crossorigin="anonymous">



  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #4D4D4C;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #F7F7F7;
      background-image: linear-gradient(#F7F7F7, #F7F7F7);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>

  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('复制成功')
          else $(this).text('复制失败')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>

<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"handsomexiu/comments","repo_id":"R_kgDOJzfTTQ","category":"Announcements","category_id":"DIC_kwDOJzfTTc4CXcBf","mapping":"pathname","data_strict":0,"reactions_enabled":1,"emit_metadata":0,"theme":"light","lang":"zh-CN","crossorigin":"anonymous","input_position":"bottom"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>

</body>
</html>
